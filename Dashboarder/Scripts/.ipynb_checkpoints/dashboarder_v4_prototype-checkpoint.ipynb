{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from datetime import datetime as dt\n",
    "import json\n",
    "import pyodbc\n",
    "import re\n",
    "import types\n",
    "from termcolor import colored\n",
    "import types\n",
    "import re\n",
    "import os\n",
    "from bokeh import plotting\n",
    "from bokeh import layouts\n",
    "from bokeh import io\n",
    "from bokeh import models\n",
    "from bokeh.models.tools import HoverTool\n",
    "from bokeh.models.widgets.markups import Div\n",
    "from math import ceil\n",
    "import math\n",
    "from sympy.ntheory import primefactors\n",
    "import statsmodels as sm        \n",
    "import copy\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Login ##\n",
    "\n",
    "ROOT_PATH = sys.path[0][:sys.path[0].rindex('\\\\')]\n",
    "\n",
    "RESOURCES_PATH = os.path.join(ROOT_PATH, r'Resources')\n",
    "\n",
    "login_file_path = os.path.join(RESOURCES_PATH, r'login.json')\n",
    "\n",
    "with open(login_file_path, 'r') as json_file:\n",
    "    login_details = json.load(json_file)\n",
    "\n",
    "## Obtain list of all databases with relevant information ##\n",
    "\n",
    "master_db = 'master'\n",
    "\n",
    "master_db_connection = pyodbc.connect('Driver={SQL Server};'\n",
    "                                'Server=' + login_details['server'] + ';'\n",
    "                                 'Database=' + master_db + ';'\n",
    "                                 'Uid=' + login_details['uid'] + ';'\n",
    "                                 'Pwd=' + login_details['pwd'] + ';')\n",
    "\n",
    "get_databases_query = (\"select name \\\n",
    "                        from master.sys.databases \\\n",
    "                        where name like '%scada_production%'\")\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "customer_data_databases = pd.read_sql_query(get_databases_query, master_db_connection)\n",
    "warnings.resetwarnings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 name\n",
      "1               scada_Production_AMAT\n",
      "2       scada_Production_AMAT_PdMTest\n",
      "3                scada_Production_ASW\n",
      "4               scada_Production_CXMT\n",
      "5               scada_Production_DBCC\n",
      "6       scada_Production_GF_Diffusion\n",
      "7         scada_Production_GF_Dresden\n",
      "8           scada_Production_GF_Films\n",
      "9      scada_Production_GF_Patterning\n",
      "10         scada_Production_GF_Phase1\n",
      "11              scada_Production_IMEC\n",
      "12         scada_Production_IMEC_MAIN\n",
      "13  scada_Production_Infineon_Dresden\n",
      "14      scada_Production_KIOXIA_DAISE\n",
      "15              scada_Production_LETI\n",
      "16               scada_Production_MB1\n",
      "17        scada_Production_Micron_F11\n",
      "18        scada_Production_Micron_F15\n",
      "19        scada_Production_Micron_F16\n",
      "20         scada_Production_Micron_F6\n",
      "21          scada_Production_Nexperia\n",
      "22           scada_Production_PdMDemo\n",
      "23           scada_Production_Plessey\n",
      "24         scada_Production_Samsung01\n",
      "25         scada_Production_Samsung02\n",
      "26        scada_Production_ST_Crolles\n",
      "27        scada_Production_TEL_Hosaka\n",
      "28           scada_Production_UMC_CSA\n",
      "29            scada_Production_UMC12i\n",
      "30              scada_Production_UMC5\n",
      "31           scada_Production_UMC5_17\n",
      "32          scada_Production_UMCDec19\n",
      "33           scada_Production_UMCP1_2\n",
      "34       scada_Production_XFAB_France\n",
      "35           scada_Production_Yachiyo\n",
      "36            scada_Production_YMTC_2\n",
      "37            scada_Production_YMTC_3\n",
      "\n",
      "Using the the table displayed, please enter the number corresponding to the customer database of interest:\n",
      "19\n",
      "You have chosen \"scada_Production_Micron_F16\". Is this correct (Y/N)? y\n",
      "Please enter the path of the directory within which you wish the data and figures to be saved: C:\\Users\\a00555655\\OneDrive - ONEVIRTUALOFFICE\\Documents\\Python Scripts\\Dashboards\n",
      "\n",
      "All files will be placed at: \n",
      "\"C:\\Users\\a00555655\\OneDrive - ONEVIRTUALOFFICE\\Documents\\Python Scripts\\Dashboards\\Micron_F16\".\n",
      "Please choose whether you wish to proceed by \n",
      "1. System Name; \n",
      "2. System Type; \n",
      "3. Both.\n",
      "Alternatively, if you wish to retrieve data for all systems within scada_Production_Micron_F16, please enter 4.\n",
      "4\n",
      "Thank you for choosing 4\n",
      "30 systems were found within scada_Production_Micron_F16, including:\n",
      "       Description  SystemTypeID\n",
      "0     KOXDL50300FC            36\n",
      "1     KOXDL50500FC            36\n",
      "2     KOXDL50200FC            36\n",
      "3     KOXDL50100FC            36\n",
      "4       KOXDL50500            37\n",
      "5       KOXDL50300            37\n",
      "6       KOXDL50100            37\n",
      "7       KOXDL50200            37\n",
      "8       KOXDL50400            49\n",
      "9   KOXDL50200Ch A            49\n",
      "10      KOXDL50900            49\n",
      "11      KOXDL50600            49\n",
      "12  KOXDL50300Ch A            49\n",
      "13  KOXDL50100Ch A            49\n",
      "14  KOXDL50500Ch A            49\n",
      "15      KOXDL50800            49\n",
      "16      KOXDL50700            49\n",
      "17    KOXDL50200AC         16403\n",
      "18    KOXDL50500AC         16403\n",
      "19    KOXDL50300AC         16403\n",
      "20    KOXDL50100AC         16403\n",
      "21    KOXDL50300VI         17002\n",
      "22    KOXDL50700VI         17002\n",
      "23    KOXDL50800VI         17002\n",
      "24    KOXDL50100VI         17002\n",
      "25    KOXDL50200VI         17002\n",
      "26    KOXDL50500VI         17002\n",
      "27    KOXDL50600VI         17002\n",
      "28    KOXDL50900VI         17002\n",
      "29    KOXDL50400VI         17002\n",
      "Will retrieve data for these systems.\n"
     ]
    }
   ],
   "source": [
    "## Prompt user for the customer/database of interest ##\n",
    "\n",
    "confirmation = 'N'\n",
    "while confirmation != 'Y':\n",
    "    print(customer_data_databases.iloc[1:])\n",
    "    choices = customer_data_databases.iloc[1:].index.to_list()\n",
    "    user_choice = input('\\nUsing the the table displayed, please enter the number corresponding to the customer database of interest:\\n')\n",
    "    try:\n",
    "        user_choice = int(user_choice)\n",
    "    except:\n",
    "        pass\n",
    "    while user_choice not in choices:\n",
    "        print(customer_data_databases.iloc[1:])\n",
    "        user_choice = input('\\nInvalid choice. Please choose a number associated with one of the databases listed below: \\n')\n",
    "        try:\n",
    "            user_choice = int(user_choice)\n",
    "        except:\n",
    "            pass\n",
    "    confirmation = input(f'You have chosen \"{customer_data_databases.iloc[user_choice][0]}\". Is this correct (Y/N)? ').upper()\n",
    "database = customer_data_databases.iloc[user_choice][0]\n",
    "\n",
    "MAIN_FOLDER_PATH = fr\"{input('Please enter the path of the directory within which you wish the data and figures to be saved: ')}\".replace('\"', '').replace(\"'\",'')\n",
    "while not os.path.exists(MAIN_FOLDER_PATH):\n",
    "    print('\\n')\n",
    "    MAIN_FOLDER_PATH = fr\"{input('The entered path does not exist. Please enter a valid path to continue: ')}\"\n",
    "date = datetime.datetime.today().strftime('%Y-%m-%d')\n",
    "customer_account_name = database[17:]\n",
    "MAIN_FOLDER_PATH = os.path.join(MAIN_FOLDER_PATH, fr'{customer_account_name}')\n",
    "if not os.path.exists(MAIN_FOLDER_PATH):\n",
    "    os.makedirs(MAIN_FOLDER_PATH)\n",
    "    assert os.path.exists(MAIN_FOLDER_PATH)\n",
    "print(f'\\nAll files will be placed at: \\n\"{MAIN_FOLDER_PATH}\".')\n",
    "    \n",
    "## Get inputs function ##\n",
    "\n",
    "def get_input(prompt, success_conditions=None, failure_messages=None, message=None, wrapping_func=None, literal_str=False):\n",
    "\n",
    "    if wrapping_func == None:\n",
    "        wrapping_func = lambda x: x\n",
    "    \n",
    "    if message is not None:\n",
    "        print(message)\n",
    "    \n",
    "    if success_conditions == None:\n",
    "#         print('input1')\n",
    "        if literal_str==True:\n",
    "#             print('input2')\n",
    "            return fr\"{input(prompt)}\"\n",
    "        else:\n",
    "#             print('input3')\n",
    "            return wrapping_func(input(prompt))\n",
    "    else:\n",
    "        k=1\n",
    "#         print('input4')\n",
    "        x = fr\"{input(prompt)}\"\n",
    "        \n",
    "        x = x.replace('\"', '')\n",
    "        \n",
    "        num_conditions_to_satisfy = len(success_conditions)\n",
    "\n",
    "        success_count = 0\n",
    "\n",
    "        while success_count < num_conditions_to_satisfy:\n",
    "#             print('input5')\n",
    "        \n",
    "            for idx in range(num_conditions_to_satisfy):\n",
    "#                 print('input6')\n",
    "                # print(f'Success condition {idx} is {success_conditions[idx](x)} because x is {x} and its type is {type(x)}')\n",
    "                if isinstance(success_conditions[idx], types.FunctionType):\n",
    "#                     print('input7')\n",
    "                    if success_conditions[idx](x):\n",
    "#                         print('input8')\n",
    "                        success_count+=1\n",
    "                    else:\n",
    "#                         print('input9')\n",
    "                        print(failure_messages)\n",
    "                        if failure_messages is not None and len(failure_messages) > 1:\n",
    "#                             print('input10')\n",
    "                            print(failure_messages[idx].format(x, type(x), f'Condition {idx+1} failure'))\n",
    "                            return get_input(prompt, \n",
    "                                            success_conditions=success_conditions, \n",
    "                                            failure_messages=failure_messages, \n",
    "                                            message=message,\n",
    "                                            wrapping_func=wrapping_func)\n",
    "                        elif failure_messages is not None and len(failure_messages) == 1:\n",
    "#                             print('input11')\n",
    "                            print(failure_messages[0].format(x))\n",
    "                            return get_input(prompt, \n",
    "                                             success_conditions=success_conditions, \n",
    "                                             failure_messages=failure_messages, \n",
    "                                             message=message,\n",
    "                                             wrapping_func=wrapping_func)\n",
    "                \n",
    "                else:\n",
    "#                     print('input12')\n",
    "                    if success_conditions[idx]:\n",
    "                        success_count+=1\n",
    "                    else:\n",
    "#                         print('input13')\n",
    "                        if len(failure_messages) > 1:\n",
    "#                             print('input14')\n",
    "                            print(failure_messages[idx].format(x, type(x), f'Condition {idx+1} failure'))\n",
    "                            return get_input(prompt, \n",
    "                                            success_conditions=success_conditions, \n",
    "                                            failure_messages=failure_messages, \n",
    "                                            message=message,\n",
    "                                            wrapping_func=wrapping_func)\n",
    "                        else:\n",
    "#                             print('input15')\n",
    "                            print(failure_messages[0])\n",
    "                            return get_input(prompt, \n",
    "                                             success_conditions=success_conditions, \n",
    "                                             failure_messages=failure_messages, \n",
    "                                             message=message,\n",
    "                                            wrapping_func=wrapping_func)\n",
    "        print(f'Thank you for choosing {wrapping_func(x)}')\n",
    "        return wrapping_func(x)\n",
    "\n",
    "## Establish connection with the chosen customer data connection ##\n",
    "\n",
    "db_connection = pyodbc.connect('Driver={SQL Server};'\n",
    "                                'Server=' + login_details['server'] + ';'\n",
    "                                 'Database=' + database + ';'\n",
    "                                 'Uid=' + login_details['uid'] + ';'\n",
    "                                 'Pwd=' + login_details['pwd'] + ';')\n",
    "\n",
    "## Define a function that checks whether a string can be converted to an integetr or not ##\n",
    "\n",
    "def isintable(x):\n",
    "    try:\n",
    "        x = int(x)\n",
    "        return True\n",
    "    except:\n",
    "        False\n",
    "\n",
    "## Prompt user for whether they want to obtain system data based on system types, system names or both ##\n",
    "\n",
    "type_or_name_or_both = get_input(prompt=f'Please choose whether you wish to proceed by \\n1. System Name; \\n2. System Type; \\n3. Both.\\nAlternatively, if you wish to retrieve data for all systems within {database}, please enter 4.\\n',\n",
    "                                 success_conditions=(isintable, lambda x: int(x) in (1,2,3,4)),\n",
    "                                 failure_messages=('{2}: {0} is not a valid choice. Please choose from 1, 2, 3 and 4 because {0} cannot be converted into an integer.',\n",
    "                                                   '{2}: {0} is not a valid choice. Please choose from 1, 2, 3 and 4 because {0} is not in (1,2,3,4).'),\n",
    "                                 message=None,\n",
    "                                 wrapping_func=int)\n",
    "\n",
    "if type_or_name_or_both in (1,3):\n",
    "    systems_by_file = get_input(prompt='Would you like to \\n0. Enter the system names here (enter 0); or \\n1. Pass a file path containing the system names (enter 1)\\n',\n",
    "                                success_conditions=(isintable, lambda x: int(x) in (0,1)),\n",
    "                                failure_messages=('{2}: {0} is not a valid choice as it cannot be converted into an integer. Please choose from 0 or 1.',\n",
    "                                                  '{2}: {0} is noT a valid choice as it is neither 0 nor 1. Please choose 0 or 1.'),\n",
    "                                wrapping_func=int)\n",
    "\n",
    "else:\n",
    "    systems_by_file = 0\n",
    "\n",
    "get_system_names_bool_args = {'by_names':bool(type_or_name_or_both==1 or type_or_name_or_both==3),\n",
    "                              'by_types':bool(type_or_name_or_both==2 or type_or_name_or_both==3),\n",
    "                              'systems_by_file':bool(systems_by_file==1),\n",
    "                              'everything':bool(type_or_name_or_both==4)}\n",
    "\n",
    "\n",
    "## Define a function for retrieving system names form a comma separated text file ##\n",
    "\n",
    "def systems_from_csv(PATH):\n",
    "    \n",
    "    systems = []\n",
    "    \n",
    "    SYSTEMS_FILE_PATH = PATH\n",
    "\n",
    "    with open(SYSTEMS_FILE_PATH, 'r') as systems_file:\n",
    "        for line in systems_file:\n",
    "            line_systems = re.split(',|, | ,| , ', line)\n",
    "            systems = systems.copy() + line_systems.copy()\n",
    "\n",
    "    for i in range(len(systems)):\n",
    "        if '\\'' in systems[i] or '\\\"' in systems[i]:\n",
    "            systems[i] = systems[i].replace('\\'', '')\n",
    "            systems[i] = systems[i].replace('\\\"', '')\n",
    "    \n",
    "    return systems\n",
    "\n",
    "## Prompt user for systems/system types/both and ensure at least one corresponding system exists ##\n",
    "\n",
    "def get_system_names(db_connection, database, by_names=False, by_types=False, systems_by_file=False, everything=False):\n",
    "    if by_names:\n",
    "        if not systems_by_file:\n",
    "            systems = get_input(prompt='Please enter the names of the systems for which you wish to retrieve data, separated by commas.\\n')\n",
    "            systems = re.split(',| ,|, | , ', systems)\n",
    "            systems_as_string = str(systems).replace('[','(').replace(']',')')\n",
    "            \n",
    "\n",
    "            if by_types:\n",
    "                system_types = get_input(prompt='Please enter the types of the systems for which you wish to retrieve data, separated by commas.\\n')\n",
    "                system_types = re.split(',| ,| , ', system_types)\n",
    "                system_types_as_string = str(system_types).replace('[', '(').replace(']', ')')\n",
    "                \n",
    "                check_system_name_query = f'select * from {database}.dbo.fst_GEN_system \\\n",
    "                                            where Description in {systems_as_string} \\\n",
    "                                            and SystemTypeID in {system_types_as_string} \\\n",
    "                                            order by SystemTypeID'\n",
    "            \n",
    "            else:\n",
    "                check_system_name_query = f'select * from {database}.dbo.fst_GEN_system \\\n",
    "                                            where Description in {systems_as_string} \\\n",
    "                                            order by SystemTypeID'\n",
    "\n",
    "        else:\n",
    "            systems_path = get_input(prompt='Please enter the file location for a comma separated file containing the names of the systems of interest:\\n',\n",
    "                                     success_conditions=[os.path.exists],\n",
    "                                     failure_messages=['The path you have entered, namely {}, does not exist. Please try again.\\n'])\n",
    "            systems = systems_from_csv(systems_path)\n",
    "            systems_as_string = str(systems).replace('[','(').replace(']',')')\n",
    "\n",
    "\n",
    "            if by_types:\n",
    "                system_types = get_input(prompt='Please enter the types of the systems for which you wish to retrieve data, separated by commas.\\n')\n",
    "                system_types = re.split(',| ,| , ', system_types)\n",
    "                system_types_as_string = str(system_types).replace('[','(').replace(']',')')\n",
    "                check_system_name_query = f'select * from {database}.dbo.fst_GEN_system \\\n",
    "                                                where Description in {systems_as_string} \\\n",
    "                                                and SystemTypeID in {system_types_as_string} \\\n",
    "                                                order by SystemTypeID'\n",
    "            else:\n",
    "                check_system_name_query = f'select * from {database}.dbo.fst_GEN_system \\\n",
    "                                            where Description in {systems_as_string} \\\n",
    "                                            order by SystemTypeID'\n",
    "        warnings.filterwarnings('ignore')\n",
    "        query_result = pd.read_sql_query(check_system_name_query, db_connection)\n",
    "        warnings.resetwarnings()\n",
    "        valid_systems = list(query_result['Description'].unique())\n",
    "        invalid_systems = list(set(systems) - set(valid_systems))\n",
    "        if len(invalid_systems) > 1:\n",
    "            print('checking invalid systems')\n",
    "            if len(valid_systems) < 1:\n",
    "                print('yo13')\n",
    "                print(f'Could not find any systems within {database} corresponding to the system names and types (if any entered) provided. Please try again.')\n",
    "                return get_system_names(db_connection=db_connection, \n",
    "                                        database=database, \n",
    "                                        by_names=by_names, \n",
    "                                        by_types=by_types, \n",
    "                                        systems_by_file=systems_by_file,\n",
    "                                        everything=everything)\n",
    "            else:\n",
    "                print(f'Could not find any systems within {database} corresponding to the entered system types (if any were entered) and following system names: {invalid_systems}.')\n",
    "                print(f'Valid system names: {valid_systems}.\\nWill retrieve data for these systems.')\n",
    "                return query_result, valid_systems\n",
    "        else:\n",
    "            print(f'Found systems corresponding to all of the entered names within the {database} database; namely: \\n{valid_systems}\\nWill retrieve data for these systems.')\n",
    "            return query_result, valid_systems\n",
    "\n",
    "    elif by_types:\n",
    "        system_types = get_input(prompt='Please enter the types of the systems for which you wish to retrieve data, separated by commas.\\n')\n",
    "        system_types = re.split(',| ,| , ', system_types)\n",
    "        system_types_as_string = str(system_types).replace('[','(').replace(']',')')\n",
    "        check_system_name_query = f'select * from {database}.dbo.fst_GEN_system \\\n",
    "                                    where SystemTypeID in {system_types_as_string} \\\n",
    "                                    order by SystemTypeID'\n",
    "        \n",
    "        warnings.filterwarnings('ignore')\n",
    "        query_result = pd.read_sql_query(check_system_name_query, db_connection)\n",
    "        warnings.resetwarnings()\n",
    "        \n",
    "        if len(query_result) > 0:\n",
    "            type_systems = query_result[['Description', 'SystemTypeID']]\n",
    "            print(f'The following systems were found to correspond with system types {system_types}:')\n",
    "            print(type_systems)\n",
    "            print('Will retrieve data for these systems.')\n",
    "            return query_result, list(query_result.Description.unique())\n",
    "        \n",
    "        else:\n",
    "            print('yo19')\n",
    "            print(f'Could not find any systems within {database} whose system type IDs correspond with any of {system_types}. Please try again.')\n",
    "            return get_system_names(db_connection=db_connection, \n",
    "                                    database=database, \n",
    "                                    by_names=by_names, \n",
    "                                    by_types=by_types, \n",
    "                                    systems_by_file=systems_by_file,\n",
    "                                    everything=everything)\n",
    "    elif everything:\n",
    "        check_system_name_query = f'select * from {database}.dbo.fst_GEN_System \\\n",
    "                                    order by SystemTypeID'\n",
    "        warnings.filterwarnings('ignore')\n",
    "        query_result = pd.read_sql_query(check_system_name_query, db_connection)\n",
    "        warnings.resetwarnings()\n",
    "        print(f'{len(query_result)} systems were found within {database}, including:')\n",
    "        print(query_result[['Description','SystemTypeID']])\n",
    "        print('Will retrieve data for these systems.')\n",
    "        return query_result, list(query_result.Description.unique())\n",
    "\n",
    "systems_info, systems = get_system_names(db_connection=db_connection,\n",
    "                                         database=database,\n",
    "                                         **get_system_names_bool_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Would you like the system data to be: \n",
      "1. Separated by swaps (enter 1); \n",
      "2. Unseparated by swaps (enter 2); \n",
      "3. Plots for the entire data as well as the data separated by swaps (enter 3).\n",
      "3\n",
      "Thank you for choosing 3\n"
     ]
    }
   ],
   "source": [
    "## Prompt user for whether they want to obtain data separated by swaps, unseparated by swaps or both\n",
    "\n",
    "separate_by_swap = False\n",
    "sep_and_whole = False\n",
    "\n",
    "separate_by_swap_or_not = get_input(prompt=f'Would you like the system data to be: \\n1. Separated by swaps (enter 1); \\n2. Unseparated by swaps (enter 2); \\n3. Plots for the entire data as well as the data separated by swaps (enter 3).\\n',\n",
    "                                    success_conditions=(isintable, lambda x: int(x) in (1,2,3)),\n",
    "                                    failure_messages=('{2}: {0} is not a valid choice as it cannot be converted into an integer. Please choose from 1, 2 or 3.',\n",
    "                                                      '{2}: {0} is noT a valid choice as it is not in (1,2,3). Please choose 1, 2 or 3.'),\n",
    "                                    wrapping_func=int)\n",
    "\n",
    "if separate_by_swap_or_not in (1,3):\n",
    "    separate_by_swap = True\n",
    "    if separate_by_swap_or_not == 3:\n",
    "        sep_and_whole = True\n",
    "elif separate_by_swap_or_not == 2:\n",
    "    pass\n",
    "else:\n",
    "    raise ValueError(f'Invalid value of \\'{separate_by_swap_or_not}\\' of type {type(separate_by_swap_or_not)} passed to `separate_by_swap_or_not`.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Would you like the parameter definitions to be concealed? (Y/N):\n",
      "n\n",
      "Thank you for choosing n\n"
     ]
    }
   ],
   "source": [
    "# Prompt user for whether they want the parameter definitions to be concealed\n",
    "\n",
    "def conceal_or_not():\n",
    "    conceal_param_defs = get_input(prompt='Would you like the parameter definitions to be concealed? (Y/N):\\n',\n",
    "                               success_conditions=[lambda x: isinstance(x, str), lambda x: x.upper() in ('Y', 'N')],\n",
    "                               failure_messages=['The value entered is not a string. Please enter \\'Y\\' or \\'N\\'.',\n",
    "                                                 'The value entered is neither \\'Y\\' nor \\'N\\'. Please enter a valid input.'])\n",
    "    if conceal_param_defs.upper() == 'Y':\n",
    "        conceal_param_defs = True\n",
    "    elif conceal_param_defs.upper() == 'N':\n",
    "        conceal_param_defs = False\n",
    "    else:\n",
    "        print(f'Invalid entry {conceal_param_defs} provided. Please try again')\n",
    "        return conceal_or_not()\n",
    "    \n",
    "    return conceal_param_defs\n",
    "\n",
    "conceal_params = conceal_or_not()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Would you like to see: \n",
      "1) all of the parameter data for these systems; or \n",
      "2) just predefined views?\n",
      "2\n",
      "Thank you for choosing 2\n"
     ]
    }
   ],
   "source": [
    "# Prompt the user for whether they want all parameter data or predefined views\n",
    "\n",
    "def plot_all_data_or_view():\n",
    "    view_or_all = get_input(prompt='Would you like to see: \\n1) all of the parameter data for these systems; or \\n2) just predefined views?\\n',\n",
    "                            success_conditions=[isintable, lambda x: int(x) in (1,2)],\n",
    "                            failure_messages=('{2}: {0} is not a valid choice as it cannot be converted into an integer. Please enter 1 or 2.',\n",
    "                                              '{2}: {0} is not in (1,2). Please enter 1 or 2.'),\n",
    "                            wrapping_func=int)\n",
    "    if view_or_all == 1:\n",
    "        view_or_all = 'all'\n",
    "    elif view_or_all == 2:\n",
    "        view_or_all = 'view'\n",
    "    else:\n",
    "        print(f'Invalid entry {view_or_all} provided. Please try again')\n",
    "        return plot_all_data_or_view()\n",
    "    \n",
    "    return view_or_all\n",
    "\n",
    "dash_view_or_all = plot_all_data_or_view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving data for KOXDL50300FC.\n",
      "Data retrieved for KOXDL50300FC.\n",
      "29 systems remain to be processed.\n",
      "Retrieving data for KOXDL50500FC.\n",
      "Data retrieved for KOXDL50500FC.\n",
      "28 systems remain to be processed.\n",
      "Retrieving data for KOXDL50200FC.\n",
      "Data retrieved for KOXDL50200FC.\n",
      "27 systems remain to be processed.\n",
      "Retrieving data for KOXDL50100FC.\n",
      "Data retrieved for KOXDL50100FC.\n",
      "26 systems remain to be processed.\n",
      "Retrieving data for KOXDL50500.\n",
      "Data retrieved for KOXDL50500.\n",
      "25 systems remain to be processed.\n",
      "Retrieving data for KOXDL50300.\n",
      "Data retrieved for KOXDL50300.\n",
      "24 systems remain to be processed.\n",
      "Retrieving data for KOXDL50100.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_239312\\2069818296.py\u001b[0m in \u001b[0;36m<cell line: 96>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilterwarnings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ignore'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 122\u001b[1;33m     \u001b[0msystem_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_sql_query\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msystem_data_query\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdb_connection\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    123\u001b[0m     \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresetwarnings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36mread_sql_query\u001b[1;34m(sql, con, index_col, coerce_float, params, parse_dates, chunksize, dtype)\u001b[0m\n\u001b[0;32m    397\u001b[0m     \"\"\"\n\u001b[0;32m    398\u001b[0m     \u001b[0mpandas_sql\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpandasSQL_builder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 399\u001b[1;33m     return pandas_sql.read_query(\n\u001b[0m\u001b[0;32m    400\u001b[0m         \u001b[0msql\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m         \u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36mread_query\u001b[1;34m(self, sql, index_col, coerce_float, params, parse_dates, chunksize, dtype)\u001b[0m\n\u001b[0;32m   2092\u001b[0m             )\n\u001b[0;32m   2093\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2094\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetchall_as_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcursor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2095\u001b[0m             \u001b[0mcursor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2096\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36m_fetchall_as_list\u001b[1;34m(self, cur)\u001b[0m\n\u001b[0;32m   2106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2107\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_fetchall_as_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcur\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2108\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcur\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetchall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2109\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2110\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Obtain parameter information ##\n",
    "\n",
    "def get_parameters(systems, database, db_connection):\n",
    "\n",
    "    systems_parameter_info = {}\n",
    "        \n",
    "    for idx in range(len(systems)):\n",
    "\n",
    "        sys = systems[idx]\n",
    "\n",
    "        get_parameters_query = (f\"select DISTINCT a.SystemID, a.SystemTypeID, a.Description [SystemName], a.LastAlertLogTime, c.ParameterNumber, c.zzDescription,  c.SIUnitID\\\n",
    "                                from {database}..fst_GEN_System a \\\n",
    "                                join [{database}].[dbo].[fst_GEN_Parameter] b \\\n",
    "                                    on a.SystemTypeID = b.SystemTypeID \\\n",
    "                                join [{database}].[dbo].[fst_GEN_ParameterType] c \\\n",
    "                                    on b.SystemTypeID = c.SystemTypeID \\\n",
    "                                    and b.ParameterNumber = c.ParameterNumber \\\n",
    "                                where a.Description = \\'{sys}\\' \\\n",
    "                                order by a.SystemTypeID, a.Description\")\n",
    "        warnings.filterwarnings('ignore')\n",
    "        parameter_information = pd.read_sql_query(get_parameters_query, db_connection)\n",
    "        warnings.resetwarnings()\n",
    "        \n",
    "        systems_parameter_info[sys] = parameter_information\n",
    "        \n",
    "    return systems_parameter_info\n",
    "\n",
    "## Create a parameter mapping dictionary for all systems ##\n",
    "\n",
    "systems_parameter_info = get_parameters(systems=systems, database=database, db_connection=db_connection)\n",
    "\n",
    "systems_parameter_info['param_mapping'] = {}\n",
    "for system in systems:\n",
    "    zipped = list(zip(systems_parameter_info[system]['ParameterNumber'], systems_parameter_info[system]['zzDescription']))\n",
    "    systems_parameter_info['param_mapping'][system] = dict(zipped)\n",
    "\n",
    "systems_parameter_info['param_mapping']\n",
    "systems_to_check = list(systems_parameter_info['param_mapping'].keys())\n",
    "for key in systems_to_check:\n",
    "    if len(systems_parameter_info['param_mapping'][key]) == 0:\n",
    "        print(f'Removing \\'{key}\\' from the list of systems for which data will be retrieved because it has no parameter informaiton.')\n",
    "        systems_parameter_info['param_mapping'].pop(key)\n",
    "\n",
    "### Partition Parameters by the Associated Mechanical Part ###\n",
    "\n",
    "systems = list(systems_parameter_info['param_mapping'].keys())\n",
    "params_dict_partitioned = {system:{} for system in systems}\n",
    "for system in systems:\n",
    "    # print(systems_parameter_info['param_mapping'].keys())\n",
    "    # print(system)\n",
    "    # print(system in list(systems_parameter_info['param_mapping'].keys()))\n",
    "    params_sys = systems_parameter_info['param_mapping'][system]\n",
    "    params_sys_dict = {'DryPump':{},\n",
    "                       'Booster':{},\n",
    "                       'ExhaustAndShaft':{},\n",
    "                       'Flow':{},\n",
    "                       'RunTime':{},\n",
    "                       'Oil':{},\n",
    "                       'Others':{}}\n",
    "    for sys in params_sys.keys():\n",
    "        params_sys[sys] = params_sys[sys].replace(' ', '').replace('DP', 'DryPump').replace('MB', 'Booster')\n",
    "        if 'DP' in params_sys[sys] or 'Dry' in params_sys[sys]:\n",
    "            params_sys_dict['DryPump'][sys]=params_sys[sys]\n",
    "\n",
    "        elif 'Booster' in params_sys[sys] or 'MB' in params_sys[sys]:\n",
    "            params_sys_dict['Booster'][sys]=params_sys[sys]\n",
    "\n",
    "        elif 'Exhaust' in params_sys[sys] or 'Shaft' in params_sys[sys]:\n",
    "            params_sys_dict['ExhaustAndShaft'][sys]=params_sys[sys]\n",
    "\n",
    "        elif 'Time' in params_sys[sys] or 'Hours' in params_sys[sys]:\n",
    "            params_sys_dict['RunTime'][sys]=params_sys[sys]\n",
    "\n",
    "        elif 'Oil' in params_sys[sys]:\n",
    "            params_sys_dict['Oil'][sys]=params_sys[sys]\n",
    "            \n",
    "        elif 'Flow' in params_sys[sys]:\n",
    "            params_sys_dict['Flow'][sys]=params_sys[sys]\n",
    "\n",
    "        else:\n",
    "            params_sys_dict['Others'][sys]=params_sys[sys]\n",
    "    # for key in params_sys_dict.keys():\n",
    "    #     params_sys_dict[key].sort()\n",
    "    params_dict_partitioned[system] = params_sys_dict\n",
    "\n",
    "## Define directory paths ##\n",
    "\n",
    "AVAIL_FOLDER_PATH = os.path.join(MAIN_FOLDER_PATH, f'Availability')\n",
    "DATA_FOLDER_PATH = os.path.join(MAIN_FOLDER_PATH, 'Data')\n",
    "\n",
    "## Retrieve data for each system to store in parquet files ##\n",
    "\n",
    "systems_with_data = []\n",
    "systems_withou_data = []\n",
    "systems_param_mapping = {}\n",
    "for system in systems:\n",
    "    if not os.path.exists(DATA_FOLDER_PATH):\n",
    "        os.mkdir(DATA_FOLDER_PATH)\n",
    "    assert os.path.exists(DATA_FOLDER_PATH)\n",
    "    print(f'Retrieving data for {system}.')\n",
    "    system_parameters = list(systems_parameter_info['param_mapping'][f'{system}'].keys())\n",
    "#     print(f'Parameters: \\n{system_parameters}')\n",
    "\n",
    "    # Get systems data:\n",
    "\n",
    "    parameters_as_string = str(system_parameters).replace('[', '(').replace(']', ')')\n",
    "\n",
    "    system_data_query = (f'SELECT t3.[Description], t4.[zzDescription], t1.[ParameterId], t1.[LogTime], t1.[Value] \\\n",
    "                           FROM [dbo].[fst_GEN_ParameterValue] AS t1 \\\n",
    "                           INNER JOIN [dbo].[fst_GEN_Parameter] AS t2 \\\n",
    "                            ON t1.[ParameterId] = t2.[ParameterID] \\\n",
    "                           INNER JOIN [dbo].[fst_GEN_System] AS t3 \\\n",
    "                            ON t2.[SystemID] = t3.[SystemID] \\\n",
    "                           INNER JOIN [dbo].fst_GEN_ParameterType AS t4 \\\n",
    "                            ON t2.[SystemTypeID] = t4.[SystemTypeID] \\\n",
    "                            AND t2.[ParameterNumber] = t4.[ParameterNumber] \\\n",
    "                           WHERE t3.[Description] = \\'{str(system)}\\' \\\n",
    "                           AND t2.[ParameterNumber] in {parameters_as_string} \\\n",
    "                           ORDER BY t1.[LogTime]')\n",
    "    \n",
    "    warnings.filterwarnings('ignore')\n",
    "    system_data = pd.read_sql_query(system_data_query, con=db_connection)\n",
    "    warnings.resetwarnings()\n",
    "    \n",
    "    system_data['ParameterInfo'] = system_data['zzDescription'] + ' RID ' + system_data['ParameterId'].astype(str)\n",
    "\n",
    "    # Get system parameter mappings:\n",
    "\n",
    "    all_customer_systems_query = ('SELECT [SystemID], [SystemTypeID], [Description] '\n",
    "                                  'FROM [dbo].[fst_GEN_System] '\n",
    "                                  'ORDER BY [Description]')\n",
    "    warnings.filterwarnings('ignore')\n",
    "    all_customer_systems_res = pd.read_sql_query(all_customer_systems_query, con=db_connection)\n",
    "    warnings.resetwarnings()\n",
    "    \n",
    "    system_type_ids = all_customer_systems_res.loc[all_customer_systems_res.Description == system, 'SystemTypeID']\n",
    "\n",
    "    if len(system_type_ids) == 0:\n",
    "        print(f'{system} has not system type in the database {database}. Removing this system from the systems for which data will be retrieved.')\n",
    "        del systems[system]\n",
    "        continue\n",
    "    elif len(system_type_ids) > 1:\n",
    "        print(f'{system} has multiple system IDs - choosing {str(max(system_type_ids))}.')\n",
    "    system_type_id= max(system_type_ids.values)\n",
    "    \n",
    "    get_parameters_info_query = (f'SELECT DISTINCT a.[ParameterNumber], [zzDescription], [SIUnitID] \\\n",
    "                                 FROM fst_GEN_Parameter a \\\n",
    "                                 INNER JOIN fst_GEN_ParameterType b \\\n",
    "                                     ON a.[SystemTypeID] = b.SystemTypeID \\\n",
    "                                     AND a.[ParameterNumber] = b.[ParameterNumber] \\\n",
    "                                 WHERE b.[SystemTypeId] = {str(system_type_id)} \\\n",
    "                                 ORDER BY a.[ParameterNumber] ASC')\n",
    "    warnings.filterwarnings('ignore')\n",
    "    system_param_mapping = pd.read_sql_query(get_parameters_info_query, con=db_connection)\n",
    "    warnings.resetwarnings()\n",
    "    \n",
    "    systems_param_mapping[system] = dict(zip(system_param_mapping['ParameterNumber'].to_list(), system_param_mapping['zzDescription'].to_list()))\n",
    "\n",
    "    if system_data is not None:\n",
    "        file_path = os.path.join(DATA_FOLDER_PATH, system+'.parquet')\n",
    "        system_data.to_parquet(file_path, compression=None)\n",
    "        print(f'Data retrieved for {system}.')\n",
    "        systems_with_data.append(system)\n",
    "    \n",
    "    else:\n",
    "        print(f'There is no available data for {system}.')\n",
    "        systems_withou_data.append(system)\n",
    "    num_remaining_systems = len(systems) - (systems.index(system) + 1)\n",
    "    print(f\"{num_remaining_systems} systems remain to be processed.\")\n",
    "        \n",
    "for sys in systems_param_mapping.keys():\n",
    "    sys_param_nums = list(systems_param_mapping[sys].keys())\n",
    "    for part in params_dict_partitioned[sys].keys():\n",
    "        for param_num in params_dict_partitioned[sys][part].keys():\n",
    "            if param_num in sys_param_nums:\n",
    "                params_dict_partitioned[sys][part][param_num] = systems_param_mapping[sys][param_num].replace(' ', '')\n",
    "            else:\n",
    "                params_dict_partitioned[sys][part].pop([param_num])\n",
    "\n",
    "systems_in_dict = list(params_dict_partitioned.keys())\n",
    "for sys in systems_in_dict:\n",
    "    if sys not in systems_with_data:\n",
    "        params_dict_partitioned.pop(sys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation #\n",
    "\n",
    "DATA_FILES_DIR = DATA_FOLDER_PATH\n",
    "FIG_DIR = os.path.join(MAIN_FOLDER_PATH,'Figures')\n",
    "CSV_DIR = AVAIL_FOLDER_PATH\n",
    "if not os.path.exists(DATA_FOLDER_PATH):\n",
    "    os.mkdir(DATA_FOLDER_PATH)\n",
    "if not os.path.exists(FIG_DIR):\n",
    "    os.mkdir(FIG_DIR)\n",
    "if not os.path.exists(CSV_DIR):\n",
    "    os.mkdir(CSV_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('__package__', 16),\n",
       " ('__loader__', 16),\n",
       " ('__spec__', 16),\n",
       " ('system_data_dictionary', 16),\n",
       " ('systems_by_file', 24),\n",
       " ('conceal_params', 24),\n",
       " ('user_choice', 28),\n",
       " ('type_or_name_or_both', 28),\n",
       " ('separate_by_swap', 28),\n",
       " ('sep_and_whole', 28),\n",
       " ('separate_by_swap_or_not', 28),\n",
       " ('num_remaining_systems', 28),\n",
       " ('system_type_ids', 32),\n",
       " ('system_type_id', 32),\n",
       " ('exit', 48),\n",
       " ('quit', 48),\n",
       " ('print_function', 48),\n",
       " ('obj', 48),\n",
       " ('confirmation', 50),\n",
       " ('dash_view_or_all', 53),\n",
       " ('master_db', 55),\n",
       " ('systems_withou_data', 56),\n",
       " ('_i73', 56),\n",
       " ('_i77', 56),\n",
       " ('_i84', 56),\n",
       " ('_i95', 56),\n",
       " ('__name__', 57),\n",
       " ('date', 59),\n",
       " ('customer_account_name', 59),\n",
       " ('system', 59),\n",
       " ('system_name', 59),\n",
       " ('_i38', 60),\n",
       " ('_i39', 60),\n",
       " ('key', 61),\n",
       " ('name_of_system', 61),\n",
       " ('var', 63),\n",
       " ('_dh', 64),\n",
       " ('get_ipython', 64),\n",
       " ('_i32', 65),\n",
       " ('_i40', 71),\n",
       " ('__builtin__', 72),\n",
       " ('__builtins__', 72),\n",
       " ('os', 72),\n",
       " ('sys', 72),\n",
       " ('pd', 72),\n",
       " ('np', 72),\n",
       " ('datetime', 72),\n",
       " ('json', 72),\n",
       " ('pyodbc', 72),\n",
       " ('re', 72),\n",
       " ('types', 72),\n",
       " ('plotting', 72),\n",
       " ('layouts', 72),\n",
       " ('io', 72),\n",
       " ('models', 72),\n",
       " ('ceil', 72),\n",
       " ('math', 72),\n",
       " ('sm', 72),\n",
       " ('copy', 72),\n",
       " ('warnings', 72),\n",
       " ('_i76', 72),\n",
       " ('_i78', 73),\n",
       " ('database', 76),\n",
       " ('_i13', 76),\n",
       " ('_i88', 76),\n",
       " ('_i86', 77),\n",
       " ('_i87', 77),\n",
       " ('_i80', 78),\n",
       " ('_i85', 78),\n",
       " ('_i79', 79),\n",
       " ('_i82', 79),\n",
       " ('_i83', 79),\n",
       " ('_i81', 80),\n",
       " ('_i96', 82),\n",
       " ('_i41', 87),\n",
       " ('_i71', 87),\n",
       " ('_i12', 88),\n",
       " ('_i33', 93),\n",
       " ('_i42', 99),\n",
       " ('parameters_as_string', 102),\n",
       " ('_i34', 107),\n",
       " ('_i35', 107),\n",
       " ('__doc__', 113),\n",
       " ('_i70', 116),\n",
       " ('systems_with_data', 120),\n",
       " ('system_data', 124),\n",
       " ('_38', 124),\n",
       " ('_39', 124),\n",
       " ('_i72', 130),\n",
       " ('ROOT_PATH', 132),\n",
       " ('_i74', 136),\n",
       " ('_i91', 138),\n",
       " ('RESOURCES_PATH', 142),\n",
       " ('colored', 144),\n",
       " ('primefactors', 144),\n",
       " ('get_input', 144),\n",
       " ('isintable', 144),\n",
       " ('systems_from_csv', 144),\n",
       " ('get_system_names', 144),\n",
       " ('conceal_or_not', 144),\n",
       " ('plot_all_data_or_view', 144),\n",
       " ('get_parameters', 144),\n",
       " ('get_data_dir_contents', 144),\n",
       " ('plot_prep_from_parquet', 144),\n",
       " ('order_parameters', 144),\n",
       " ('moving_averages', 144),\n",
       " ('recursive_dict', 144),\n",
       " ('bokeh_plot_all_system_data', 144),\n",
       " ('ndarray_idx', 144),\n",
       " ('bokeh_plot_system_view', 144),\n",
       " ('interactive_plot_all_systems_data', 144),\n",
       " ('all_customer_systems_query', 148),\n",
       " ('get_databases_query', 171),\n",
       " ('system_parameters', 176),\n",
       " ('_i93', 203),\n",
       " ('_i17', 204),\n",
       " ('_i61', 204),\n",
       " ('json_file', 208),\n",
       " ('master_db_connection', 208),\n",
       " ('db_connection', 208),\n",
       " ('__', 232),\n",
       " ('login_details', 232),\n",
       " ('get_system_names_bool_args', 232),\n",
       " ('bokeh_system_data_plotters', 232),\n",
       " ('_40', 232),\n",
       " ('data_df', 232),\n",
       " ('_95', 232),\n",
       " ('_i68', 233),\n",
       " ('_i37', 237),\n",
       " ('_i36', 238),\n",
       " ('custom_views', 240),\n",
       " ('_i69', 243),\n",
       " ('_i75', 244),\n",
       " ('zipped', 248),\n",
       " ('_i20', 258),\n",
       " ('_i53', 258),\n",
       " ('_i64', 258),\n",
       " ('systems', 296),\n",
       " ('systems_to_check', 296),\n",
       " ('_iii', 303),\n",
       " ('_i97', 303),\n",
       " ('_12', 312),\n",
       " ('names_of_file', 312),\n",
       " ('_34', 312),\n",
       " ('names_of_files', 312),\n",
       " ('_35', 312),\n",
       " ('MAIN_FOLDER_PATH', 330),\n",
       " ('_i10', 330),\n",
       " ('_i100', 330),\n",
       " ('DATA_FOLDER_PATH', 345),\n",
       " ('DATA_FILES_DIR', 345),\n",
       " ('choices', 352),\n",
       " ('FIG_DIR', 354),\n",
       " ('_i90', 354),\n",
       " ('params_sys_dict', 360),\n",
       " ('systems_param_mapping', 360),\n",
       " ('_i24', 360),\n",
       " ('login_file_path', 363),\n",
       " ('_i92', 368),\n",
       " ('AVAIL_FOLDER_PATH', 369),\n",
       " ('CSV_DIR', 369),\n",
       " ('file_path', 402),\n",
       " ('dt', 408),\n",
       " ('defaultdict', 408),\n",
       " ('_i94', 437),\n",
       " ('get_parameters_info_query', 523),\n",
       " ('_i', 591),\n",
       " ('_i1', 591),\n",
       " ('_i99', 591),\n",
       " ('_i23', 656),\n",
       " ('_i25', 656),\n",
       " ('_i27', 656),\n",
       " ('_i29', 656),\n",
       " ('_i31', 656),\n",
       " ('_i44', 656),\n",
       " ('_i47', 656),\n",
       " ('_i48', 666),\n",
       " ('_i49', 666),\n",
       " ('_i56', 666),\n",
       " ('_i67', 666),\n",
       " ('_i89', 666),\n",
       " ('system_data_query', 910),\n",
       " ('_ih', 920),\n",
       " ('In', 920),\n",
       " ('_i11', 940),\n",
       " ('_i7', 968),\n",
       " ('local_vars', 968),\n",
       " ('sorted_vals_and_size', 968),\n",
       " ('_10', 968),\n",
       " ('_i8', 979),\n",
       " ('_i2', 1042),\n",
       " ('_i3', 1042),\n",
       " ('_i19', 1148),\n",
       " ('_i52', 1148),\n",
       " ('_i63', 1148),\n",
       " ('_oh', 1176),\n",
       " ('Out', 1176),\n",
       " ('systems_parameter_info', 1176),\n",
       " ('params_dict_partitioned', 1176),\n",
       " ('params_sys', 1176),\n",
       " ('_41', 1176),\n",
       " ('HoverTool', 1200),\n",
       " ('Div', 1200),\n",
       " ('_i6', 1221),\n",
       " ('system_param_mapping', 1479),\n",
       " ('_i16', 2544),\n",
       " ('_i60', 2544),\n",
       " ('_ii', 2674),\n",
       " ('_i98', 2674),\n",
       " ('customer_data_databases', 3250),\n",
       " ('_i15', 3295),\n",
       " ('_i59', 3295),\n",
       " ('vars_and_size', 4696),\n",
       " ('all_customer_systems_res', 5294),\n",
       " ('_i26', 5599),\n",
       " ('_i22', 5600),\n",
       " ('_i28', 5609),\n",
       " ('_i30', 5619),\n",
       " ('_i43', 5649),\n",
       " ('_i46', 5649),\n",
       " ('_i55', 5649),\n",
       " ('_i66', 5649),\n",
       " ('_i57', 7586),\n",
       " ('_i58', 7586),\n",
       " ('_i14', 7662),\n",
       " ('_i9', 9039),\n",
       " ('_i18', 9254),\n",
       " ('_i51', 9640),\n",
       " ('_i62', 9640),\n",
       " ('_i21', 10162),\n",
       " ('_i45', 10186),\n",
       " ('_i50', 10417),\n",
       " ('_i54', 10417),\n",
       " ('_i65', 10420),\n",
       " ('_i4', 15627),\n",
       " ('_i5', 15627),\n",
       " ('systems_info', 20143),\n",
       " ('_42', 18216424),\n",
       " ('_78', 22389960),\n",
       " ('_79', 22389960),\n",
       " ('_80', 22389960),\n",
       " ('_81', 22389960),\n",
       " ('_82', 22389960),\n",
       " ('_83', 22389960),\n",
       " ('_87', 22389960),\n",
       " ('_85', 44779904),\n",
       " ('___', 67169848),\n",
       " ('_86', 67169848),\n",
       " ('_88', 67169848),\n",
       " ('_', 974346192),\n",
       " ('_96', 974346192),\n",
       " ('_73', 1311242085),\n",
       " ('_77', 1947925144),\n",
       " ('_84', 1947925144)]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function  # for Python2\n",
    "import sys\n",
    "\n",
    "local_vars = list(locals().items())\n",
    "vars_and_size = {}\n",
    "for var, obj in local_vars:\n",
    "    vars_and_size[var]=sys.getsizeof(obj)\n",
    "\n",
    "sorted_vals_and_size=sorted(vars_and_size.items(), key=lambda x:x[1])\n",
    "sorted_vals_and_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var_and_size in sorted_vals_and_size[-10:]:\n",
    "    del locals()[var_and_size[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_dir_contents(data_files_dir, \n",
    "                          include_system_names_like=None):\n",
    "    \"\"\"\n",
    "    Retrieves the names of all the files (i.e. systems) in the data_files_dir directory and places them in a list.\n",
    "    \"\"\"\n",
    "    \n",
    "    files = os.listdir(data_files_dir)\n",
    "    if include_system_names_like != None:\n",
    "        if type(include_system_names_like)==str:\n",
    "            files = [file for file in files if include_system_names_like in file]\n",
    "\n",
    "        elif type(include_system_names_like)==list or type(include_system_names_like)==tuple:\n",
    "            files = [file for file in files if any(name_like in file for name_like in include_system_names_like)]\n",
    "\n",
    "        else:\n",
    "            raise TypeError(f\"The argument `include_system_names_like` does not take assignments of type {type(include_system_names_like)}. Please pass a string or list of strings to this argument.\")\n",
    "\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['KOXDL50100.parquet',\n",
       " 'KOXDL50100AC.parquet',\n",
       " 'KOXDL50100Ch A.parquet',\n",
       " 'KOXDL50100FC.parquet',\n",
       " 'KOXDL50100VI.parquet',\n",
       " 'KOXDL50200.parquet',\n",
       " 'KOXDL50200AC.parquet',\n",
       " 'KOXDL50200Ch A.parquet',\n",
       " 'KOXDL50200FC.parquet',\n",
       " 'KOXDL50200VI.parquet',\n",
       " 'KOXDL50300.parquet',\n",
       " 'KOXDL50300AC.parquet',\n",
       " 'KOXDL50300Ch A.parquet',\n",
       " 'KOXDL50300FC.parquet',\n",
       " 'KOXDL50300VI.parquet',\n",
       " 'KOXDL50400.parquet',\n",
       " 'KOXDL50400VI.parquet',\n",
       " 'KOXDL50500.parquet',\n",
       " 'KOXDL50500AC.parquet',\n",
       " 'KOXDL50500Ch A.parquet',\n",
       " 'KOXDL50500FC.parquet',\n",
       " 'KOXDL50500VI.parquet',\n",
       " 'KOXDL50600.parquet',\n",
       " 'KOXDL50600VI.parquet',\n",
       " 'KOXDL50700.parquet',\n",
       " 'KOXDL50700VI.parquet',\n",
       " 'KOXDL50800.parquet',\n",
       " 'KOXDL50800VI.parquet',\n",
       " 'KOXDL50900.parquet',\n",
       " 'KOXDL50900VI.parquet']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_data_dir_contents(DATA_FOLDER_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Prepare the data in the parquet files for plotting ##\n",
    "\n",
    "def plot_prep_from_parquet(data_files_dir, \n",
    "                           file_name, \n",
    "                           include_system_names_like=None):\n",
    "\n",
    "    \"\"\"\n",
    "    Prepares the data that has already been written to parquet files for plotting. In particular, \n",
    "    this function separates the data for each system by swap date. It does so by partitioning the\n",
    "    provisioned data by any columns whose name contains any of the following substrings:\n",
    "    ('Run Hours', 'Time')\n",
    "    \n",
    "    Inputs:\n",
    "    - data_files_dir (str): Full path or path from current working directory where the parquet files containing the system parametric data are stored.\n",
    "    \n",
    "    - include_system_names_like (str or list(str)): String or list of strings of the types of system names whose data we wish to  prepare. For instance, to prepare data for the systems that contain the substring 'iH1000' and 'iH2000', pass ['iH1000', 'iH2000']. DEFAULT is None and, in this case, all of the files in the provisioned directory are parsed.\n",
    "    \n",
    "    Outputs:\n",
    "    - all_systems_data: A dictionary containing the data for the specified types of system names (if any were passed) partitioned by swap dates (if any swaps occurred).\n",
    "    \n",
    "    NB: If a system does not have any columns with the substring 'Run Hours' or 'Time', the system will be assumed to not be a pump and therefore skipped. Its data will not appear in the output.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    system_data_dict = {}\n",
    "\n",
    "    # Get the system data and format correctly:\n",
    "\n",
    "    system_name = re.split(r'\\.', file_name)[0]\n",
    "    system_data = pd.read_parquet(os.path.join(data_files_dir, file_name))\n",
    "    print(f'Preparing the {system_name} data for plotting.')\n",
    "\n",
    "    # Convert DataFrame from long to wide format and sort by LogTime:\n",
    "\n",
    "    system_data = system_data.pivot_table(index='LogTime',\n",
    "                                          columns='ParameterInfo',\n",
    "                                          values='Value').sort_values(by='LogTime')\n",
    "\n",
    "    system_data = system_data.rename(columns={col_name:col_name.replace(' ', '') for col_name in system_data.columns})\n",
    "\n",
    "    system_data.sort_values(by='LogTime')\n",
    "\n",
    "    run_time_cols = list(set([col_name for col_name in system_data.columns \n",
    "                                                    if 'RunTime' in col_name\n",
    "                                                    or 'Hour' in col_name]))\n",
    "\n",
    "    print(f'Run Time Columns {run_time_cols}')\n",
    "\n",
    "    try:\n",
    "        assert len(run_time_cols) > 0\n",
    "        run_time_col = run_time_cols[0]\n",
    "        # system_data.rename({run_time_col:'RunHours'}, axis=1, inplace=True)\n",
    "\n",
    "    except:\n",
    "        # raise ValueError\n",
    "        print(f\"The system {system_name} does not have any parameters that include the strings `RunHours` nor `Time`. Therefore, it must not be a pump. Skipping.\")\n",
    "        return None, system_name\n",
    "\n",
    "    print(f'Data for system {system_name} retrieved.')\n",
    "\n",
    "    # Separate data by the swap number:\n",
    "\n",
    "    run_hours = system_data[[run_time_col]][~system_data[run_time_col].isna()]\n",
    "    run_hours_idx_list = list(run_hours.index)\n",
    "    first_datum_idx = run_hours.index.min()\n",
    "    first_datum_idx_num = run_hours_idx_list.index(first_datum_idx)\n",
    "    swap_dates = [first_datum_idx]\n",
    "    current_swap_num = 1\n",
    "\n",
    "    run_hours['system_num'] = current_swap_num\n",
    "    for idx_num in range(0, len(run_hours.index)-1):\n",
    "\n",
    "        if idx_num in [0]:\n",
    "            continue\n",
    "\n",
    "        condition_1 = abs(run_hours.iloc[idx_num][run_time_col] - run_hours.iloc[idx_num + 1][run_time_col]) > 30\n",
    "\n",
    "        # condition_2 ensures that the low difference in run_hours identified by condition_1 is \n",
    "        # not due to a break in incoming data\n",
    "\n",
    "        current_dt = run_hours.index[idx_num]\n",
    "        prev_dt = run_hours.index[idx_num-2]\n",
    "        try:\n",
    "            current_run_hrs = run_hours[run_time_col].loc[current_dt].iloc[0]\n",
    "        except:\n",
    "            try:\n",
    "                current_run_hrs = run_hours[run_time_col].loc[current_dt]\n",
    "            except:\n",
    "                print('wtf')\n",
    "\n",
    "        time_diff = ((run_hours.index[idx_num+1] - run_hours.index[idx_num])) + datetime.timedelta(hours=24)\n",
    "        hrs_diff = float((time_diff/np.timedelta64(1, 'h')))\n",
    "        future_dt = run_hours.index[idx_num] + time_diff\n",
    "        current_dt = run_hours.index[idx_num]\n",
    "        try:\n",
    "            current_run_hrs = run_hours.loc[current_dt].iloc[0]\n",
    "        except:\n",
    "            current_run_hrs = run_hours.loc[current_dt]\n",
    "        # print(run_hours.index[idx_num], run_hours.loc[run_hours.index[idx_num]]) \n",
    "        # print(run_hours.index[idx_num+1], run_hours.loc[run_hours.index[idx_num+1]])\n",
    "        # print(hrs_diff) \n",
    "        # print(future_dt, run_hours.loc[future_dt[0]-datetime.timedelta(hours=2):future_dt[0]])\n",
    "        local_future_run_hrs = run_hours.loc[current_dt:future_dt]\n",
    "        last_future_val = local_future_run_hrs.iloc[-1]\n",
    "        condition_2 = (current_run_hrs - last_future_val)[run_time_col] > hrs_diff\n",
    "\n",
    "        try:\n",
    "            if condition_1 and condition_2:\n",
    "                current_swap_num += 1\n",
    "                swap_dates.append(run_hours.index[idx_num+1])\n",
    "        except:\n",
    "            raise ValueError(f'condition_1: \\n{condition_1}\\n\\ncondition_2: \\n{condition_2}\\n\\ncurrent_run_hrs: \\n{current_run_hrs}\\n\\nlast_future_val: \\n{last_future_val}')\n",
    "\n",
    "        run_hours.loc[run_hours.index[idx_num], 'system_num'] = current_swap_num\n",
    "\n",
    "    run_hours['system_num'] = run_hours['system_num'].fillna(method='ffill').fillna(method='bfill')\n",
    "\n",
    "    print(f'Swap dates for system {system_name} isolated.')\n",
    "\n",
    "    system_data_dict[system_name] = {}\n",
    "\n",
    "    system_data_dict[system_name]['swap_dates'] = swap_dates\n",
    "\n",
    "    # Check if any swaps took place\n",
    "    if len(swap_dates) == 0:\n",
    "        system_data_dict[system_name]['system_1'] = system_data\n",
    "\n",
    "    elif len(swap_dates) == 1:\n",
    "        system_data_dict[system_name]['system_1'] = system_data[swap_dates[0]:]\n",
    "\n",
    "    elif len(swap_dates) > 1:\n",
    "        # Add the data, separated by swap number, into the system_data_all dictionary:\n",
    "        for swap_dt_idx in range(len(swap_dates)):\n",
    "            system_num = swap_dt_idx+1\n",
    "            swap_dt = swap_dates[swap_dt_idx]\n",
    "            if swap_dt_idx == len(swap_dates)-1:\n",
    "                system_data_dict[system_name][f\"system_{system_num}\"] = system_data[swap_dt:]\n",
    "            else:\n",
    "                next_swap_dt = swap_dates[swap_dt_idx+1]\n",
    "                system_data_dict[system_name][f\"system_{system_num}\"] = system_data[swap_dt:next_swap_dt]\n",
    "\n",
    "        if system_data_dict[system_name]['swap_dates'][0] == system_data_dict[system_name]['swap_dates'][1]:\n",
    "            del system_data_dict[system_name]['swap_dates'][0]\n",
    "            system_key_nums = [key for key in system_data_dict[system_name].keys() if key!='swap_dates']\n",
    "            for p_num in range(1,len(system_key_nums)):\n",
    "                new_key = f'system_{p_num}'\n",
    "                old_key = f'system_{p_num+1}'\n",
    "                system_data_dict[system_name][new_key] = system_data_dict[system_name][old_key]\n",
    "                del system_data_dict[system_name][old_key]\n",
    "\n",
    "    print(f'Data for system {system_name} partitioned by swap date.')\n",
    "\n",
    "#         print(f'System swap dates: {all_systems_data[system_name][\"swap_dates\"]}')\n",
    "\n",
    "    print(f\"Data for {system_name} prepared for plotting!\")\n",
    "\n",
    "#     if len(all_systems_data) > 0:\n",
    "#         print(f\"\\n\\nData retrieved and prepared for the following systems: \")\n",
    "#         for system in all_systems_data.keys():\n",
    "#             print(system)\n",
    "    \n",
    "#     else:\n",
    "#         print('No data found for the specified systems.')\n",
    "    \n",
    "    return system_data_dict, system_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define a function to partition parameters into type of process\n",
    "\n",
    "def order_parameters(data, cols, conceal_params=False):\n",
    "    \n",
    "    '''\n",
    "    The function:\n",
    "    1. Separates the parameters into groups \n",
    "    2. Changes the units of columns with temperature, pressure and flow from Kelvin, Pa and m^3/s to degrees Celcius, PSI and liters/minute, respectively.\n",
    "    All of this is then used for columnar plotting by the function `interactive_plot_custom_data_1`.'''\n",
    "    parameters_ordered = {'DryPump (DP)':[],\n",
    "                          'Booster (MB)':[],\n",
    "                          'ExhaustAndShaft (ES)':[],\n",
    "                          'RunTime (RT)':[],\n",
    "                          'Oil (OL)':[],\n",
    "                          'Flow (FW)':[],\n",
    "                          'Motor (MR)':[],\n",
    "                          'Vibration (VR)':[],\n",
    "                          'Pos (PS)':[],\n",
    "                          'MagneticBearing (MC)':[],\n",
    "                          'MiscellaneousTemperatures (MT)':[],\n",
    "                          'Other (OT)':[]}\n",
    "    \n",
    "    data = data.rename(columns={col:col.replace(' ', '').replace('DP', 'DryPump').replace('MB', 'Booster') for col in data.columns})\n",
    "    \n",
    "    for column in data.columns:\n",
    "        if ('Dry' in column or 'DP' in column) and ('Hours' not in column and 'Time' not in column):\n",
    "            parameters_ordered['DryPump (DP)'].append(column)\n",
    "        elif 'Booster' in column or 'MB' in column:\n",
    "            parameters_ordered['Booster (MB)'].append(column)\n",
    "        elif 'Exhaust' in column or 'Shaft' in column:\n",
    "            parameters_ordered['ExhaustAndShaft (ES)'].append(column)\n",
    "        elif 'Oil' in column:\n",
    "            parameters_ordered['Oil (OL)'].append(column)\n",
    "        elif 'Hour' in column or 'Time' in column:\n",
    "            parameters_ordered['RunTime (RT)'].append(column)\n",
    "        elif 'Flow' in column:\n",
    "            parameters_ordered['Flow (FW)'].append(column)\n",
    "        elif 'Motor' in column:\n",
    "            parameters_ordered['Motor (MR)'].append(column)\n",
    "        elif 'Vib' in column:\n",
    "            parameters_ordered['Vibration (VR)'].append(column)\n",
    "        elif 'Pos' in column:\n",
    "            parameters_ordered['Pos (PS)'].append(column)\n",
    "        elif 'Magnetic' in column:\n",
    "            parameters_ordered['MagneticBearing (MC)'].append(column)\n",
    "        elif 'Temperature' in column:\n",
    "            parameters_ordered['MiscellaneousTemperatures (MT)'].append(column)\n",
    "        else:\n",
    "            parameters_ordered['Other (OT)'].append(column)\n",
    "        \n",
    "        if 'temp' in column.lower():\n",
    "            data[column] = data[column] - 273.15\n",
    "        elif 'pressure' in column.lower():\n",
    "            data[column] = data[column] * 0.000145038\n",
    "        elif 'flow' in column.lower():\n",
    "            data[column] = data[column] * 60000\n",
    "    \n",
    "    parameters_ordered_concealed = {}\n",
    "    \n",
    "    for key in parameters_ordered.keys():\n",
    "        parameters_ordered[key].sort()\n",
    "        left_idx = key.index('(')+1\n",
    "        right_idx = key.index(')')\n",
    "        concealed_key = key[left_idx:right_idx]\n",
    "        parameters_ordered_concealed[concealed_key] = parameters_ordered[key]\n",
    "    \n",
    "    if cols==None:\n",
    "        cols = data.columns\n",
    "        \n",
    "    if conceal_params:\n",
    "        return parameters_ordered_concealed, data\n",
    "    else:\n",
    "        return parameters_ordered, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define a function to compute sma and ewma for each parameter passed\n",
    "\n",
    "def moving_averages(data, \n",
    "                    current_parameter, \n",
    "                    run_time_data=False,\n",
    "                    ewma_span=None,\n",
    "                    ewma_com=None,\n",
    "                    ewma_halflife=None,\n",
    "                    ewma_alpha=None,\n",
    "                    ewma_min_periods=None,\n",
    "                    ewma_adjust=True,\n",
    "                    ewma_ignore_na=False,\n",
    "                    resampling_frequency='12H',\n",
    "                    rolling_period='14D'):\n",
    "\n",
    "    if not run_time_data:\n",
    "        start_date = data.index.min()\n",
    "        end_date = data.index.max()\n",
    "        data = data.loc[~data.index.duplicated()]\n",
    "        old_data = data.copy()\n",
    "        try:\n",
    "            new_index = pd.date_range(start=start_date,\n",
    "                                      end=end_date,\n",
    "                                      freq=resampling_frequency)\n",
    "        except:\n",
    "            print(start_date)\n",
    "            print(end_date)\n",
    "            raise ValueError\n",
    "        smoothed_data = data[data.notna()].reindex(new_index, method='ffill')\n",
    "        smoothed_data.index.name='LogTime'\n",
    "        col_data_df = pd.DataFrame(smoothed_data)\n",
    "\n",
    "        # Simple Moving Average:\n",
    "        sma_parameter = f'{current_parameter}_SimpleMovingAverage'\n",
    "        sma_col_data = col_data_df[current_parameter].rolling(rolling_period).mean()\n",
    "        col_data_df[sma_parameter] = sma_col_data\n",
    "\n",
    "        # Exponentially Weighted Moving Average:\n",
    "        ewma_parameter = f'{current_parameter}_ExpontentiallyWeightedMovingAverage'\n",
    "        ewma_col_data = col_data_df[current_parameter].ewm(span=ewma_span,\n",
    "                                                           com=ewma_com,\n",
    "                                                           halflife=ewma_halflife,\n",
    "                                                           alpha=ewma_alpha,\n",
    "                                                           min_periods=ewma_min_periods,\n",
    "                                                           adjust=ewma_adjust,\n",
    "                                                           ignore_na=ewma_ignore_na).mean()\n",
    "        col_data_df[ewma_parameter] = ewma_col_data\n",
    "        col_data_df = col_data_df.reindex(old_data.index, \n",
    "                                          method='ffill')\n",
    "        try:\n",
    "            col_data_df[current_parameter] = old_data\n",
    "        except:\n",
    "            try:\n",
    "                col_data_df[current_parameter] = old_data[current_parameter]\n",
    "            except:\n",
    "                pass\n",
    "                raise ValueError(\"There's a problem.\")\n",
    "        \n",
    "        return col_data_df, sma_parameter, ewma_parameter\n",
    "    \n",
    "    else:\n",
    "        col_data_df = pd.DataFrame(data[data.notna()])\n",
    "        return col_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define funtion to create arbitrarily deep dictionaries\n",
    "\n",
    "from collections import defaultdict\n",
    "def recursive_dict():\n",
    "    return defaultdict(recursive_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create dashboards ##\n",
    "\n",
    "def bokeh_plot_all_system_data(data,\n",
    "                             save_dest,\n",
    "                             system,\n",
    "                             system_position,\n",
    "                             customer_name,\n",
    "                             cols=None,\n",
    "                             save=True,\n",
    "                             show_plots=False,\n",
    "                             conceal_params=False):\n",
    "    \n",
    "    \n",
    "    start_datetime = data.index.min().strftime('%d/%m/%Y %H:%M:%S')\n",
    "\n",
    "    end_datetime = data.index.max().strftime('%d/%m/%Y %H:%M:%S')\n",
    "    \n",
    "    system_name = f\"{system_position}: {system.capitalize().replace('_', ' ')}, Start Date-Time: {start_datetime}, End Date-Time: {end_datetime}\"\n",
    "\n",
    "    parameters_ordered, data = order_parameters(data, cols, conceal_params=conceal_params)\n",
    "    \n",
    "    parts_plots = {}\n",
    "    count = 0\n",
    "    for i in parameters_ordered.keys():\n",
    "        # print(f'\\npart parames before anything: \\n{parameters_ordered}')\n",
    "        # parameters_ordered[i] = [parameters_ordered[i][j] for j in parameters_ordered[i] if j in data.columns]\n",
    "        # print(f'\\npart params after checking against data columns: \\n{parameters_ordered}')\n",
    "        part_data = data[parameters_ordered[i]]\n",
    "#         return part_data\n",
    "        part_data = part_data.rename({col:col.replace(' ', '') for col in part_data.columns}, axis=1)\n",
    "        parameters_ordered[i] = [param.replace(' ', '') for param in parameters_ordered[i]]\n",
    "        parts_plots[i] = []\n",
    "        # print(parameters_ordered)\n",
    "        for j in range(len(parameters_ordered[i])):\n",
    "            col_data = part_data[parameters_ordered[i][j]]\n",
    "            # print(type(col_data))\n",
    "            if col_data.notna().sum() < 1:\n",
    "                continue\n",
    "            elif col_data.notna().sum() < 15:\n",
    "                radius_size=3\n",
    "            else:\n",
    "                radius_size=0.8\n",
    "            current_parameter = parameters_ordered[i][j]\n",
    "            \n",
    "\n",
    "\n",
    "            col_data = col_data[col_data.notna()]\n",
    "            \n",
    "            if 'RT' not in i:\n",
    "                col_data_df, sma_parameter, ewma_parameter = moving_averages(col_data, \n",
    "                                                                         current_parameter=current_parameter,\n",
    "                                                                         run_time_data=False,\n",
    "                                                                         rolling_period='14D',\n",
    "                                                                         ewma_alpha=0.15,\n",
    "                                                                         ewma_adjust=False)\n",
    "                if conceal_params:\n",
    "#                     print('concealing parameter')\n",
    "                    left_raw_idx = current_parameter.index('RID')\n",
    "                    left_sma_idx = sma_parameter.index('RID')\n",
    "                    left_ewma_idx = ewma_parameter.index('RID')\n",
    "                    raw_label = f'{customer_name}_{current_parameter[left_raw_idx:]}'\n",
    "                    sma_label = f'{customer_name}_{sma_parameter[left_sma_idx:]}'\n",
    "                    ewma_label = f'{customer_name}_{ewma_parameter[left_ewma_idx:]}'\n",
    "#                     print(raw_label, sma_label, ewma_label, sep='\\n')\n",
    "                    \n",
    "                else:\n",
    "#                     print('not concealing parameter')\n",
    "                    raw_label = current_parameter\n",
    "                    sma_label = sma_parameter\n",
    "                    ewma_label = ewma_parameter\n",
    "#                     print(raw_label, sma_label, ewma_label, sep='\\n')\n",
    "                \n",
    "                source = plotting.ColumnDataSource(col_data_df)\n",
    "\n",
    "                # Create interactive hovertool\n",
    "                fig_hover_tool = HoverTool(tooltips=[('LogTime', '@LogTime{%Y-%m-%d %H:%M:%S.%3N}'),\n",
    "                                                    (f'{raw_label}', f'@{current_parameter}'),\n",
    "                                                    (f'{sma_label}', f'@{sma_parameter}'),\n",
    "                                                    (f'{ewma_label}', f'@{sma_parameter}')],\n",
    "                                           formatters={'@LogTime':'datetime'},\n",
    "                                           mode='mouse')    \n",
    "\n",
    "            else:\n",
    "                col_data_df = moving_averages(col_data,\n",
    "                                              current_parameter=current_parameter,\n",
    "                                              run_time_data=True,\n",
    "                                              rolling_period='14D',\n",
    "                                              ewma_alpha=0.15,\n",
    "                                              ewma_adjust=False)\n",
    "                source = plotting.ColumnDataSource(col_data_df)\n",
    "                raw_label = current_parameter\n",
    "                # Create interactive hovertool\n",
    "                fig_hover_tool = HoverTool(tooltips=[('LogTime', '@LogTime{%Y-%m-%d %H:%M:%S.%3N}'),\n",
    "                                                    (f'{raw_label}', f'@{current_parameter}')],\n",
    "                                           formatters={'@LogTime':'datetime'},\n",
    "                                           mode='mouse')\n",
    "            \n",
    "            if count > 0:\n",
    "                fig = plotting.figure(x_axis_label='DateTime',\n",
    "                                      y_axis_label=raw_label,\n",
    "                                      x_range=shared_x_range,\n",
    "                                      x_axis_type='datetime',\n",
    "                                      title=raw_label)\n",
    "                # print(f'\\n\\nData plotted for {system_position} {system} {i}:{j}')\n",
    "            \n",
    "            else:\n",
    "                fig = plotting.figure(x_axis_label='DateTime',\n",
    "                                      y_axis_label=raw_label,\n",
    "                                      x_axis_type='datetime',\n",
    "                                      title=raw_label)\n",
    "                # print(f'\\n\\nData plotted for {system_position} {system} {i}:{j}')\n",
    "            \n",
    "            if count == 0:\n",
    "                count += 1\n",
    "                shared_x_range = fig.x_range\n",
    "\n",
    "            fig.line(x='LogTime', \n",
    "                     y=current_parameter, \n",
    "                     source=source, \n",
    "                     color='#47ed00',\n",
    "                     line_alpha=0.7,\n",
    "                     muted_alpha=0.2,\n",
    "                     legend_label=raw_label)\n",
    "            \n",
    "            fig.add_tools(fig_hover_tool)\n",
    "            \n",
    "            if 'RT' not in i:\n",
    "                fig.line(x='LogTime',\n",
    "                        y=sma_parameter,\n",
    "                        source=source,\n",
    "                        color='red',\n",
    "                        line_alpha=1,\n",
    "                        muted_alpha=0.1,\n",
    "                        legend_label=sma_label)\n",
    "\n",
    "                fig.line(x='LogTime',\n",
    "                        y=ewma_parameter,\n",
    "                        source=source,\n",
    "                        color='blue',\n",
    "                        line_alpha=1,\n",
    "                        muted_alpha=0.2,\n",
    "                        legend_label=ewma_label)\n",
    "\n",
    "            fig.circle(x='LogTime',\n",
    "                       y=current_parameter,\n",
    "                       source=source,\n",
    "                       color='green',\n",
    "                       radius=radius_size)\n",
    "            \n",
    "            fig.title.text_font_size = '12pt'\n",
    "\n",
    "            fig.xaxis.major_label_orientation = math.pi/4\n",
    "\n",
    "            fig.axis.axis_label_text_font_size = '10px'\n",
    "\n",
    "            fig.legend.title = 'Legend'\n",
    "\n",
    "            fig.legend.title_text_font_size = '12pt'\n",
    "\n",
    "            fig.legend.title_text_font_style = 'italic'\n",
    "\n",
    "            fig.legend.title_text_color = 'white'\n",
    "\n",
    "            fig.legend.location = 'top_left'\n",
    "\n",
    "            fig.legend.border_line_alpha = 1\n",
    "\n",
    "            fig.legend.border_line_color = 'black'\n",
    "\n",
    "            fig.legend.background_fill_alpha = 0.7\n",
    "\n",
    "            fig.legend.background_fill_color = 'grey'\n",
    "\n",
    "            fig.legend.click_policy = 'hide'\n",
    "\n",
    "            fig.legend.label_text_font_size = '12pt'\n",
    "\n",
    "            fig.legend.label_text_font_style = 'italic'\n",
    "\n",
    "            fig.legend.label_text_color = 'white'\n",
    "            \n",
    "            # fig.add_layout(fig.legend[0], 'right')\n",
    "\n",
    "            parts_plots[i].append(fig)\n",
    "    \n",
    "    \n",
    "    plot_title = Div(text=f\"{system_name}\",\n",
    "                     style={'font-size':'30px', 'color':'black'}) #, style={'font-size':'300%', \n",
    "                                            #       'color':'black', \n",
    "                                            #       'text-align':'center', \n",
    "                                            #       'margin':'auto'})\n",
    "    \n",
    "    plot_columns = []\n",
    "    for key in parts_plots.keys():\n",
    "        if len(parts_plots[key]) > 0:\n",
    "            part_name = Div(text=f'{key} Parameters',\n",
    "                            style={'font-size':'22px', 'color':'black'})\n",
    "            plot_columns.append(layouts.column(part_name, layouts.column(parts_plots[key])))\n",
    "        \n",
    "    system_figure_dir = os.path.join(save_dest, system_position)\n",
    "    \n",
    "    if not os.path.exists(system_figure_dir):\n",
    "        os.makedirs(system_figure_dir)\n",
    "        assert os.path.exists(system_figure_dir)\n",
    "    \n",
    "    if conceal_params:\n",
    "        output_file_name = os.path.join(system_figure_dir, f\"{system_position}_{system}_concealed_parameters.html\")\n",
    "    else:\n",
    "        output_file_name = os.path.join(system_figure_dir, f\"{system_position}_{system}.html\")\n",
    "    \n",
    "    if save:\n",
    "        io.output_file(output_file_name)\n",
    "        \n",
    "        plotting.save(layouts.column(plot_title,\n",
    "                                     layouts.row(plot_columns)))\n",
    "        \n",
    "    if show_plots:\n",
    "        io.show(layouts.column(plot_title,\n",
    "                                     layouts.row(plot_columns)))\n",
    "        \n",
    "bokeh_system_data_plotters = {}\n",
    "bokeh_system_data_plotters['all']=bokeh_plot_all_system_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of numpy arrays where each array contains the rows of the desired dashboard view spec\n",
    "\n",
    "custom_views = recursive_dict()\n",
    "custom_views['view_1'] = np.array([['BoosterPower', 'DryPumpPower', 'ExhaustPressure'],\n",
    "                          ['BoosterSpeed', 'DryPumpSpeed', 'DryPumpInternalTemp'],\n",
    "                          ['BoosterTemp', 'DryPumpHVTemp', 'DryPumpEndCoverTemp']]).T\n",
    "custom_views['view_2'] = np.array([['BoosterPower', 'DryPumpPower', 'ExhaustPressure', 'ExhaustPressure'],\n",
    "                          ['BoosterSpeed', 'DryPumpSpeed', 'RunHours', 'N2Flow'],\n",
    "                          ['BoosterTemp', 'DryPumpHVTemp', 'DryPumpEndCoverTemp', 'DryPumpInternalTemp'],\n",
    "                          ['VI1', 'VI2', 'VI3', 'VI4']]).T\n",
    "custom_views['view_3'] = np.array([['BoosterPower', 'DryPumpPower', 'ExhaustPressure', 'ExhaustPressure'],\n",
    "                          ['BoosterSpeed', 'DryPumpSpeed', 'RunHours', 'N2Flow'],\n",
    "                          ['BoosterTemp', 'DryPumpInternalTemp', 'DryPumpHVTemp', 'DryPumpEndCoverTemp'],\n",
    "                          ['VI1', 'VI2', 'VI3', 'VI4']]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to return the index of an item in an arbitrarily nested array\n",
    "\n",
    "def ndarray_idx(array, item):\n",
    "    for idx, val in np.ndenumerate(array):\n",
    "        if array[idx] == item:\n",
    "            return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bokeh_plot_system_view(data,\n",
    "                           system,\n",
    "                           system_position,\n",
    "                           customer_name,\n",
    "                           save_dest,\n",
    "                           views_array,\n",
    "                           view_to_use='view_1',\n",
    "                           cols=None,\n",
    "                           save=True,\n",
    "                           show_plots=False,\n",
    "                           conceal_params=False):\n",
    "    \n",
    "    data = data.rename({col:col.replace(' ', '') for col in data.columns}, axis=1)\n",
    "    \n",
    "    data.index.name = 'LogTime'\n",
    "    \n",
    "    start_datetime = data.index.min().strftime('%d/%m/%Y %H:%M:%S')\n",
    "\n",
    "    end_datetime = data.index.max().strftime('%d/%m/%Y %H:%M:%S')\n",
    "    \n",
    "    dash_title = f\"{system_position}: {system.capitalize().replace('_', ' ')}, {view_to_use} Start Date-Time: {start_datetime}, End Date-Time: {end_datetime}\"\n",
    "    \n",
    "    view = views_array[view_to_use]\n",
    "    \n",
    "    dashboard_dimensions = view.shape\n",
    "    \n",
    "    parts_plots = [[] for i in range(dashboard_dimensions[0])] # Initialise a list of n rows where n is the number of rows in `view`\n",
    "    \n",
    "    non_empty_plot_count = 0\n",
    "    \n",
    "    for param_idx, param in np.ndenumerate(view):\n",
    "        \n",
    "        param_row_idx=param_idx[0]\n",
    "        \n",
    "        # Find parameter in data\n",
    "        \n",
    "        if param!='RunHours':\n",
    "            param_to_seek = copy.deepcopy(param)\n",
    "            param_to_seek_alt = param_to_seek.replace('Booster', 'MB').replace('DryPump', 'DP')\n",
    "        \n",
    "        else:\n",
    "            param_to_seek = 'Hour'\n",
    "            param_to_seek_alt = 'RunTime'\n",
    "            \n",
    "        param_data = data.filter(regex=f\"({param_to_seek})|({param_to_seek_alt})\")\n",
    "        \n",
    "        # Ensure there is data to plot\n",
    "        try:\n",
    "            assert len(param_data.columns) > 0\n",
    "            param_col = param_data.columns[0]\n",
    "            assert len(param_data[param_data[param_col].notna()]) > 0\n",
    "        except:\n",
    "            print(f\"There is no {param} data for {system}.\")\n",
    "            if conceal_params:\n",
    "                empty_fig_title = 'unavailable_parameter'\n",
    "            else:\n",
    "                empty_fig_title = f'unavailable_parameter_{param}'\n",
    "            \n",
    "            if sum(param_idx) > 0:\n",
    "            \n",
    "                empty_fig = plotting.figure(x_axis_label='DateTime',\n",
    "                                            y_axis_label=param,\n",
    "                                            x_axis_type='datetime',\n",
    "                                            title=empty_fig_title)\n",
    "            else:\n",
    "                empty_fig = plotting.figure(x_axis_label='DateTime',\n",
    "                                            y_axis_label=param,\n",
    "                                            x_axis_type='datetime',\n",
    "                                            title=empty_fig_title)\n",
    "            \n",
    "            parts_plots[param_row_idx].append(empty_fig)\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            param_col = param_data.columns[0]\n",
    "        except:\n",
    "            print(f\"ran into problem with {system} {system_position}, {param_to_seek}\")\n",
    "            print(param_data)\n",
    "                \n",
    "        param_data = param_data[param_data[param_col].notna()]\n",
    "        \n",
    "        # Check if this is a run hours parameter\n",
    "        if 'Hour' in param or 'RunTime' in param:\n",
    "            # Just data will be plotted if the parameter is a run hours parameter\n",
    "            print(f'The RunHours parameter is {param_col}')\n",
    "            param_df = pd.DataFrame(param_data)\n",
    "            source = plotting.ColumnDataSource(param_df)\n",
    "            raw_label = param_col\n",
    "            print(f\"The names of the columns of the column data source are {source.column_names}\")\n",
    "            fig_hover_tool = HoverTool(tooltips=[('LogTime', '@LogTime{%Y-%m-%d %H:%M:%S.%3N}'),\n",
    "                                                (f'{raw_label}', f'@{param_col}')],\n",
    "                                       formatters={'@LogTime':'datetime'},\n",
    "                                       mode='mouse')\n",
    "        else:\n",
    "            # Otherwise, compute SMA and EWMA\n",
    "            try:\n",
    "                param_df, sma_parameter, ewma_parameter = moving_averages(param_data,\n",
    "                                                                          current_parameter=param_col,\n",
    "                                                                          run_time_data=False,\n",
    "                                                                          rolling_period='14D',\n",
    "                                                                          ewma_alpha=0.5,\n",
    "                                                                          ewma_adjust=False)\n",
    "            except:\n",
    "                print(system)\n",
    "                print(system_position)\n",
    "                print(param)\n",
    "                print(param_col)\n",
    "                print(param_df)\n",
    "                raise ValueError\n",
    "            \n",
    "            # Check if concealment has been requested\n",
    "            if conceal_params:\n",
    "                # If so, conceal parameter names and set the result to `_label` variables\n",
    "                left_raw_idx = param_col.index('RID')\n",
    "                left_sma_idx = sma_parameter.index('RID')\n",
    "                left_ewma_idx = ewma_parameter.index('RID')\n",
    "                raw_label = f\"{customer_name}_{param_col[left_raw_idx:]}\"\n",
    "                sma_label = f\"{customer_name}_{sma_parameter[left_sma_idx:]}\"\n",
    "                ewma_label = f\"{customer_name}_{ewma_parameter[left_ewma_idx:]}\"\n",
    "                \n",
    "            else:\n",
    "                # Otherwise, set the labels to be the same as the parameter names\n",
    "                raw_label = param_col\n",
    "                sma_label = sma_parameter\n",
    "                ewma_label = ewma_parameter\n",
    "            \n",
    "            # Create a Bokeh ColumnDataSource object from the data\n",
    "            source = plotting.ColumnDataSource(param_df)\n",
    "            \n",
    "            # Create interactive hovertool\n",
    "            fig_hover_tool = HoverTool(tooltips=[('LogTime', '@LogTime{%Y-%m-%d %H:%M:%S.%3N}'),\n",
    "                                                (f'{raw_label}', f'@{param_col}'),\n",
    "                                                (f'{sma_label}', f'@{sma_parameter}'),\n",
    "                                                (f'{ewma_label}', f'@{sma_parameter}')],\n",
    "                                       formatters={'@LogTime':'datetime'},\n",
    "                                       mode='mouse')\n",
    "\n",
    "        # Initialise figure\n",
    "\n",
    "        if non_empty_plot_count > 0:\n",
    "            # If this is not the first figure, use the shared_x_range\n",
    "            fig = plotting.figure(x_axis_label='DateTime',\n",
    "                                  y_axis_label=raw_label,\n",
    "                                  x_range=shared_x_range,\n",
    "                                  x_axis_type='datetime',\n",
    "                                  title=raw_label)\n",
    "        else:\n",
    "            # Otherwise, allow the figure to default to the x_range required to plot the data\n",
    "            fig = plotting.figure(x_axis_label='DateTime',\n",
    "                                  y_axis_label=raw_label,\n",
    "                                  x_axis_type='datetime',\n",
    "                                  title=raw_label)\n",
    "\n",
    "        # Add objects to figure\n",
    "        fig.line(x='LogTime', \n",
    "                 y=param_col,\n",
    "                 source=source,\n",
    "                 color='#47ed00',\n",
    "                 line_alpha=0.7,\n",
    "                 muted_alpha=0.2,\n",
    "                 legend_label=raw_label)\n",
    "        \n",
    "        fig.add_tools(fig_hover_tool)\n",
    "        \n",
    "        if 'Hour' in param or 'RunTime' in param:\n",
    "            pass\n",
    "        else:\n",
    "            # If this is not a run hours parameter, plot the sma and ewma\n",
    "            fig.line(x='LogTime',\n",
    "                     y=sma_parameter,\n",
    "                     source=source,\n",
    "                     color='red',\n",
    "                     line_alpha=1,\n",
    "                     muted_alpha=0.1,\n",
    "                     legend_label=sma_label)\n",
    "\n",
    "            fig.line(x='LogTime',\n",
    "                     y=ewma_parameter,\n",
    "                     source=source,\n",
    "                     color='blue',\n",
    "                     line_alpha=1,\n",
    "                     muted_alpha=0.2,\n",
    "                     legend_label=ewma_label)\n",
    "\n",
    "        # If this is the first non-empty plot \n",
    "        if non_empty_plot_count == 0:\n",
    "            shared_x_range = fig.x_range\n",
    "            non_empty_plot_count+=1\n",
    "            \n",
    "        # Modify figure appearance\n",
    "        \n",
    "        fig.title.text_font_size = '12pt'\n",
    "\n",
    "        fig.xaxis.major_label_orientation = math.pi/4\n",
    "\n",
    "        fig.axis.axis_label_text_font_size = '10px'\n",
    "\n",
    "        fig.legend.title = 'Legend'\n",
    "\n",
    "        fig.legend.title_text_font_size = '12pt'\n",
    "\n",
    "        fig.legend.title_text_font_style = 'italic'\n",
    "\n",
    "        fig.legend.title_text_color = 'white'\n",
    "\n",
    "        fig.legend.location = 'top_left'\n",
    "\n",
    "        fig.legend.border_line_alpha = 1\n",
    "\n",
    "        fig.legend.border_line_color = 'black'\n",
    "\n",
    "        fig.legend.background_fill_alpha = 0.7\n",
    "\n",
    "        fig.legend.background_fill_color = 'grey'\n",
    "\n",
    "        fig.legend.click_policy = 'hide'\n",
    "\n",
    "        fig.legend.label_text_font_size = '12pt'\n",
    "\n",
    "        fig.legend.label_text_font_style = 'italic'\n",
    "\n",
    "        fig.legend.label_text_color = 'white'\n",
    "\n",
    "        # Save x_range if this is the first figure\n",
    "\n",
    "        if sum(param_idx) == 0:\n",
    "            shared_x_range = fig.x_range\n",
    "\n",
    "        # Add plot to the correct row in the parts_plots list\n",
    "            \n",
    "        parts_plots[param_row_idx].append(fig)\n",
    "    \n",
    "    dashboard_title = Div(text=f\"{dash_title}\",\n",
    "                          style={'font-size':'30px', 'color':'black'})\n",
    "    \n",
    "    dashboard_rows = []\n",
    "    for dash_row_idx in range(len(parts_plots)):\n",
    "        dash_row = layouts.row(parts_plots[dash_row_idx])\n",
    "        dashboard_rows.append(dash_row)\n",
    "    \n",
    "    system_figure_dir = os.path.join(save_dest, system_position)\n",
    "    \n",
    "    if not os.path.exists(system_figure_dir):\n",
    "        os.makedirs(system_figure_dir)\n",
    "        assert os.path.exists(system_figure_dir)\n",
    "    \n",
    "    if conceal_params:\n",
    "        output_file_name = os.path.join(system_figure_dir, f\"{system_position}_{system}_{view_to_use}_concealed_params.html\")\n",
    "    else:\n",
    "        output_file_name = os.path.join(system_figure_dir, f\"{system_position}_{system}_{view_to_use}.html\")\n",
    "        \n",
    "    \n",
    "    if save:\n",
    "        io.output_file(output_file_name)\n",
    "        plotting.save(layouts.column(dashboard_title, layouts.column(dashboard_rows)))\n",
    "        \n",
    "    if show_plots:\n",
    "        io.show(layouts.column(plot_title, layouts.column(dashboard_rows)))\n",
    "\n",
    "bokeh_system_data_plotters['view']=bokeh_plot_system_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def interactive_plot_all_systems_data(data_files_dir,\n",
    "                                      save_dest,\n",
    "                                      customer_name,\n",
    "                                      mark='all',\n",
    "                                      cols=None,\n",
    "                                      save=True,\n",
    "                                      show_plots=False,\n",
    "                                      separate_by_swap=True,\n",
    "                                      sep_and_whole=True,\n",
    "                                      conceal_params=False,\n",
    "                                      views_array=None):\n",
    "    \n",
    "    data_files = get_data_dir_contents(data_files_dir=data_files_dir)\n",
    "    \n",
    "    for file_name in data_files:\n",
    "        system_data_dict, system_name = plot_prep_from_parquet(data_files_dir=data_files_dir,\n",
    "                                                               file_name=file_name)\n",
    "        try:\n",
    "            assert system_data_dict is not None\n",
    "        except:\n",
    "            continue # this is where I got to\n",
    "    \n",
    "        position = system_name # Every 'system_name' is actually the name of a position at a customer site at which particular systems are placed\n",
    "        \n",
    "        # Changes: all_system_data[position] now replaced with 'system_data_dict[position]'\n",
    "        \n",
    "        position_systems = [dict_key for dict_key in system_data_dict[position].keys() if 'swap_date' not in str(dict_key)]\n",
    "        if separate_by_swap or sep_and_whole:\n",
    "            for system in position_systems: # Here system means the system number at that position - e.g. system `pump_1` at position KOXDL50400\n",
    "                print(f'\\nWorking on the separated by swap date plot for {position} {system}.\\n')\n",
    "                if mark=='all':\n",
    "                    bokeh_system_data_plotters[mark](data=system_data_dict[position][system],\n",
    "                                                    save_dest = save_dest,\n",
    "                                                    system_position = f\"{position}\",\n",
    "                                                    system=f\"{system}\",\n",
    "                                                    show_plots=show_plots,\n",
    "                                                    save=save,\n",
    "                                                    conceal_params=conceal_params,\n",
    "                                                    customer_name=customer_name)\n",
    "                elif mark=='view':\n",
    "                    for view_to_use in list(views_array.keys()):\n",
    "                        try:\n",
    "                            bokeh_system_data_plotters[mark](data=system_data_dict[position][system],\n",
    "                                                        save_dest = save_dest,\n",
    "                                                        views_array=views_array,\n",
    "                                                        view_to_use=view_to_use,\n",
    "                                                        system_position = f\"{position}\",\n",
    "                                                        system=f\"{system}\",\n",
    "                                                        show_plots=show_plots,\n",
    "                                                        save=save,\n",
    "                                                        conceal_params=conceal_params,\n",
    "                                                        customer_name=customer_name)\n",
    "                        except:\n",
    "                            print(position)\n",
    "                            print(system)\n",
    "                            print(system_data_dict[system])\n",
    "                            raise ValueError('Something went wrong.')\n",
    "\n",
    "                if save:\n",
    "                    text = '\\033[1m' + f\"Dashboard for {position} {system} generated and placed within '{save_dest}.'\" + '\\033[0m'\n",
    "                    colored_text = colored(text=text, color='blue')\n",
    "                    print(colored_text)\n",
    "\n",
    "        if (not separate_by_swap) or sep_and_whole:\n",
    "            all_data_for_position = pd.concat([system_data_dict[position][sys] for sys in position_systems])\n",
    "            print(f'\\nWorking on the plot for all of the data on {position}.\\n')\n",
    "\n",
    "            if mark=='all':\n",
    "                bokeh_system_data_plotters[mark](data=all_data_for_position,\n",
    "                                                save_dest=save_dest,\n",
    "                                                system_position=position,\n",
    "                                                system='All_Systems',\n",
    "                                                show_plots=show_plots,\n",
    "                                                save=save,\n",
    "                                                conceal_params=conceal_params,\n",
    "                                                customer_name=customer_name)\n",
    "            elif mark=='view':\n",
    "                for view_to_use in list(views_array.keys()):\n",
    "                        try:\n",
    "                            bokeh_system_data_plotters[mark](data=all_data_for_position,\n",
    "                                                            save_dest=save_dest,\n",
    "                                                            system_position=position,\n",
    "                                                            system='All_Systems',\n",
    "                                                            views_array=views_array,\n",
    "                                                            view_to_use=view_to_use,\n",
    "                                                            show_plots=show_plots,\n",
    "                                                            save=save,\n",
    "                                                            conceal_params=conceal_params,\n",
    "                                                            customer_name=customer_name)\n",
    "                        except:\n",
    "                            print(position)\n",
    "                            print(system)\n",
    "                            print(all_data_for_position)\n",
    "                            raise ValueError('Something went wrong.')\n",
    "            if save:\n",
    "                text = '\\033[1m' + f\"Dashboard for all of the data on {position} generated and placed within '{save_dest}.'\" + '\\033[0m'\n",
    "                colored_text = colored(text=text, color='blue')\n",
    "                print(colored_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing the KOXDL50100 data for plotting.\n",
      "Run Time Columns []\n",
      "The system KOXDL50100 does not have any parameters that include the strings `RunHours` nor `Time`. Therefore, it must not be a pump. Skipping.\n",
      "Preparing the KOXDL50100AC data for plotting.\n",
      "Run Time Columns []\n",
      "The system KOXDL50100AC does not have any parameters that include the strings `RunHours` nor `Time`. Therefore, it must not be a pump. Skipping.\n",
      "Preparing the KOXDL50100Ch A data for plotting.\n",
      "Run Time Columns ['DPRunHoursRID1036']\n",
      "Data for system KOXDL50100Ch A retrieved.\n",
      "Swap dates for system KOXDL50100Ch A isolated.\n",
      "Data for system KOXDL50100Ch A partitioned by swap date.\n",
      "Data for KOXDL50100Ch A prepared for plotting!\n",
      "\n",
      "Working on the separated by swap date plot for KOXDL50100Ch A system_1.\n",
      "\n",
      "There is no BoosterSpeed data for system_1.\n",
      "There is no BoosterTemp data for system_1.\n",
      "There is no DryPumpSpeed data for system_1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:bokeh.core.validation.check:W-1000 (MISSING_RENDERERS): Plot has no renderers: Figure(id='1950207', ...)\n",
      "WARNING:bokeh.core.validation.check:W-1000 (MISSING_RENDERERS): Plot has no renderers: Figure(id='1950240', ...)\n",
      "WARNING:bokeh.core.validation.check:W-1000 (MISSING_RENDERERS): Plot has no renderers: Figure(id='1950396', ...)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no BoosterSpeed data for system_1.\n",
      "There is no BoosterTemp data for system_1.\n",
      "There is no DryPumpSpeed data for system_1.\n",
      "The RunHours parameter is DPRunHoursRID1036\n",
      "The names of the columns of the column data source are ['LogTime', 'DPRunHoursRID1036']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:bokeh.core.validation.check:W-1000 (MISSING_RENDERERS): Plot has no renderers: Figure(id='1953356', ...)\n",
      "WARNING:bokeh.core.validation.check:W-1000 (MISSING_RENDERERS): Plot has no renderers: Figure(id='1953668', ...)\n",
      "WARNING:bokeh.core.validation.check:W-1000 (MISSING_RENDERERS): Plot has no renderers: Figure(id='1953389', ...)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no BoosterSpeed data for system_1.\n",
      "There is no BoosterTemp data for system_1.\n",
      "There is no DryPumpSpeed data for system_1.\n",
      "The RunHours parameter is DPRunHoursRID1036\n",
      "The names of the columns of the column data source are ['LogTime', 'DPRunHoursRID1036']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:bokeh.core.validation.check:W-1000 (MISSING_RENDERERS): Plot has no renderers: Figure(id='1959190', ...)\n",
      "WARNING:bokeh.core.validation.check:W-1000 (MISSING_RENDERERS): Plot has no renderers: Figure(id='1959157', ...)\n",
      "WARNING:bokeh.core.validation.check:W-1000 (MISSING_RENDERERS): Plot has no renderers: Figure(id='1959469', ...)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDashboard for KOXDL50100Ch A system_1 generated and placed within 'C:\\Users\\a00555655\\OneDrive - ONEVIRTUALOFFICE\\Documents\\Python Scripts\\Dashboards\\Micron_F16\\Figures.'\u001b[0m\n",
      "\n",
      "Working on the separated by swap date plot for KOXDL50100Ch A system_2.\n",
      "\n",
      "There is no BoosterSpeed data for system_2.\n",
      "There is no BoosterTemp data for system_2.\n",
      "There is no DryPumpSpeed data for system_2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:bokeh.core.validation.check:W-1000 (MISSING_RENDERERS): Plot has no renderers: Figure(id='1964991', ...)\n",
      "WARNING:bokeh.core.validation.check:W-1000 (MISSING_RENDERERS): Plot has no renderers: Figure(id='1965147', ...)\n",
      "WARNING:bokeh.core.validation.check:W-1000 (MISSING_RENDERERS): Plot has no renderers: Figure(id='1964958', ...)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no BoosterSpeed data for system_2.\n",
      "There is no BoosterTemp data for system_2.\n",
      "There is no DryPumpSpeed data for system_2.\n",
      "The RunHours parameter is DPRunHoursRID1036\n",
      "The names of the columns of the column data source are ['LogTime', 'DPRunHoursRID1036']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:bokeh.core.validation.check:W-1000 (MISSING_RENDERERS): Plot has no renderers: Figure(id='1968140', ...)\n",
      "WARNING:bokeh.core.validation.check:W-1000 (MISSING_RENDERERS): Plot has no renderers: Figure(id='1968419', ...)\n",
      "WARNING:bokeh.core.validation.check:W-1000 (MISSING_RENDERERS): Plot has no renderers: Figure(id='1968107', ...)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no BoosterSpeed data for system_2.\n",
      "There is no BoosterTemp data for system_2.\n",
      "There is no DryPumpSpeed data for system_2.\n",
      "The RunHours parameter is DPRunHoursRID1036\n",
      "The names of the columns of the column data source are ['LogTime', 'DPRunHoursRID1036']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:bokeh.core.validation.check:W-1000 (MISSING_RENDERERS): Plot has no renderers: Figure(id='1974220', ...)\n",
      "WARNING:bokeh.core.validation.check:W-1000 (MISSING_RENDERERS): Plot has no renderers: Figure(id='1973908', ...)\n",
      "WARNING:bokeh.core.validation.check:W-1000 (MISSING_RENDERERS): Plot has no renderers: Figure(id='1973941', ...)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDashboard for KOXDL50100Ch A system_2 generated and placed within 'C:\\Users\\a00555655\\OneDrive - ONEVIRTUALOFFICE\\Documents\\Python Scripts\\Dashboards\\Micron_F16\\Figures.'\u001b[0m\n",
      "\n",
      "Working on the separated by swap date plot for KOXDL50100Ch A system_3.\n",
      "\n",
      "There is no BoosterSpeed data for system_3.\n",
      "There is no BoosterTemp data for system_3.\n",
      "There is no DryPumpSpeed data for system_3.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:bokeh.core.validation.check:W-1000 (MISSING_RENDERERS): Plot has no renderers: Figure(id='1979709', ...)\n",
      "WARNING:bokeh.core.validation.check:W-1000 (MISSING_RENDERERS): Plot has no renderers: Figure(id='1979742', ...)\n",
      "WARNING:bokeh.core.validation.check:W-1000 (MISSING_RENDERERS): Plot has no renderers: Figure(id='1979898', ...)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no BoosterSpeed data for system_3.\n",
      "There is no BoosterTemp data for system_3.\n",
      "There is no DryPumpSpeed data for system_3.\n",
      "The RunHours parameter is DPRunHoursRID1036\n",
      "The names of the columns of the column data source are ['LogTime', 'DPRunHoursRID1036']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:bokeh.core.validation.check:W-1000 (MISSING_RENDERERS): Plot has no renderers: Figure(id='1983170', ...)\n",
      "WARNING:bokeh.core.validation.check:W-1000 (MISSING_RENDERERS): Plot has no renderers: Figure(id='1982891', ...)\n",
      "WARNING:bokeh.core.validation.check:W-1000 (MISSING_RENDERERS): Plot has no renderers: Figure(id='1982858', ...)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no BoosterSpeed data for system_3.\n",
      "There is no BoosterTemp data for system_3.\n",
      "There is no DryPumpSpeed data for system_3.\n",
      "The RunHours parameter is DPRunHoursRID1036\n",
      "The names of the columns of the column data source are ['LogTime', 'DPRunHoursRID1036']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:bokeh.core.validation.check:W-1000 (MISSING_RENDERERS): Plot has no renderers: Figure(id='1988971', ...)\n",
      "WARNING:bokeh.core.validation.check:W-1000 (MISSING_RENDERERS): Plot has no renderers: Figure(id='1988692', ...)\n",
      "WARNING:bokeh.core.validation.check:W-1000 (MISSING_RENDERERS): Plot has no renderers: Figure(id='1988659', ...)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDashboard for KOXDL50100Ch A system_3 generated and placed within 'C:\\Users\\a00555655\\OneDrive - ONEVIRTUALOFFICE\\Documents\\Python Scripts\\Dashboards\\Micron_F16\\Figures.'\u001b[0m\n",
      "\n",
      "Working on the separated by swap date plot for KOXDL50100Ch A system_4.\n",
      "\n",
      "There is no BoosterSpeed data for system_4.\n",
      "There is no BoosterTemp data for system_4.\n",
      "There is no DryPumpSpeed data for system_4.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:bokeh.core.validation.check:W-1000 (MISSING_RENDERERS): Plot has no renderers: Figure(id='1994649', ...)\n",
      "WARNING:bokeh.core.validation.check:W-1000 (MISSING_RENDERERS): Plot has no renderers: Figure(id='1994493', ...)\n",
      "WARNING:bokeh.core.validation.check:W-1000 (MISSING_RENDERERS): Plot has no renderers: Figure(id='1994460', ...)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no BoosterSpeed data for system_4.\n",
      "There is no BoosterTemp data for system_4.\n",
      "There is no DryPumpSpeed data for system_4.\n",
      "The RunHours parameter is DPRunHoursRID1036\n",
      "The names of the columns of the column data source are ['LogTime', 'DPRunHoursRID1036']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:bokeh.core.validation.check:W-1000 (MISSING_RENDERERS): Plot has no renderers: Figure(id='1997921', ...)\n",
      "WARNING:bokeh.core.validation.check:W-1000 (MISSING_RENDERERS): Plot has no renderers: Figure(id='1997642', ...)\n",
      "WARNING:bokeh.core.validation.check:W-1000 (MISSING_RENDERERS): Plot has no renderers: Figure(id='1997609', ...)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no BoosterSpeed data for system_4.\n",
      "There is no BoosterTemp data for system_4.\n",
      "There is no DryPumpSpeed data for system_4.\n",
      "The RunHours parameter is DPRunHoursRID1036\n",
      "The names of the columns of the column data source are ['LogTime', 'DPRunHoursRID1036']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:bokeh.core.validation.check:W-1000 (MISSING_RENDERERS): Plot has no renderers: Figure(id='2003443', ...)\n",
      "WARNING:bokeh.core.validation.check:W-1000 (MISSING_RENDERERS): Plot has no renderers: Figure(id='2003410', ...)\n",
      "WARNING:bokeh.core.validation.check:W-1000 (MISSING_RENDERERS): Plot has no renderers: Figure(id='2003722', ...)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDashboard for KOXDL50100Ch A system_4 generated and placed within 'C:\\Users\\a00555655\\OneDrive - ONEVIRTUALOFFICE\\Documents\\Python Scripts\\Dashboards\\Micron_F16\\Figures.'\u001b[0m\n",
      "\n",
      "Working on the plot for all of the data on KOXDL50100Ch A.\n",
      "\n",
      "There is no BoosterSpeed data for All_Systems.\n",
      "There is no BoosterTemp data for All_Systems.\n",
      "There is no DryPumpSpeed data for All_Systems.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:bokeh.core.validation.check:W-1000 (MISSING_RENDERERS): Plot has no renderers: Figure(id='2009244', ...)\n",
      "WARNING:bokeh.core.validation.check:W-1000 (MISSING_RENDERERS): Plot has no renderers: Figure(id='2009400', ...)\n",
      "WARNING:bokeh.core.validation.check:W-1000 (MISSING_RENDERERS): Plot has no renderers: Figure(id='2009211', ...)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KOXDL50100Ch A\n",
      "system_4\n",
      "ParameterInfo            BoosterControlRID1035  BoosterCurrentRID1169  \\\n",
      "LogTime                                                                 \n",
      "2022-07-19 15:07:21.270                    4.0                    NaN   \n",
      "2022-07-19 15:08:31.127                    4.0                    9.1   \n",
      "2022-07-19 15:08:51.397                    NaN                    NaN   \n",
      "2022-07-19 15:09:01.797                    NaN                    NaN   \n",
      "2022-07-19 15:09:17.757                    NaN                    NaN   \n",
      "...                                        ...                    ...   \n",
      "2023-01-11 23:59:21.803                    NaN                    NaN   \n",
      "2023-01-11 23:59:42.350                    NaN                    NaN   \n",
      "2023-01-11 23:59:44.397                    NaN                    NaN   \n",
      "2023-01-11 23:59:47.493                    NaN                    9.0   \n",
      "2023-01-11 23:59:57.760                    NaN                    NaN   \n",
      "\n",
      "ParameterInfo            BoosterPowerRID1034  Ch1VI1RID1219  Ch1VI2RID1220  \\\n",
      "LogTime                                                                      \n",
      "2022-07-19 15:07:21.270               1600.0            NaN            NaN   \n",
      "2022-07-19 15:08:31.127               1600.0            NaN            NaN   \n",
      "2022-07-19 15:08:51.397                  NaN            NaN            NaN   \n",
      "2022-07-19 15:09:01.797                  NaN            NaN            NaN   \n",
      "2022-07-19 15:09:17.757                  NaN            NaN            NaN   \n",
      "...                                      ...            ...            ...   \n",
      "2023-01-11 23:59:21.803                  NaN            NaN            NaN   \n",
      "2023-01-11 23:59:42.350                  NaN            NaN            NaN   \n",
      "2023-01-11 23:59:44.397                  NaN            NaN            NaN   \n",
      "2023-01-11 23:59:47.493                  NaN            NaN            NaN   \n",
      "2023-01-11 23:59:57.760               1500.0            NaN            NaN   \n",
      "\n",
      "ParameterInfo            Ch1VI3RID1221  Ch1VI4RID1222  Ch1VI5RID1223  \\\n",
      "LogTime                                                                \n",
      "2022-07-19 15:07:21.270            NaN            NaN            NaN   \n",
      "2022-07-19 15:08:31.127            NaN            NaN            NaN   \n",
      "2022-07-19 15:08:51.397            NaN            NaN            NaN   \n",
      "2022-07-19 15:09:01.797            NaN            NaN            NaN   \n",
      "2022-07-19 15:09:17.757            NaN            NaN            NaN   \n",
      "...                                ...            ...            ...   \n",
      "2023-01-11 23:59:21.803            NaN            NaN            NaN   \n",
      "2023-01-11 23:59:42.350            NaN            NaN            NaN   \n",
      "2023-01-11 23:59:44.397            NaN            NaN            NaN   \n",
      "2023-01-11 23:59:47.493            NaN            NaN            NaN   \n",
      "2023-01-11 23:59:57.760            NaN            NaN            NaN   \n",
      "\n",
      "ParameterInfo            Ch1VI6RID1224  ControllerTemperatureRID1172  ...  \\\n",
      "LogTime                                                               ...   \n",
      "2022-07-19 15:07:21.270            NaN                           NaN  ...   \n",
      "2022-07-19 15:08:31.127            NaN                        332.25  ...   \n",
      "2022-07-19 15:08:51.397            NaN                           NaN  ...   \n",
      "2022-07-19 15:09:01.797            NaN                           NaN  ...   \n",
      "2022-07-19 15:09:17.757            NaN                           NaN  ...   \n",
      "...                                ...                           ...  ...   \n",
      "2023-01-11 23:59:21.803            NaN                           NaN  ...   \n",
      "2023-01-11 23:59:42.350            NaN                           NaN  ...   \n",
      "2023-01-11 23:59:44.397            NaN                           NaN  ...   \n",
      "2023-01-11 23:59:47.493            NaN                           NaN  ...   \n",
      "2023-01-11 23:59:57.760            NaN                           NaN  ...   \n",
      "\n",
      "ParameterInfo            MBEndCoverTempRID1170  \\\n",
      "LogTime                                          \n",
      "2022-07-19 15:07:21.270                    NaN   \n",
      "2022-07-19 15:08:31.127             393.550018   \n",
      "2022-07-19 15:08:51.397                    NaN   \n",
      "2022-07-19 15:09:01.797                    NaN   \n",
      "2022-07-19 15:09:17.757                    NaN   \n",
      "...                                        ...   \n",
      "2023-01-11 23:59:21.803                    NaN   \n",
      "2023-01-11 23:59:42.350                    NaN   \n",
      "2023-01-11 23:59:44.397                    NaN   \n",
      "2023-01-11 23:59:47.493                    NaN   \n",
      "2023-01-11 23:59:57.760                    NaN   \n",
      "\n",
      "ParameterInfo            MBInverterControllerTemperatureRID1049  \\\n",
      "LogTime                                                           \n",
      "2022-07-19 15:07:21.270                              334.649994   \n",
      "2022-07-19 15:08:31.127                              334.649994   \n",
      "2022-07-19 15:08:51.397                                     NaN   \n",
      "2022-07-19 15:09:01.797                                     NaN   \n",
      "2022-07-19 15:09:17.757                                     NaN   \n",
      "...                                                         ...   \n",
      "2023-01-11 23:59:21.803                                     NaN   \n",
      "2023-01-11 23:59:42.350                                     NaN   \n",
      "2023-01-11 23:59:44.397                                     NaN   \n",
      "2023-01-11 23:59:47.493                                     NaN   \n",
      "2023-01-11 23:59:57.760                                     NaN   \n",
      "\n",
      "ParameterInfo            MBInverterHeatSinkTemperatureRID1174  \\\n",
      "LogTime                                                         \n",
      "2022-07-19 15:07:21.270                                   NaN   \n",
      "2022-07-19 15:08:31.127                            305.950012   \n",
      "2022-07-19 15:08:51.397                                   NaN   \n",
      "2022-07-19 15:09:01.797                                   NaN   \n",
      "2022-07-19 15:09:17.757                            302.450012   \n",
      "...                                                       ...   \n",
      "2023-01-11 23:59:21.803                                   NaN   \n",
      "2023-01-11 23:59:42.350                                   NaN   \n",
      "2023-01-11 23:59:44.397                                   NaN   \n",
      "2023-01-11 23:59:47.493                                   NaN   \n",
      "2023-01-11 23:59:57.760                                   NaN   \n",
      "\n",
      "ParameterInfo            MBInverterSpeedRID1047  MBStatorTempRID1039  \\\n",
      "LogTime                                                                \n",
      "2022-07-19 15:07:21.270              101.900002           411.649994   \n",
      "2022-07-19 15:08:31.127              101.900002           413.950012   \n",
      "2022-07-19 15:08:51.397                     NaN                  NaN   \n",
      "2022-07-19 15:09:01.797                     NaN                  NaN   \n",
      "2022-07-19 15:09:17.757                     NaN                  NaN   \n",
      "...                                         ...                  ...   \n",
      "2023-01-11 23:59:21.803                     NaN                  NaN   \n",
      "2023-01-11 23:59:42.350                     NaN                  NaN   \n",
      "2023-01-11 23:59:44.397              101.900002           424.350006   \n",
      "2023-01-11 23:59:47.493                     NaN                  NaN   \n",
      "2023-01-11 23:59:57.760                     NaN                  NaN   \n",
      "\n",
      "ParameterInfo            OffProcessLevelRID1043  ProcessOn/OffRID1042  \\\n",
      "LogTime                                                                 \n",
      "2022-07-19 15:07:21.270                     1.0                   1.0   \n",
      "2022-07-19 15:08:31.127                     1.0                   1.0   \n",
      "2022-07-19 15:08:51.397                     NaN                   NaN   \n",
      "2022-07-19 15:09:01.797                     NaN                   NaN   \n",
      "2022-07-19 15:09:17.757                     NaN                   NaN   \n",
      "...                                         ...                   ...   \n",
      "2023-01-11 23:59:21.803                     NaN                   NaN   \n",
      "2023-01-11 23:59:42.350                     NaN                   NaN   \n",
      "2023-01-11 23:59:44.397                     NaN                   NaN   \n",
      "2023-01-11 23:59:47.493                     NaN                   NaN   \n",
      "2023-01-11 23:59:57.760                     NaN                   NaN   \n",
      "\n",
      "ParameterInfo            PumpN2FlowRID1037  PumpNodeRID1272  \\\n",
      "LogTime                                                       \n",
      "2022-07-19 15:07:21.270           0.001628              NaN   \n",
      "2022-07-19 15:08:31.127           0.001628              NaN   \n",
      "2022-07-19 15:08:51.397                NaN              NaN   \n",
      "2022-07-19 15:09:01.797                NaN              NaN   \n",
      "2022-07-19 15:09:17.757                NaN              NaN   \n",
      "...                                    ...              ...   \n",
      "2023-01-11 23:59:21.803           0.002225              NaN   \n",
      "2023-01-11 23:59:42.350                NaN              NaN   \n",
      "2023-01-11 23:59:44.397                NaN              NaN   \n",
      "2023-01-11 23:59:47.493                NaN              NaN   \n",
      "2023-01-11 23:59:57.760                NaN              NaN   \n",
      "\n",
      "ParameterInfo            VIsionDerivedStatusRID1212  \n",
      "LogTime                                              \n",
      "2022-07-19 15:07:21.270                         NaN  \n",
      "2022-07-19 15:08:31.127                         NaN  \n",
      "2022-07-19 15:08:51.397                         NaN  \n",
      "2022-07-19 15:09:01.797                         NaN  \n",
      "2022-07-19 15:09:17.757                         NaN  \n",
      "...                                             ...  \n",
      "2023-01-11 23:59:21.803                         NaN  \n",
      "2023-01-11 23:59:42.350                         NaN  \n",
      "2023-01-11 23:59:44.397                         NaN  \n",
      "2023-01-11 23:59:47.493                         NaN  \n",
      "2023-01-11 23:59:57.760                         NaN  \n",
      "\n",
      "[2066399 rows x 33 columns]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Something went wrong.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_239312\\1361181376.py\u001b[0m in \u001b[0;36minteractive_plot_all_systems_data\u001b[1;34m(data_files_dir, save_dest, customer_name, mark, cols, save, show_plots, separate_by_swap, sep_and_whole, conceal_params, views_array)\u001b[0m\n\u001b[0;32m     79\u001b[0m                         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m                             bokeh_system_data_plotters[mark](data=all_data_for_position,\n\u001b[0m\u001b[0;32m     81\u001b[0m                                                             \u001b[0msave_dest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msave_dest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_239312\\3703289776.py\u001b[0m in \u001b[0;36mbokeh_plot_system_view\u001b[1;34m(data, system, system_position, customer_name, save_dest, views_array, view_to_use, cols, save, show_plots, conceal_params)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_file_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 255\u001b[1;33m         \u001b[0mplotting\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayouts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdashboard_title\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayouts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdashboard_rows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\dev\\lib\\site-packages\\bokeh\\io\\saving.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(obj, filename, resources, title, template, state)\u001b[0m\n\u001b[0;32m     97\u001b[0m     \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresources\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_save_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresources\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m     \u001b[0m_save_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresources\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemplate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtheme\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mabspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\dev\\lib\\site-packages\\bokeh\\io\\saving.py\u001b[0m in \u001b[0;36m_save_helper\u001b[1;34m(obj, filename, resources, title, template, theme)\u001b[0m\n\u001b[0;32m    166\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"w\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 167\u001b[1;33m         \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 28] No space left on device",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_239312\\989820156.py\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Plot views for all systems:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m interactive_plot_all_systems_data(DATA_FOLDER_PATH,\n\u001b[0m\u001b[0;32m      4\u001b[0m                                   \u001b[0msave_dest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFIG_DIR\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                   \u001b[0mmark\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdash_view_or_all\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_239312\\1361181376.py\u001b[0m in \u001b[0;36minteractive_plot_all_systems_data\u001b[1;34m(data_files_dir, save_dest, customer_name, mark, cols, save, show_plots, separate_by_swap, sep_and_whole, conceal_params, views_array)\u001b[0m\n\u001b[0;32m     92\u001b[0m                             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msystem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m                             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_data_for_position\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m                             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Something went wrong.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0msave\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m                 \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'\\033[1m'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34mf\"Dashboard for all of the data on {position} generated and placed within '{save_dest}.'\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'\\033[0m'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Something went wrong."
     ]
    }
   ],
   "source": [
    "# Plot views for all systems:\n",
    "\n",
    "interactive_plot_all_systems_data(DATA_FOLDER_PATH,\n",
    "                                  save_dest=FIG_DIR,\n",
    "                                  mark=dash_view_or_all,\n",
    "                                  views_array=custom_views,\n",
    "                                  show_plots=False,\n",
    "                                  save=True,\n",
    "                                  separate_by_swap=separate_by_swap,\n",
    "                                  sep_and_whole=sep_and_whole,\n",
    "                                  conceal_params=conceal_params,\n",
    "                                  customer_name=customer_account_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "27e55a07bc38151c1c095ec1be726f30fcff6d2fbda644176d0355fa9ce05d44"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
