{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 805,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from datetime import datetime as dt\n",
    "import json\n",
    "import pyodbc\n",
    "import re\n",
    "import types\n",
    "from termcolor import colored\n",
    "import types\n",
    "import re\n",
    "import os\n",
    "from bokeh import plotting\n",
    "from bokeh import layouts\n",
    "from bokeh import io\n",
    "from bokeh import models\n",
    "from bokeh.models.tools import HoverTool\n",
    "from bokeh.models.widgets.markups import Div\n",
    "from math import ceil\n",
    "import math\n",
    "from sympy.ntheory import primefactors\n",
    "import statsmodels as sm        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "## Login ##\n",
    "\n",
    "RESOURCES_PATH = os.path.join(sys.path[0][:sys.path[0].rindex('\\\\')], r'Resources')\n",
    "\n",
    "login_file_path = os.path.join(sys.path[0][:sys.path[0].rindex('\\\\')], r'Resources\\login.json')\n",
    "\n",
    "with open(login_file_path, 'r') as json_file:\n",
    "    login_details = json.load(json_file)\n",
    "\n",
    "## Obtain list of all databases with relevant information ##\n",
    "\n",
    "master_db = 'master'\n",
    "\n",
    "master_db_connection = pyodbc.connect('Driver={SQL Server};'\n",
    "                                'Server=' + login_details['server'] + ';'\n",
    "                                 'Database=' + master_db + ';'\n",
    "                                 'Uid=' + login_details['uid'] + ';'\n",
    "                                 'Pwd=' + login_details['pwd'] + ';')\n",
    "\n",
    "get_databases_query = (\"select name \\\n",
    "                        from master.sys.databases \\\n",
    "                        where name like '%scada_production%'\")\n",
    "\n",
    "customer_data_databases = pd.read_sql_query(get_databases_query, master_db_connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 name\n",
      "1               scada_Production_AMAT\n",
      "2       scada_Production_AMAT_PdMTest\n",
      "3                scada_Production_ASW\n",
      "4               scada_Production_CXMT\n",
      "5               scada_Production_DBCC\n",
      "6       scada_Production_GF_Diffusion\n",
      "7         scada_Production_GF_Dresden\n",
      "8           scada_Production_GF_Films\n",
      "9      scada_Production_GF_Patterning\n",
      "10         scada_Production_GF_Phase1\n",
      "11              scada_Production_IMEC\n",
      "12         scada_Production_IMEC_MAIN\n",
      "13  scada_Production_Infineon_Dresden\n",
      "14      scada_Production_KIOXIA_DAISE\n",
      "15              scada_Production_LETI\n",
      "16               scada_Production_MB1\n",
      "17        scada_Production_Micron_F11\n",
      "18        scada_Production_Micron_F15\n",
      "19        scada_Production_Micron_F16\n",
      "20         scada_Production_Micron_F6\n",
      "21           scada_Production_PdMDemo\n",
      "22           scada_Production_Plessey\n",
      "23         scada_Production_Samsung01\n",
      "24         scada_Production_Samsung02\n",
      "25        scada_Production_ST_Crolles\n",
      "26        scada_Production_TEL_Hosaka\n",
      "27           scada_Production_UMC_CSA\n",
      "28              scada_Production_UMC5\n",
      "29           scada_Production_UMC5_17\n",
      "30          scada_Production_UMCDec19\n",
      "31           scada_Production_UMCP1_2\n",
      "32       scada_Production_XFAB_France\n",
      "33           scada_Production_Yachiyo\n",
      "34            scada_Production_YMTC_2\n",
      "35            scada_Production_YMTC_3\n",
      "\n",
      "Using the the table displayed, please enter the number corresponding to the customer database of interest:\n",
      "32\n",
      "You have chosen \"scada_Production_XFAB_France\". Is this correct (Y/N)? Y\n",
      "Please enter the path of the directory within which you wish the data and figures to be saved: C:\\Users\\a00555655\\OneDrive - ONEVIRTUALOFFICE\\Documents\\Dashboards\n",
      "\n",
      "All files will be placed at: \n",
      "\"C:\\Users\\a00555655\\OneDrive - ONEVIRTUALOFFICE\\Documents\\Dashboards\\XFAB_France\\2022-12-15\".\n",
      "Please choose whether you wish to proceed by \n",
      "1. System Name; \n",
      "2. System Type; \n",
      "3. Both.\n",
      "Alternatively, if you wish to retrieve data for all systems within scada_Production_XFAB_France, please enter 4.\n",
      "1\n",
      "Thank you for choosing 1\n",
      "Would you like to \n",
      "0. Enter the system names here (enter 0); or \n",
      "1. Pass a file path containing the system names (enter 1)\n",
      "1\n",
      "Thank you for choosing 1\n",
      "Please enter the file location for a comma separated file containing the names of the systems of interest:\n",
      "\"C:\\Users\\a00555655\\OneDrive - ONEVIRTUALOFFICE\\Documents\\Python Scripts\\XFABDashboarder\\HOTLPCVDs\\Resources\\DryPumps.txt\"\n",
      "Thank you for choosing C:\\Users\\a00555655\\OneDrive - ONEVIRTUALOFFICE\\Documents\\Python Scripts\\XFABDashboarder\\HOTLPCVDs\\Resources\\DryPumps.txt\n",
      "Found systems corresponding to all of the entered names within the scada_Production_XFAB_France database; namely: \n",
      "['FV11', 'FV06', 'TW01', 'FV07', 'FV09', 'TW05', 'TW08', 'TW06', 'TV03', 'TW03', 'TV01', 'FV-13', 'TV05', 'TV04', 'TW02', 'TW04', 'TV-02', 'TW07', 'TW09']\n",
      "Will retrieve data for these systems.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "## Prompt user for the customer/database of interest ##\n",
    "\n",
    "confirmation = 'N'\n",
    "while confirmation != 'Y':\n",
    "    print(customer_data_databases.iloc[1:])\n",
    "    choices = customer_data_databases.iloc[1:].index.to_list()\n",
    "    user_choice = input('\\nUsing the the table displayed, please enter the number corresponding to the customer database of interest:\\n')\n",
    "    try:\n",
    "        user_choice = int(user_choice)\n",
    "    except:\n",
    "        pass\n",
    "    while user_choice not in choices:\n",
    "        print(customer_data_databases.iloc[1:])\n",
    "        user_choice = input('\\nInvalid choice. Please choose a number associated with one of the databases listed below: \\n')\n",
    "        try:\n",
    "            user_choice = int(user_choice)\n",
    "        except:\n",
    "            pass\n",
    "    confirmation = input(f'You have chosen \"{customer_data_databases.iloc[user_choice][0]}\". Is this correct (Y/N)? ').upper()\n",
    "database = customer_data_databases.iloc[user_choice][0]\n",
    "\n",
    "MAIN_FOLDER_PATH = fr\"{input('Please enter the path of the directory within which you wish the data and figures to be saved: ')}\".replace('\"', '').replace(\"'\",'')\n",
    "while not os.path.exists(MAIN_FOLDER_PATH):\n",
    "    print('\\n')\n",
    "    MAIN_FOLDER_PATH = fr\"{input('The entered path does not exist. Please enter a valid path to continue: ')}\"\n",
    "date = datetime.datetime.today().strftime('%Y-%m-%d')\n",
    "customer_account_name = database[17:]\n",
    "MAIN_FOLDER_PATH = os.path.join(MAIN_FOLDER_PATH, fr'{customer_account_name}\\{date}')\n",
    "if not os.path.exists(MAIN_FOLDER_PATH):\n",
    "    os.makedirs(MAIN_FOLDER_PATH)\n",
    "    assert os.path.exists(MAIN_FOLDER_PATH)\n",
    "print(f'\\nAll files will be placed at: \\n\"{MAIN_FOLDER_PATH}\".')\n",
    "    \n",
    "## Get inputs function ##\n",
    "\n",
    "def get_input(prompt, success_conditions=None, failure_messages=None, message=None, wrapping_func=None, literal_str=False):\n",
    "\n",
    "    if wrapping_func == None:\n",
    "        wrapping_func = lambda x: x\n",
    "    \n",
    "    if message is not None:\n",
    "        print(message)\n",
    "    \n",
    "    if success_conditions == None:\n",
    "#         print('input1')\n",
    "        if literal_str==True:\n",
    "#             print('input2')\n",
    "            return fr\"{input(prompt)}\"\n",
    "        else:\n",
    "#             print('input3')\n",
    "            return wrapping_func(input(prompt))\n",
    "    else:\n",
    "        k=1\n",
    "#         print('input4')\n",
    "        x = fr\"{input(prompt)}\"\n",
    "        \n",
    "        x = x.replace('\"', '')\n",
    "        \n",
    "        num_conditions_to_satisfy = len(success_conditions)\n",
    "\n",
    "        success_count = 0\n",
    "\n",
    "        while success_count < num_conditions_to_satisfy:\n",
    "#             print('input5')\n",
    "        \n",
    "            for idx in range(num_conditions_to_satisfy):\n",
    "#                 print('input6')\n",
    "                # print(f'Success condition {idx} is {success_conditions[idx](x)} because x is {x} and its type is {type(x)}')\n",
    "                if isinstance(success_conditions[idx], types.FunctionType):\n",
    "#                     print('input7')\n",
    "                    if success_conditions[idx](x):\n",
    "#                         print('input8')\n",
    "                        success_count+=1\n",
    "                    else:\n",
    "#                         print('input9')\n",
    "                        print(failure_messages)\n",
    "                        if failure_messages is not None and len(failure_messages) > 1:\n",
    "#                             print('input10')\n",
    "                            print(failure_messages[idx].format(x, type(x), f'Condition {idx+1} failure'))\n",
    "                            return get_input(prompt, \n",
    "                                            success_conditions=success_conditions, \n",
    "                                            failure_messages=failure_messages, \n",
    "                                            message=message,\n",
    "                                            wrapping_func=wrapping_func)\n",
    "                        elif failure_messages is not None and len(failure_messages) == 1:\n",
    "#                             print('input11')\n",
    "                            print(failure_messages[0].format(x))\n",
    "                            return get_input(prompt, \n",
    "                                             success_conditions=success_conditions, \n",
    "                                             failure_messages=failure_messages, \n",
    "                                             message=message,\n",
    "                                             wrapping_func=wrapping_func)\n",
    "                \n",
    "                else:\n",
    "#                     print('input12')\n",
    "                    if success_conditions[idx]:\n",
    "                        success_count+=1\n",
    "                    else:\n",
    "#                         print('input13')\n",
    "                        if len(failure_messages) > 1:\n",
    "#                             print('input14')\n",
    "                            print(failure_messages[idx].format(x, type(x), f'Condition {idx+1} failure'))\n",
    "                            return get_input(prompt, \n",
    "                                            success_conditions=success_conditions, \n",
    "                                            failure_messages=failure_messages, \n",
    "                                            message=message,\n",
    "                                            wrapping_func=wrapping_func)\n",
    "                        else:\n",
    "#                             print('input15')\n",
    "                            print(failure_messages[0])\n",
    "                            return get_input(prompt, \n",
    "                                             success_conditions=success_conditions, \n",
    "                                             failure_messages=failure_messages, \n",
    "                                             message=message,\n",
    "                                            wrapping_func=wrapping_func)\n",
    "        print(f'Thank you for choosing {wrapping_func(x)}')\n",
    "        return wrapping_func(x)\n",
    "\n",
    "## Establish connection with the chosen customer data connection ##\n",
    "\n",
    "db_connection = pyodbc.connect('Driver={SQL Server};'\n",
    "                                'Server=' + login_details['server'] + ';'\n",
    "                                 'Database=' + database + ';'\n",
    "                                 'Uid=' + login_details['uid'] + ';'\n",
    "                                 'Pwd=' + login_details['pwd'] + ';')\n",
    "\n",
    "## Define a function that checks whether a string can be converted to an integetr or not ##\n",
    "\n",
    "def isintable(x):\n",
    "    try:\n",
    "        x = int(x)\n",
    "        return True\n",
    "    except:\n",
    "        False\n",
    "\n",
    "## Prompt user for whether they want to obtain system data based on system types, system names or both ##\n",
    "\n",
    "type_or_name_or_both = get_input(prompt=f'Please choose whether you wish to proceed by \\n1. System Name; \\n2. System Type; \\n3. Both.\\nAlternatively, if you wish to retrieve data for all systems within {database}, please enter 4.\\n',\n",
    "                                 success_conditions=(isintable, lambda x: int(x) in (1,2,3,4)),\n",
    "                                 failure_messages=('{2}: {0} is not a valid choice. Please choose from 1, 2, 3 and 4 because {0} cannot be converted into an integer.',\n",
    "                                                   '{2}: {0} is not a valid choice. Please choose from 1, 2, 3 and 4 because {0} is not in (1,2,3,4).'),\n",
    "                                 message=None,\n",
    "                                 wrapping_func=int)\n",
    "\n",
    "if type_or_name_or_both in (1,3):\n",
    "    systems_by_file = get_input(prompt='Would you like to \\n0. Enter the system names here (enter 0); or \\n1. Pass a file path containing the system names (enter 1)\\n',\n",
    "                                success_conditions=(isintable, lambda x: int(x) in (0,1)),\n",
    "                                failure_messages=('{2}: {0} is not a valid choice as it cannot be converted into an integer. Please choose from 0 or 1.',\n",
    "                                                  '{2}: {0} is noT a valid choice as it is neither 0 nor 1. Please choose 0 or 1.'),\n",
    "                                wrapping_func=int)\n",
    "\n",
    "else:\n",
    "    systems_by_file = 0\n",
    "\n",
    "get_system_names_bool_args = {'by_names':bool(type_or_name_or_both==1 or type_or_name_or_both==3),\n",
    "                              'by_types':bool(type_or_name_or_both==2 or type_or_name_or_both==3),\n",
    "                              'systems_by_file':bool(systems_by_file==1),\n",
    "                              'everything':bool(type_or_name_or_both==4)}\n",
    "\n",
    "\n",
    "## Define a function for retrieving system names form a comma separated text file ##\n",
    "\n",
    "def systems_from_csv(PATH):\n",
    "    \n",
    "    systems = []\n",
    "    \n",
    "    SYSTEMS_FILE_PATH = PATH\n",
    "\n",
    "    with open(SYSTEMS_FILE_PATH, 'r') as systems_file:\n",
    "        for line in systems_file:\n",
    "            line_systems = re.split(',|, | ,| , ', line)\n",
    "            systems = systems.copy() + line_systems.copy()\n",
    "\n",
    "    for i in range(len(systems)):\n",
    "        if '\\'' in systems[i] or '\\\"' in systems[i]:\n",
    "            systems[i] = systems[i].replace('\\'', '')\n",
    "            systems[i] = systems[i].replace('\\\"', '')\n",
    "    \n",
    "    return systems\n",
    "\n",
    "## Prompt user for systems/system types/both and ensure at least one corresponding system exists ##\n",
    "\n",
    "def get_system_names(db_connection, database, by_names=False, by_types=False, systems_by_file=False, everything=False):\n",
    "    if by_names:\n",
    "        if not systems_by_file:\n",
    "            systems = get_input(prompt='Please enter the names of the systems for which you wish to retrieve data, separated by commas.\\n')\n",
    "            systems = re.split(',| ,|, | , ', systems)\n",
    "            systems_as_string = str(systems).replace('[','(').replace(']',')')\n",
    "            \n",
    "\n",
    "            if by_types:\n",
    "                system_types = get_input(prompt='Please enter the types of the systems for which you wish to retrieve data, separated by commas.\\n')\n",
    "                system_types = re.split(',| ,| , ', system_types)\n",
    "                system_types_as_string = str(system_types).replace('[', '(').replace(']', ')')\n",
    "                \n",
    "                check_system_name_query = f'select * from {database}.dbo.fst_GEN_system \\\n",
    "                                            where Description in {systems_as_string} \\\n",
    "                                            and SystemTypeID in {system_types_as_string} \\\n",
    "                                            order by SystemTypeID'\n",
    "            \n",
    "            else:\n",
    "                check_system_name_query = f'select * from {database}.dbo.fst_GEN_system \\\n",
    "                                            where Description in {systems_as_string} \\\n",
    "                                            order by SystemTypeID'\n",
    "\n",
    "        else:\n",
    "            systems_path = get_input(prompt='Please enter the file location for a comma separated file containing the names of the systems of interest:\\n',\n",
    "                                     success_conditions=[os.path.exists],\n",
    "                                     failure_messages=['The path you have entered, namely {}, does not exist. Please try again.\\n'])\n",
    "            systems = systems_from_csv(systems_path)\n",
    "            systems_as_string = str(systems).replace('[','(').replace(']',')')\n",
    "\n",
    "\n",
    "            if by_types:\n",
    "                system_types = get_input(prompt='Please enter the types of the systems for which you wish to retrieve data, separated by commas.\\n')\n",
    "                system_types = re.split(',| ,| , ', system_types)\n",
    "                system_types_as_string = str(system_types).replace('[','(').replace(']',')')\n",
    "                check_system_name_query = f'select * from {database}.dbo.fst_GEN_system \\\n",
    "                                                where Description in {systems_as_string} \\\n",
    "                                                and SystemTypeID in {system_types_as_string} \\\n",
    "                                                order by SystemTypeID'\n",
    "            else:\n",
    "                check_system_name_query = f'select * from {database}.dbo.fst_GEN_system \\\n",
    "                                            where Description in {systems_as_string} \\\n",
    "                                            order by SystemTypeID'\n",
    "        query_result = pd.read_sql_query(check_system_name_query, db_connection)\n",
    "        valid_systems = list(query_result['Description'].unique())\n",
    "        invalid_systems = list(set(systems) - set(valid_systems))\n",
    "        if len(invalid_systems) > 1:\n",
    "            print('checking invalid systems')\n",
    "            if len(valid_systems) < 1:\n",
    "                print('yo13')\n",
    "                print(f'Could not find any systems within {database} corresponding to the system names and types (if any entered) provided. Please try again.')\n",
    "                return get_system_names(db_connection=db_connection, \n",
    "                                        database=database, \n",
    "                                        by_names=by_names, \n",
    "                                        by_types=by_types, \n",
    "                                        systems_by_file=systems_by_file,\n",
    "                                        everything=everything)\n",
    "            else:\n",
    "                print(f'Could not find any systems within {database} corresponding to the entered system types (if any were entered) and following system names: {invalid_systems}.')\n",
    "                print(f'Valid system names: {valid_systems}.\\nWill retrieve data for these systems.')\n",
    "                return query_result, valid_systems\n",
    "        else:\n",
    "            print(f'Found systems corresponding to all of the entered names within the {database} database; namely: \\n{valid_systems}\\nWill retrieve data for these systems.')\n",
    "            return query_result, valid_systems\n",
    "\n",
    "    elif by_types:\n",
    "        system_types = get_input(prompt='Please enter the types of the systems for which you wish to retrieve data, separated by commas.\\n')\n",
    "        system_types = re.split(',| ,| , ', system_types)\n",
    "        system_types_as_string = str(system_types).replace('[','(').replace(']',')')\n",
    "        check_system_name_query = f'select * from {database}.dbo.fst_GEN_system \\\n",
    "                                    where SystemTypeID in {system_types_as_string} \\\n",
    "                                    order by SystemTypeID'\n",
    "\n",
    "        query_result = pd.read_sql_query(check_system_name_query, db_connection)\n",
    "\n",
    "        if len(query_result) > 0:\n",
    "            type_systems = query_result[['Description', 'SystemTypeID']]\n",
    "            print(f'The following systems were found to correspond with system types {system_types}:')\n",
    "            print(type_systems)\n",
    "            print('Will retrieve data for these systems.')\n",
    "            return query_result, list(query_result.Description.unique())\n",
    "        \n",
    "        else:\n",
    "            print('yo19')\n",
    "            print(f'Could not find any systems within {database} whose system type IDs correspond with any of {system_types}. Please try again.')\n",
    "            return get_system_names(db_connection=db_connection, \n",
    "                                    database=database, \n",
    "                                    by_names=by_names, \n",
    "                                    by_types=by_types, \n",
    "                                    systems_by_file=systems_by_file,\n",
    "                                    everything=everything)\n",
    "    elif everything:\n",
    "        check_system_name_query = f'select * from {database}.dbo.fst_GEN_System \\\n",
    "                                    order by SystemTypeID'\n",
    "        query_result = pd.read_sql_query(check_system_name_query, db_connection)\n",
    "        print(f'{len(query_result)} systems were found within {database}, including:')\n",
    "        print(query_result[['Description','SystemTypeID']])\n",
    "        print('Will retrieve data for these systems.')\n",
    "        return query_result, list(query_result.Description.unique())\n",
    "\n",
    "systems_info, systems = get_system_names(db_connection=db_connection,\n",
    "                                         database=database,\n",
    "                                         **get_system_names_bool_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Would you like the system data to be: \n",
      "1. Separated by swaps (enter 1); \n",
      "2. Unseparated by swaps (enter 2); \n",
      "3. Plots for the entire data as well as the data separated by swaps (enter 3).\n",
      "3\n",
      "Thank you for choosing 3\n"
     ]
    }
   ],
   "source": [
    "## Prompt user for whether they want to obtain data separated by swaps, unseparated by swaps or both\n",
    "\n",
    "separate_by_swap = False\n",
    "sep_and_whole = False\n",
    "\n",
    "separate_by_swap_or_not = get_input(prompt=f'Would you like the system data to be: \\n1. Separated by swaps (enter 1); \\n2. Unseparated by swaps (enter 2); \\n3. Plots for the entire data as well as the data separated by swaps (enter 3).\\n',\n",
    "                                    success_conditions=(isintable, lambda x: int(x) in (1,2,3)),\n",
    "                                    failure_messages=('{2}: {0} is not a valid choice as it cannot be converted into an integer. Please choose from 1, 2 or 3.',\n",
    "                                                      '{2}: {0} is noT a valid choice as it is not in (1,2,3). Please choose 1, 2 or 3.'),\n",
    "                                    wrapping_func=int)\n",
    "\n",
    "if separate_by_swap_or_not in (1,3):\n",
    "    separate_by_swap = True\n",
    "    if separate_by_swap_or_not == 3:\n",
    "        sep_and_whole = True\n",
    "elif separate_by_swap_or_not == 2:\n",
    "    pass\n",
    "else:\n",
    "    raise ValueError(f'Invalid value of \\'{separate_by_swap_or_not}\\' of type {type(separate_by_swap_or_not)} passed to `separate_by_swap_or_not`.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Block Start \n",
    "=============================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Would you like the parameter definitions to be concealed? (Y/N):\n",
      "y\n",
      "Thank you for choosing y\n"
     ]
    }
   ],
   "source": [
    "# Prompt user for whether they want the parameter definitions to be concealed\n",
    "\n",
    "def conceal_or_not():\n",
    "    conceal_param_defs = get_input(prompt='Would you like the parameter definitions to be concealed? (Y/N):\\n',\n",
    "                               success_conditions=[lambda x: isinstance(x, str), lambda x: x.upper() in ('Y', 'N')],\n",
    "                               failure_messages=['The value entered is not a string. Please enter \\'Y\\' or \\'N\\'.',\n",
    "                                                 'The value entered is neither \\'Y\\' nor \\'N\\'. Please enter a valid input.'])\n",
    "    if conceal_param_defs.upper() == 'Y':\n",
    "        conceal_param_defs = True\n",
    "    elif conceal_param_defs.upper() == 'N':\n",
    "        conceal_param_defs = False\n",
    "    else:\n",
    "        print(f'Invalid entry {conceal_param_defs} provided. Please try again')\n",
    "        return conceal_or_not()\n",
    "    \n",
    "    return conceal_param_defs\n",
    "\n",
    "conceal_params = conceal_or_not()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==============================\n",
    "# New Block End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving data for FV11.\n",
      "Parameters: \n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 14, 16, 32, 35, 39, 40, 54, 55, 56, 57, 58, 59, 60, 131, 140, 152, 153, 160, 161, 169]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data retrieved for FV11.\n",
      "Retrieving data for FV06.\n",
      "Parameters: \n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 14, 16, 32, 35, 39, 40, 54, 55, 56, 57, 58, 59, 60, 131, 140, 152, 153, 160, 161, 169]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data retrieved for FV06.\n",
      "Retrieving data for TW01.\n",
      "Parameters: \n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 14, 16, 32, 35, 39, 40, 54, 55, 56, 57, 58, 59, 60, 131, 140, 152, 153, 160, 161, 169]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data retrieved for TW01.\n",
      "Retrieving data for FV07.\n",
      "Parameters: \n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 14, 16, 32, 35, 39, 40, 54, 55, 56, 57, 58, 59, 60, 131, 140, 152, 153, 160, 161, 169]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data retrieved for FV07.\n",
      "Retrieving data for FV09.\n",
      "Parameters: \n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 14, 16, 32, 35, 39, 40, 54, 55, 56, 57, 58, 59, 60, 131, 140, 152, 153, 160, 161, 169]\n",
      "Data retrieved for FV09.\n",
      "Retrieving data for TW05.\n",
      "Parameters: \n",
      "[1, 2, 4, 6, 8, 11, 12, 14, 35, 39, 40, 54, 55, 57, 59, 79, 131, 140, 152, 153, 161, 173, 174, 176, 183, 184, 186]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data retrieved for TW05.\n",
      "Retrieving data for TW08.\n",
      "Parameters: \n",
      "[1, 2, 4, 6, 8, 11, 12, 14, 35, 39, 40, 54, 55, 57, 59, 79, 131, 140, 152, 153, 161, 173, 174, 176, 183, 184, 186]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data retrieved for TW08.\n",
      "Retrieving data for TW06.\n",
      "Parameters: \n",
      "[1, 2, 4, 6, 8, 11, 12, 14, 35, 39, 40, 54, 55, 57, 59, 79, 131, 140, 152, 153, 161, 173, 174, 176, 183, 184, 186]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TW06 has multiple system IDs - choosing 1.\n",
      "Data retrieved for TW06.\n",
      "Retrieving data for TV03.\n",
      "Parameters: \n",
      "[-1, 1, 3, 4, 7, 8, 12, 14, 31, 35, 39, 54, 55, 56, 57, 63, 68, 69, 99, 131, 140, 152, 153, 161, 173, 174, 176, 183, 184, 186, 246, 251]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data retrieved for TV03.\n",
      "Retrieving data for TW03.\n",
      "Parameters: \n",
      "[-1, 1, 3, 4, 7, 8, 12, 14, 31, 35, 39, 54, 55, 56, 57, 63, 68, 69, 99, 131, 140, 152, 153, 161, 173, 174, 176, 183, 184, 186, 246, 251]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data retrieved for TW03.\n",
      "Retrieving data for TV01.\n",
      "Parameters: \n",
      "[-1, 1, 3, 4, 7, 8, 12, 14, 31, 35, 39, 54, 55, 56, 57, 63, 68, 69, 99, 131, 140, 152, 153, 161, 173, 174, 176, 183, 184, 186, 246, 251]\n",
      "Data retrieved for TV01.\n",
      "Retrieving data for FV-13.\n",
      "Parameters: \n",
      "[-1, 1, 3, 4, 7, 8, 12, 14, 31, 35, 39, 54, 55, 56, 57, 63, 68, 69, 99, 131, 140, 152, 153, 161, 173, 174, 176, 183, 184, 186, 246, 251]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data retrieved for FV-13.\n",
      "Retrieving data for TV05.\n",
      "Parameters: \n",
      "[-1, 1, 3, 4, 7, 8, 12, 14, 31, 35, 39, 54, 55, 56, 57, 63, 68, 69, 99, 131, 140, 152, 153, 161, 173, 174, 176, 183, 184, 186, 246, 251]\n",
      "Data retrieved for TV05.\n",
      "Retrieving data for TV04.\n",
      "Parameters: \n",
      "[-1, 1, 3, 4, 7, 8, 12, 14, 31, 35, 39, 54, 55, 56, 57, 63, 68, 69, 99, 131, 140, 152, 153, 161, 173, 174, 176, 183, 184, 186, 246, 251]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data retrieved for TV04.\n",
      "Retrieving data for TW02.\n",
      "Parameters: \n",
      "[-1, 1, 3, 4, 7, 8, 12, 14, 31, 35, 39, 54, 55, 56, 57, 63, 68, 69, 99, 131, 140, 152, 153, 161, 173, 174, 176, 183, 184, 186, 246, 251]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data retrieved for TW02.\n",
      "Retrieving data for TW04.\n",
      "Parameters: \n",
      "[-1, 1, 3, 4, 7, 8, 12, 14, 31, 35, 39, 54, 55, 56, 57, 63, 68, 69, 99, 131, 140, 152, 153, 161, 173, 174, 176, 183, 184, 186, 246, 251]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data retrieved for TW04.\n",
      "Retrieving data for TV-02.\n",
      "Parameters: \n",
      "[-1, 1, 3, 4, 7, 8, 12, 14, 31, 35, 39, 54, 55, 56, 57, 63, 68, 69, 99, 131, 140, 152, 153, 161, 173, 174, 176, 183, 184, 186, 246, 251]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data retrieved for TV-02.\n",
      "Retrieving data for TW07.\n",
      "Parameters: \n",
      "[-1, 1, 3, 4, 7, 8, 12, 14, 31, 35, 39, 54, 55, 56, 57, 63, 68, 69, 99, 131, 140, 152, 153, 161, 173, 174, 176, 183, 184, 186, 246, 251]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data retrieved for TW07.\n",
      "Retrieving data for TW09.\n",
      "Parameters: \n",
      "[-1, 1, 3, 4, 7, 8, 12, 14, 31, 35, 39, 54, 55, 56, 57, 63, 68, 69, 99, 131, 140, 152, 153, 161, 173, 174, 176, 183, 184, 186, 246, 251]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\a00555655\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data retrieved for TW09.\n"
     ]
    }
   ],
   "source": [
    "## Obtain parameter information ##\n",
    "\n",
    "def get_parameters(systems, database, db_connection):\n",
    "\n",
    "    systems_parameter_info = {}\n",
    "        \n",
    "    for idx in range(len(systems)):\n",
    "\n",
    "        sys = systems[idx]\n",
    "\n",
    "        get_parameters_query = (f\"select DISTINCT a.SystemID, a.SystemTypeID, a.Description [SystemName], a.LastAlertLogTime, c.ParameterNumber, c.zzDescription,  c.SIUnitID\\\n",
    "                                from {database}..fst_GEN_System a \\\n",
    "                                join [{database}].[dbo].[fst_GEN_Parameter] b \\\n",
    "                                    on a.SystemTypeID = b.SystemTypeID \\\n",
    "                                join [{database}].[dbo].[fst_GEN_ParameterType] c \\\n",
    "                                    on b.SystemTypeID = c.SystemTypeID \\\n",
    "                                    and b.ParameterNumber = c.ParameterNumber \\\n",
    "                                where a.Description = \\'{sys}\\' \\\n",
    "                                order by a.SystemTypeID, a.Description\")\n",
    "\n",
    "        parameter_information = pd.read_sql_query(get_parameters_query, db_connection)\n",
    "        \n",
    "        systems_parameter_info[sys] = parameter_information\n",
    "        \n",
    "    return systems_parameter_info\n",
    "\n",
    "## Create a parameter mapping dictionary for all systems ##\n",
    "\n",
    "systems_parameter_info = get_parameters(systems=systems, database=database, db_connection=db_connection)\n",
    "\n",
    "systems_parameter_info['param_mapping'] = {}\n",
    "for system in systems:\n",
    "    zipped = list(zip(systems_parameter_info[system]['ParameterNumber'], systems_parameter_info[system]['zzDescription']))\n",
    "    systems_parameter_info['param_mapping'][system] = dict(zipped)\n",
    "\n",
    "systems_parameter_info['param_mapping']\n",
    "systems_to_check = list(systems_parameter_info['param_mapping'].keys())\n",
    "for key in systems_to_check:\n",
    "    if len(systems_parameter_info['param_mapping'][key]) == 0:\n",
    "        print(f'Removing \\'{key}\\' from the list of systems for which data will be retrieved because it has no parameter informaiton.')\n",
    "        systems_parameter_info['param_mapping'].pop(key)\n",
    "\n",
    "### Partition Parameters by the Associated Mechanical Part ###\n",
    "\n",
    "systems = list(systems_parameter_info['param_mapping'].keys())\n",
    "params_dict_partitioned = {system:{} for system in systems}\n",
    "for system in systems:\n",
    "    # print(systems_parameter_info['param_mapping'].keys())\n",
    "    # print(system)\n",
    "    # print(system in list(systems_parameter_info['param_mapping'].keys()))\n",
    "    params_sys = systems_parameter_info['param_mapping'][system]\n",
    "    params_sys_dict = {'DryPump':{},\n",
    "                       'Booster':{},\n",
    "                       'ExhaustAndShaft':{},\n",
    "                       'Flow':{},\n",
    "                       'RunTime':{},\n",
    "                       'Oil':{},\n",
    "                       'Others':{}}\n",
    "    for sys in params_sys.keys():\n",
    "        params_sys[sys] = params_sys[sys].replace(' ', '').replace('DP', 'DryPump').replace('MB', 'Booster')\n",
    "        if 'DP' in params_sys[sys] or 'Dry' in params_sys[sys]:\n",
    "            params_sys_dict['DryPump'][sys]=params_sys[sys]\n",
    "\n",
    "        elif 'Booster' in params_sys[sys] or 'MB' in params_sys[sys]:\n",
    "            params_sys_dict['Booster'][sys]=params_sys[sys]\n",
    "\n",
    "        elif 'Exhaust' in params_sys[sys] or 'Shaft' in params_sys[sys]:\n",
    "            params_sys_dict['ExhaustAndShaft'][sys]=params_sys[sys]\n",
    "\n",
    "        elif 'Time' in params_sys[sys] or 'Hours' in params_sys[sys]:\n",
    "            params_sys_dict['RunTime'][sys]=params_sys[sys]\n",
    "\n",
    "        elif 'Oil' in params_sys[sys]:\n",
    "            params_sys_dict['Oil'][sys]=params_sys[sys]\n",
    "            \n",
    "        elif 'Flow' in params_sys[sys]:\n",
    "            params_sys_dict['Flow'][sys]=params_sys[sys]\n",
    "\n",
    "        else:\n",
    "            params_sys_dict['Others'][sys]=params_sys[sys]\n",
    "    # for key in params_sys_dict.keys():\n",
    "    #     params_sys_dict[key].sort()\n",
    "    params_dict_partitioned[system] = params_sys_dict\n",
    "\n",
    "## Define directory paths ##\n",
    "\n",
    "AVAIL_FOLDER_PATH = os.path.join(MAIN_FOLDER_PATH, f'Availability')\n",
    "DATA_FOLDER_PATH = os.path.join(MAIN_FOLDER_PATH, 'Data')\n",
    "\n",
    "## Retrieve data for each system to store in parquet files ##\n",
    "\n",
    "systems_with_data = []\n",
    "systems_withou_data = []\n",
    "systems_param_mapping = {}\n",
    "for system in systems:\n",
    "\n",
    "    if not os.path.exists(DATA_FOLDER_PATH):\n",
    "        os.mkdir(DATA_FOLDER_PATH)\n",
    "    assert os.path.exists(DATA_FOLDER_PATH)\n",
    "    print(f'Retrieving data for {system}.')\n",
    "    system_parameters = list(systems_parameter_info['param_mapping'][f'{system}'].keys())\n",
    "    print(f'Parameters: \\n{system_parameters}')\n",
    "\n",
    "    # Get systems data:\n",
    "\n",
    "    parameters_as_string = str(system_parameters).replace('[', '(').replace(']', ')')\n",
    "\n",
    "    system_data_query = (f'SELECT t3.[Description], t4.[zzDescription], t1.[ParameterId], t1.[LogTime], t1.[Value] \\\n",
    "                           FROM [dbo].[fst_GEN_ParameterValue] AS t1 \\\n",
    "                           INNER JOIN [dbo].[fst_GEN_Parameter] AS t2 \\\n",
    "                            ON t1.[ParameterId] = t2.[ParameterID] \\\n",
    "                           INNER JOIN [dbo].[fst_GEN_System] AS t3 \\\n",
    "                            ON t2.[SystemID] = t3.[SystemID] \\\n",
    "                           INNER JOIN [dbo].fst_GEN_ParameterType AS t4 \\\n",
    "                            ON t2.[SystemTypeID] = t4.[SystemTypeID] \\\n",
    "                            AND t2.[ParameterNumber] = t4.[ParameterNumber] \\\n",
    "                           WHERE t3.[Description] = \\'{str(system)}\\' \\\n",
    "                           AND t2.[ParameterNumber] in {parameters_as_string} \\\n",
    "                           ORDER BY t1.[LogTime]')\n",
    "    \n",
    "    system_data = pd.read_sql_query(system_data_query, con=db_connection)\n",
    "\n",
    "    system_data['ParameterInfo'] = system_data['zzDescription'] + ' RID ' + system_data['ParameterId'].astype(str)\n",
    "\n",
    "    # Get system parameter mappings:\n",
    "\n",
    "    all_customer_systems_query = ('SELECT [SystemID], [SystemTypeID], [Description] '\n",
    "                                  'FROM [dbo].[fst_GEN_System] '\n",
    "                                  'ORDER BY [Description]')\n",
    "    all_customer_systems_res = pd.read_sql_query(all_customer_systems_query, con=db_connection)\n",
    "\n",
    "    system_type_ids = all_customer_systems_res.loc[all_customer_systems_res.Description == system, 'SystemTypeID']\n",
    "\n",
    "    if len(system_type_ids) == 0:\n",
    "        print(f'{system} has not system type in the database {database}. Removing this system from the systems for which data will be retrieved.')\n",
    "        del systems[system]\n",
    "        continue\n",
    "    elif len(system_type_ids) > 1:\n",
    "        print(f'{system} has multiple system IDs - choosing {str(max(system_type_ids))}.')\n",
    "    system_type_id= max(system_type_ids.values)\n",
    "    \n",
    "    get_parameters_info_query = (f'SELECT DISTINCT a.[ParameterNumber], [zzDescription], [SIUnitID] \\\n",
    "                                 FROM fst_GEN_Parameter a \\\n",
    "                                 INNER JOIN fst_GEN_ParameterType b \\\n",
    "                                     ON a.[SystemTypeID] = b.SystemTypeID \\\n",
    "                                     AND a.[ParameterNumber] = b.[ParameterNumber] \\\n",
    "                                 WHERE b.[SystemTypeId] = {str(system_type_id)} \\\n",
    "                                 ORDER BY a.[ParameterNumber] ASC')\n",
    "    \n",
    "    system_param_mapping = pd.read_sql_query(get_parameters_info_query, con=db_connection)\n",
    "    \n",
    "    systems_param_mapping[system] = dict(zip(system_param_mapping['ParameterNumber'].to_list(), system_param_mapping['zzDescription'].to_list()))\n",
    "\n",
    "    if system_data is not None:\n",
    "        file_path = os.path.join(DATA_FOLDER_PATH, system+'.parquet')\n",
    "        system_data.to_parquet(file_path, compression=None)\n",
    "        print(f'Data retrieved for {system}.')\n",
    "        systems_with_data.append(system)\n",
    "    \n",
    "    else:\n",
    "        print(f'There is no available data for {system}.')\n",
    "        systems_withou_data.append(system)\n",
    "        \n",
    "for sys in systems_param_mapping.keys():\n",
    "    sys_param_nums = list(systems_param_mapping[sys].keys())\n",
    "    for part in params_dict_partitioned[sys].keys():\n",
    "        for param_num in params_dict_partitioned[sys][part].keys():\n",
    "            if param_num in sys_param_nums:\n",
    "                params_dict_partitioned[sys][part][param_num] = systems_param_mapping[sys][param_num].replace(' ', '')\n",
    "            else:\n",
    "                params_dict_partitioned[sys][part].pop([param_num])\n",
    "\n",
    "systems_in_dict = list(params_dict_partitioned.keys())\n",
    "for sys in systems_in_dict:\n",
    "    if sys not in systems_with_data:\n",
    "        params_dict_partitioned.pop(sys)\n",
    "\n",
    "# Visualisation #\n",
    "\n",
    "DATA_FILES_DIR = DATA_FOLDER_PATH\n",
    "FIG_DIR = os.path.join(MAIN_FOLDER_PATH,'Figures')\n",
    "CSV_DIR = AVAIL_FOLDER_PATH\n",
    "if not os.path.exists(DATA_FOLDER_PATH):\n",
    "    os.mkdir(DATA_FOLDER_PATH)\n",
    "if not os.path.exists(FIG_DIR):\n",
    "    os.mkdir(FIG_DIR)\n",
    "if not os.path.exists(CSV_DIR):\n",
    "    os.mkdir(CSV_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concealed Parameter ID Mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing the FV-13 data for plotting.\n",
      "Run Time Columns []\n",
      "The system FV-13 does not have any parameters that include the strings `RunHours` nor `Time`. Therefore, it must not be a pump. Skipping.\n",
      "Preparing the FV06 data for plotting.\n",
      "Run Time Columns []\n",
      "The system FV06 does not have any parameters that include the strings `RunHours` nor `Time`. Therefore, it must not be a pump. Skipping.\n",
      "Preparing the FV07 data for plotting.\n",
      "Run Time Columns []\n",
      "The system FV07 does not have any parameters that include the strings `RunHours` nor `Time`. Therefore, it must not be a pump. Skipping.\n",
      "Preparing the FV09 data for plotting.\n",
      "Run Time Columns []\n",
      "The system FV09 does not have any parameters that include the strings `RunHours` nor `Time`. Therefore, it must not be a pump. Skipping.\n",
      "Preparing the FV11 data for plotting.\n",
      "Run Time Columns []\n",
      "The system FV11 does not have any parameters that include the strings `RunHours` nor `Time`. Therefore, it must not be a pump. Skipping.\n",
      "Preparing the TV-02 data for plotting.\n",
      "Run Time Columns []\n",
      "The system TV-02 does not have any parameters that include the strings `RunHours` nor `Time`. Therefore, it must not be a pump. Skipping.\n",
      "Preparing the TV01 data for plotting.\n",
      "Run Time Columns []\n",
      "The system TV01 does not have any parameters that include the strings `RunHours` nor `Time`. Therefore, it must not be a pump. Skipping.\n",
      "Preparing the TV03 data for plotting.\n",
      "Run Time Columns []\n",
      "The system TV03 does not have any parameters that include the strings `RunHours` nor `Time`. Therefore, it must not be a pump. Skipping.\n",
      "Preparing the TV04 data for plotting.\n",
      "Run Time Columns []\n",
      "The system TV04 does not have any parameters that include the strings `RunHours` nor `Time`. Therefore, it must not be a pump. Skipping.\n",
      "Preparing the TV05 data for plotting.\n",
      "Run Time Columns []\n",
      "The system TV05 does not have any parameters that include the strings `RunHours` nor `Time`. Therefore, it must not be a pump. Skipping.\n",
      "Preparing the TW01 data for plotting.\n",
      "Run Time Columns ['CumulativeRunTimeRID876']\n",
      "Data for system TW01 retrieved.\n",
      "Swap dates for system TW01 isolated.\n",
      "Data for system TW01 partitioned by swap date.\n",
      "System swap dates: [Timestamp('2022-09-05 01:00:24.143000')]\n",
      "Data for TW01 prepared for plotting!\n",
      "Preparing the TW02 data for plotting.\n",
      "Run Time Columns ['DPRunHoursRID10409']\n",
      "Data for system TW02 retrieved.\n",
      "condition_1: \n",
      "True\n",
      "\n",
      "condition_2: \n",
      "True\n",
      "\n",
      "current_run_hrs: \n",
      "19488.0\n",
      "\n",
      "last_future_val: \n",
      "ParameterInfo\n",
      "DPRunHoursRID10409    417.0\n",
      "pump_num                1.0\n",
      "Name: 2021-09-25 15:08:46.557000, dtype: float64\n",
      "Swap dates for system TW02 isolated.\n",
      "Data for system TW02 partitioned by swap date.\n",
      "System swap dates: [Timestamp('2021-01-27 17:26:44.967000'), Timestamp('2021-09-24 15:28:33.027000')]\n",
      "Data for TW02 prepared for plotting!\n",
      "Preparing the TW03 data for plotting.\n",
      "Run Time Columns ['DPRunHoursRID11146']\n",
      "Data for system TW03 retrieved.\n",
      "Swap dates for system TW03 isolated.\n",
      "Data for system TW03 partitioned by swap date.\n",
      "System swap dates: [Timestamp('2021-06-02 11:07:05.650000')]\n",
      "Data for TW03 prepared for plotting!\n",
      "Preparing the TW04 data for plotting.\n",
      "Run Time Columns ['DPRunHoursRID6419']\n",
      "Data for system TW04 retrieved.\n",
      "Swap dates for system TW04 isolated.\n",
      "Data for system TW04 partitioned by swap date.\n",
      "System swap dates: [Timestamp('2021-01-01 00:00:08.973000')]\n",
      "Data for TW04 prepared for plotting!\n",
      "Preparing the TW05 data for plotting.\n",
      "Run Time Columns ['CumulativeRunTimeRID1297']\n",
      "Data for system TW05 retrieved.\n",
      "Swap dates for system TW05 isolated.\n",
      "Data for system TW05 partitioned by swap date.\n",
      "System swap dates: [Timestamp('2022-09-05 00:18:02.357000')]\n",
      "Data for TW05 prepared for plotting!\n",
      "Preparing the TW06 data for plotting.\n",
      "Run Time Columns ['CumulativeRunTimeRID14843']\n",
      "Data for system TW06 retrieved.\n",
      "condition_1: \n",
      "True\n",
      "\n",
      "condition_2: \n",
      "True\n",
      "\n",
      "current_run_hrs: \n",
      "26349.0\n",
      "\n",
      "last_future_val: \n",
      "ParameterInfo\n",
      "CumulativeRunTimeRID14843    24.0\n",
      "pump_num                      1.0\n",
      "Name: 2022-08-19 04:07:29.487000, dtype: float64\n",
      "Swap dates for system TW06 isolated.\n",
      "Data for system TW06 partitioned by swap date.\n",
      "System swap dates: [Timestamp('2022-08-09 16:53:53.300000'), Timestamp('2022-08-18 04:52:32.270000')]\n",
      "Data for TW06 prepared for plotting!\n",
      "Preparing the TW07 data for plotting.\n",
      "Run Time Columns ['DPRunHoursRID11134']\n",
      "Data for system TW07 retrieved.\n",
      "Swap dates for system TW07 isolated.\n",
      "Data for system TW07 partitioned by swap date.\n",
      "System swap dates: [Timestamp('2022-09-05 00:32:19.037000')]\n",
      "Data for TW07 prepared for plotting!\n",
      "Preparing the TW08 data for plotting.\n",
      "Run Time Columns ['CumulativeRunTimeRID424']\n",
      "Data for system TW08 retrieved.\n",
      "Swap dates for system TW08 isolated.\n",
      "Data for system TW08 partitioned by swap date.\n",
      "System swap dates: [Timestamp('2022-09-05 01:35:24.827000')]\n",
      "Data for TW08 prepared for plotting!\n",
      "Preparing the TW09 data for plotting.\n",
      "Run Time Columns ['DPRunHoursRID6432']\n",
      "Data for system TW09 retrieved.\n",
      "Swap dates for system TW09 isolated.\n",
      "Data for system TW09 partitioned by swap date.\n",
      "System swap dates: [Timestamp('2022-09-05 00:41:09.413000')]\n",
      "Data for TW09 prepared for plotting!\n",
      "\n",
      "\n",
      "Data retrieved and prepared for the following systems: \n",
      "TW01\n",
      "TW02\n",
      "TW03\n",
      "TW04\n",
      "TW05\n",
      "TW06\n",
      "TW07\n",
      "TW08\n",
      "TW09\n"
     ]
    }
   ],
   "source": [
    "## Prepare the data in the parquet files for plotting ##\n",
    "\n",
    "def plot_prep_from_parquet(data_files_dir, include_system_names_like=None):\n",
    "\n",
    "    \"\"\"\n",
    "    Prepares the data that has already been written to parquet files for plotting. In particular, \n",
    "    this function separates the data for each system by swap date. It does so by partitioning the\n",
    "    provisioned data by any columns whose name contains any of the following substrings:\n",
    "    ('Run Hours', 'Time')\n",
    "    \n",
    "    Inputs:\n",
    "    - data_files_dir (str): Full path or path from current working directory where the parquet files containing the system parametric data are stored.\n",
    "    \n",
    "    - include_system_names_like (str or list(str)): String or list of strings of the types of system names whose data we wish to  prepare. For instance, to prepare data for the systems that contain the substring 'iH1000' and 'iH2000', pass ['iH1000', 'iH2000']. DEFAULT is None and, in this case, all of the files in the provisioned directory are parsed.\n",
    "    \n",
    "    Outputs:\n",
    "    - all_systems_data: A dictionary containing the data for the specified types of system names (if any were passed) partitioned by swap dates (if any swaps occurred).\n",
    "    \n",
    "    NB: If a system does not have any columns with the substring 'Run Hours' or 'Time', the system will be assumed to not be a pump and therefore skipped. Its data will not appear in the output.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    files = os.listdir(data_files_dir)\n",
    "    if include_system_names_like != None:\n",
    "        if type(include_system_names_like)==str:\n",
    "            files = [file for file in files if include_system_names_like in file]\n",
    "\n",
    "        elif type(include_system_names_like)==list or type(include_system_names_like)==tuple:\n",
    "            files = [file for file in files if any(name_like in file for name_like in include_system_names_like)]\n",
    "\n",
    "        else:\n",
    "            raise TypeError(f\"The argument `include_system_names_like` does not take assignments of type {type(include_system_names_like)}. Please pass a string or list of strings to this argument.\")\n",
    "\n",
    "    system_names=[]\n",
    "    all_systems_data = {}\n",
    "\n",
    "    for file_name in files:\n",
    "\n",
    "        # Get the system data and format correctly:\n",
    "\n",
    "        system_name = re.split(r'\\.', file_name)[0]\n",
    "        system_names.append(system_name)\n",
    "        system_data = pd.read_parquet(os.path.join(data_files_dir, file_name))\n",
    "        print(f'Preparing the {system_name} data for plotting.')\n",
    "        \n",
    "        # Convert DataFrame from long to wide format and sort by LogTime:\n",
    "        \n",
    "        system_data = system_data.pivot_table(index='LogTime',\n",
    "                                              columns='ParameterInfo',\n",
    "                                              values='Value').sort_values(by='LogTime')\n",
    "        \n",
    "        system_data = system_data.rename(columns={col_name:col_name.replace(' ', '') for col_name in system_data.columns})\n",
    "        \n",
    "        system_data.sort_values(by='LogTime')\n",
    "\n",
    "        run_time_cols = list(set([col_name for col_name in system_data.columns \n",
    "                                                        if 'Time' in col_name \n",
    "                                                        or 'RunHours' in col_name\n",
    "                                                        or 'Hour' in col_name]))\n",
    "\n",
    "        print(f'Run Time Columns {run_time_cols}')\n",
    "\n",
    "        try:\n",
    "            assert len(run_time_cols) > 0\n",
    "            run_time_col = run_time_cols[0]\n",
    "            # system_data.rename({run_time_col:'RunHours'}, axis=1, inplace=True)\n",
    "            \n",
    "        except:\n",
    "            # raise ValueError\n",
    "            print(f\"The system {system_name} does not have any parameters that include the strings `RunHours` nor `Time`. Therefore, it must not be a pump. Skipping.\")\n",
    "            continue\n",
    "            \n",
    "        print(f'Data for system {system_name} retrieved.')\n",
    "\n",
    "        # Separate data by the swap number:\n",
    "\n",
    "        run_hours = system_data[[run_time_col]][~system_data[run_time_col].isna()]\n",
    "        run_hours_idx_list = list(run_hours.index)\n",
    "        first_datum_idx = run_hours.index.min()\n",
    "        first_datum_idx_num = run_hours_idx_list.index(first_datum_idx)\n",
    "        swap_dates = [first_datum_idx]\n",
    "        current_swap_num = 1\n",
    "\n",
    "        run_hours['pump_num'] = current_swap_num\n",
    "        for idx_num in range(0, len(run_hours.index)-1):\n",
    "\n",
    "            if idx_num in [0]:\n",
    "                continue\n",
    "\n",
    "            condition_1 = abs(run_hours.iloc[idx_num][run_time_col] - run_hours.iloc[idx_num + 1][run_time_col]) > 30\n",
    "\n",
    "            # condition_2 ensures that the low difference in run_hours identified by condition_1 is \n",
    "            # not due to a break in incoming data\n",
    "\n",
    "            current_dt = run_hours.index[idx_num]\n",
    "            prev_dt = run_hours.index[idx_num-2]\n",
    "            try:\n",
    "                current_run_hrs = run_hours[run_time_col].loc[current_dt].iloc[0]\n",
    "            except:\n",
    "                try:\n",
    "                    current_run_hrs = run_hours[run_time_col].loc[current_dt]\n",
    "                except:\n",
    "                    print('wtf')\n",
    "\n",
    "            time_diff = ((run_hours.index[idx_num+1] - run_hours.index[idx_num])) + datetime.timedelta(hours=24)\n",
    "            hrs_diff = float((time_diff/np.timedelta64(1, 'h')))\n",
    "            future_dt = run_hours.index[idx_num] + time_diff\n",
    "            current_dt = run_hours.index[idx_num]\n",
    "            try:\n",
    "                current_run_hrs = run_hours.loc[current_dt].iloc[0]\n",
    "            except:\n",
    "                current_run_hrs = run_hours.loc[current_dt]\n",
    "            # print(run_hours.index[idx_num], run_hours.loc[run_hours.index[idx_num]]) \n",
    "            # print(run_hours.index[idx_num+1], run_hours.loc[run_hours.index[idx_num+1]])\n",
    "            # print(hrs_diff) \n",
    "            # print(future_dt, run_hours.loc[future_dt[0]-datetime.timedelta(hours=2):future_dt[0]])\n",
    "            local_future_run_hrs = run_hours.loc[current_dt:future_dt]\n",
    "            last_future_val = local_future_run_hrs.iloc[-1]\n",
    "            condition_2 = (current_run_hrs - last_future_val)[run_time_col] > hrs_diff\n",
    "\n",
    "            try:\n",
    "                if condition_1 and condition_2:\n",
    "                    print(f'condition_1: \\n{condition_1}\\n\\ncondition_2: \\n{condition_2}\\n\\ncurrent_run_hrs: \\n{current_run_hrs}\\n\\nlast_future_val: \\n{last_future_val}')\n",
    "            #                 print(7)\n",
    "                    current_swap_num += 1\n",
    "                    swap_dates.append(run_hours.index[idx_num+1])\n",
    "            except:\n",
    "                raise ValueError(f'condition_1: \\n{condition_1}\\n\\ncondition_2: \\n{condition_2}\\n\\ncurrent_run_hrs: \\n{current_run_hrs}\\n\\nlast_future_val: \\n{last_future_val}')\n",
    "\n",
    "            run_hours.loc[run_hours.index[idx_num], 'pump_num'] = current_swap_num\n",
    "\n",
    "        run_hours['pump_num'] = run_hours['pump_num'].fillna(method='ffill').fillna(method='bfill')\n",
    "\n",
    "        print(f'Swap dates for system {system_name} isolated.')\n",
    "\n",
    "        all_systems_data[system_name] = {}\n",
    "\n",
    "        all_systems_data[system_name]['swap_dates'] = swap_dates\n",
    "\n",
    "        # Check if any swaps took place\n",
    "        if len(swap_dates) == 0:\n",
    "            all_systems_data[system_name]['pump_1'] = system_data\n",
    "\n",
    "        elif len(swap_dates) == 1:\n",
    "            all_systems_data[system_name]['pump_1'] = system_data[swap_dates[0]:]\n",
    "\n",
    "        elif len(swap_dates) > 1:\n",
    "            # Add the data, separated by swap number, into the system_data_all dictionary:\n",
    "            for swap_dt_idx in range(len(swap_dates)):\n",
    "                pump_num = swap_dt_idx+1\n",
    "                swap_dt = swap_dates[swap_dt_idx]\n",
    "                if swap_dt_idx == len(swap_dates)-1:\n",
    "                    all_systems_data[system_name][f\"pump_{pump_num}\"] = system_data[swap_dt:]\n",
    "                else:\n",
    "                    next_swap_dt = swap_dates[swap_dt_idx+1]\n",
    "                    all_systems_data[system_name][f\"pump_{pump_num}\"] = system_data[swap_dt:next_swap_dt]\n",
    "\n",
    "            if all_systems_data[system_name]['swap_dates'][0] == all_systems_data[system_name]['swap_dates'][1]:\n",
    "                del all_systems_data[system_name]['swap_dates'][0]\n",
    "                pump_key_nums = [key for key in all_systems_data[system_name].keys() if key!='swap_dates']\n",
    "                for p_num in range(1,len(pump_key_nums)):\n",
    "                    new_key = f'pump_{p_num}'\n",
    "                    old_key = f'pump_{p_num+1}'\n",
    "                    all_systems_data[system_name][new_key] = all_systems_data[system_name][old_key]\n",
    "                    del all_systems_data[system_name][old_key]\n",
    "\n",
    "        print(f'Data for system {system_name} partitioned by swap date.')\n",
    "        \n",
    "        print(f'System swap dates: {all_systems_data[system_name][\"swap_dates\"]}')\n",
    "\n",
    "        print(f\"Data for {system_name} prepared for plotting!\")\n",
    "\n",
    "    if len(all_systems_data) > 0:\n",
    "        print(f\"\\n\\nData retrieved and prepared for the following systems: \")\n",
    "        for system in all_systems_data.keys():\n",
    "            print(system)\n",
    "    \n",
    "    else:\n",
    "        print('No data found for the specified systems.')\n",
    "    \n",
    "    return all_systems_data\n",
    "\n",
    "all_systems_data = plot_prep_from_parquet(DATA_FILES_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define a function to partition parameters into type of process\n",
    "\n",
    "def order_parameters(data, cols, conceal_params=False):\n",
    "    \n",
    "    '''\n",
    "    The function:\n",
    "    1. Separates the parameters into groups \n",
    "    2. Changes the units of columns with temperature, pressure and flow from Kelvin, Pa and m^3/s to degrees Celcius, PSI and liters/minute, respectively.\n",
    "    All of this is then used for columnar plotting by the function `interactive_plot_custom_data_1`.'''\n",
    "    parameters_ordered = {'DryPump (DP)':[],\n",
    "                          'Booster (MB)':[],\n",
    "                          'ExhaustAndShaft (ES)':[],\n",
    "                          'RunTime (RT)':[],\n",
    "                          'Oil (OL)':[],\n",
    "                          'Flow (FW)':[],\n",
    "                          'Motor (MR)':[],\n",
    "                          'Vibration (VR)':[],\n",
    "                          'Pos (PS)':[],\n",
    "                          'MagneticBearing (MC)':[],\n",
    "                          'MiscellaneousTemperatures (MT)':[],\n",
    "                          'Other (OT)':[]}\n",
    "    \n",
    "    data = data.rename(columns={col:col.replace(' ', '').replace('DP', 'DryPump').replace('MB', 'Booster') for col in data.columns})\n",
    "    \n",
    "    for column in data.columns:\n",
    "        if ('Dry' in column or 'DP' in column) and ('Hours' not in column and 'Time' not in column):\n",
    "            parameters_ordered['DryPump (DP)'].append(column)\n",
    "        elif 'Booster' in column or 'MB' in column:\n",
    "            parameters_ordered['Booster (MB)'].append(column)\n",
    "        elif 'Exhaust' in column or 'Shaft' in column:\n",
    "            parameters_ordered['ExhaustAndShaft (ES)'].append(column)\n",
    "        elif 'Oil' in column:\n",
    "            parameters_ordered['Oil (OL)'].append(column)\n",
    "        elif 'Hour' in column or 'Time' in column:\n",
    "            parameters_ordered['RunTime (RT)'].append(column)\n",
    "        elif 'Flow' in column:\n",
    "            parameters_ordered['Flow (FW)'].append(column)\n",
    "        elif 'Motor' in column:\n",
    "            parameters_ordered['Motor (MR)'].append(column)\n",
    "        elif 'Vib' in column:\n",
    "            parameters_ordered['Vibration (VR)'].append(column)\n",
    "        elif 'Pos' in column:\n",
    "            parameters_ordered['Pos (PS)'].append(column)\n",
    "        elif 'Magnetic' in column:\n",
    "            parameters_ordered['MagneticBearing (MC)'].append(column)\n",
    "        elif 'Temperature' in column:\n",
    "            parameters_ordered['MiscellaneousTemperatures (MT)'].append(column)\n",
    "        else:\n",
    "            parameters_ordered['Other (OT)'].append(column)\n",
    "        \n",
    "        if 'temp' in column.lower():\n",
    "            data[column] = data[column] - 273.15\n",
    "        elif 'pressure' in column.lower():\n",
    "            data[column] = data[column] * 0.000145038\n",
    "        elif 'flow' in column.lower():\n",
    "            data[column] = data[column] * 60000\n",
    "    \n",
    "    parameters_ordered_concealed = {}\n",
    "    \n",
    "    for key in parameters_ordered.keys():\n",
    "        parameters_ordered[key].sort()\n",
    "        left_idx = key.index('(')+1\n",
    "        right_idx = key.index(')')\n",
    "        concealed_key = key[left_idx:right_idx]\n",
    "        parameters_ordered_concealed[concealed_key] = parameters_ordered[key]\n",
    "    \n",
    "    if cols==None:\n",
    "        cols = data.columns\n",
    "        \n",
    "    if conceal_params:\n",
    "        return parameters_ordered_concealed, data\n",
    "    else:\n",
    "        return parameters_ordered, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define a function to compute sma and ewma for each parameter passed\n",
    "\n",
    "def moving_averages(data, \n",
    "                    current_parameter, \n",
    "                    run_time_data=False,\n",
    "                    ewma_span=None,\n",
    "                    ewma_com=None,\n",
    "                    ewma_halflife=None,\n",
    "                    ewma_alpha=None,\n",
    "                    ewma_min_periods=None,\n",
    "                    ewma_adjust=True,\n",
    "                    ewma_ignore_na=False,\n",
    "                    resampling_frequency='12H',\n",
    "                    rolling_period='14D'):\n",
    "\n",
    "    if not run_time_data:\n",
    "        start_date = data.index.min()\n",
    "        end_date = data.index.max()\n",
    "        data = data.loc[~data.index.duplicated()]\n",
    "        old_data = data.copy()\n",
    "        new_index = pd.date_range(start=start_date,\n",
    "                                  end=end_date,\n",
    "                                  freq=resampling_frequency)\n",
    "        smoothed_data = data[data.notna()].reindex(new_index, method='ffill')\n",
    "        smoothed_data.index.name='LogTime'\n",
    "        col_data_df = pd.DataFrame(smoothed_data)\n",
    "\n",
    "        # Simple Moving Average:\n",
    "        sma_parameter = f'{current_parameter}_SimpleMovingAverage'\n",
    "        sma_col_data = col_data_df[current_parameter].rolling(rolling_period).mean()\n",
    "        col_data_df[sma_parameter] = sma_col_data\n",
    "\n",
    "        # Exponentially Weighted Moving Average:\n",
    "        ewma_parameter = f'{current_parameter}_ExpontentiallyWeightedMovingAverage'\n",
    "        ewma_col_data = col_data_df[current_parameter].ewm(span=ewma_span,\n",
    "                                                           com=ewma_com,\n",
    "                                                           halflife=ewma_halflife,\n",
    "                                                           alpha=ewma_alpha,\n",
    "                                                           min_periods=ewma_min_periods,\n",
    "                                                           adjust=ewma_adjust,\n",
    "                                                           ignore_na=ewma_ignore_na).mean()\n",
    "        col_data_df[ewma_parameter] = ewma_col_data\n",
    "        col_data_df = col_data_df.reindex(old_data.index, \n",
    "                                          method='ffill')\n",
    "        col_data_df[current_parameter] = old_data\n",
    "        return col_data_df, sma_parameter, ewma_parameter\n",
    "    \n",
    "    else:\n",
    "        col_data_df = pd.DataFrame(data[data.notna()])\n",
    "        return col_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create dashboards ##\n",
    "\n",
    "def interactive_plot_system_data_1(data,\n",
    "                                 save_dest,\n",
    "                                 system,\n",
    "                                 system_position,\n",
    "                                 customer_name,\n",
    "                                 cols=None,\n",
    "                                 save=True,\n",
    "                                 show_plots=False,\n",
    "                                 conceal_params=False):\n",
    "    \n",
    "    \n",
    "    start_datetime = data.index.min().strftime('%d/%m/%Y %H:%M:%S')\n",
    "\n",
    "    end_datetime = data.index.max().strftime('%d/%m/%Y %H:%M:%S')\n",
    "    \n",
    "    system_name = f\"{system_position}: {system.capitalize().replace('_', ' ')}, Start Date-Time: {start_datetime}, End Date-Time: {end_datetime}\"\n",
    "\n",
    "    parameters_ordered, data = order_parameters(data, cols, conceal_params=conceal_params)\n",
    "    \n",
    "    parts_plots = {}\n",
    "    count = 0\n",
    "    for i in parameters_ordered.keys():\n",
    "        # print(f'\\npart parames before anything: \\n{parameters_ordered}')\n",
    "        # parameters_ordered[i] = [parameters_ordered[i][j] for j in parameters_ordered[i] if j in data.columns]\n",
    "        # print(f'\\npart params after checking against data columns: \\n{parameters_ordered}')\n",
    "        part_data = data[parameters_ordered[i]]\n",
    "#         return part_data\n",
    "        part_data = part_data.rename({col:col.replace(' ', '') for col in part_data.columns}, axis=1)\n",
    "        parameters_ordered[i] = [param.replace(' ', '') for param in parameters_ordered[i]]\n",
    "        parts_plots[i] = []\n",
    "        # print(parameters_ordered)\n",
    "        for j in range(len(parameters_ordered[i])):\n",
    "            col_data = part_data[parameters_ordered[i][j]]\n",
    "            # print(type(col_data))\n",
    "            if col_data.notna().sum() < 1:\n",
    "                continue\n",
    "            elif col_data.notna().sum() < 15:\n",
    "                radius_size=3\n",
    "            else:\n",
    "                radius_size=0.8\n",
    "            current_parameter = parameters_ordered[i][j]\n",
    "            \n",
    "\n",
    "\n",
    "            col_data = col_data[col_data.notna()]\n",
    "            \n",
    "            if 'RT' not in i:\n",
    "                col_data_df, sma_parameter, ewma_parameter = moving_averages(col_data, \n",
    "                                                                         current_parameter=current_parameter,\n",
    "                                                                         run_time_data=False,\n",
    "                                                                         rolling_period='14D',\n",
    "                                                                         ewma_alpha=0.15,\n",
    "                                                                         ewma_adjust=False)\n",
    "                if conceal_params:\n",
    "                    left_raw_idx = current_parameter.index('RID')\n",
    "                    left_sma_idx = sma_parameter.index('RID')\n",
    "                    left_ewma_idx = ewma_parameter.index('RID')\n",
    "                    raw_label = f'{customer_name}_{current_parameter[left_raw_idx:]}'\n",
    "                    sma_label = f'{customer_name}_{sma_parameter[left_sma_idx:]}'\n",
    "                    ewma_label = f'{customer_name}_{ewma_parameter[left_ewma_idx:]}'\n",
    "                    \n",
    "                else:\n",
    "                    raw_label = current_parameter\n",
    "                    sma_label = sma_parameter\n",
    "                    ewma_label = ewma_parameter\n",
    "                \n",
    "                source = plotting.ColumnDataSource(col_data_df)\n",
    "\n",
    "                # Create interactive hovertool\n",
    "                fig_hover_tool = HoverTool(tooltips=[('LogTime', '@LogTime{%Y-%m-%d %H:%M:%S.%3N}'),\n",
    "                                                    (f'{raw_label}', f'@{current_parameter}'),\n",
    "                                                    (f'{sma_label}', f'@{sma_parameter}'),\n",
    "                                                    (f'{ewma_label}', f'@{sma_parameter}')],\n",
    "                                           formatters={'@LogTime':'datetime'},\n",
    "                                           mode='mouse')    \n",
    "\n",
    "            else:\n",
    "                col_data_df = moving_averages(col_data,\n",
    "                                              current_parameter=current_parameter,\n",
    "                                              run_time_data=True,\n",
    "                                              rolling_period='14D',\n",
    "                                              ewma_alpha=0.15,\n",
    "                                              ewma_adjust=False)\n",
    "                source = plotting.ColumnDataSource(col_data_df)\n",
    "                # Create interactive hovertool\n",
    "                fig_hover_tool = HoverTool(tooltips=[('LogTime', '@LogTime{%Y-%m-%d %H:%M:%S.%3N}'),\n",
    "                                                    (f'{raw_label}', f'@{current_parameter}')],\n",
    "                                           formatters={'@LogTime':'datetime'},\n",
    "                                           mode='mouse')\n",
    "            \n",
    "            if count > 0:\n",
    "                fig = plotting.figure(x_axis_label='DateTime',\n",
    "                                      y_axis_label=raw_label,\n",
    "                                      x_range=shared_x_range,\n",
    "                                      x_axis_type='datetime',\n",
    "                                      title=raw_label)\n",
    "                # print(f'\\n\\nData plotted for {system_position} {system} {i}:{j}')\n",
    "            \n",
    "            else:\n",
    "                fig = plotting.figure(x_axis_label='DateTime',\n",
    "                                      y_axis_label=raw_label,\n",
    "                                      x_axis_type='datetime',\n",
    "                                      title=raw_label)\n",
    "                # print(f'\\n\\nData plotted for {system_position} {system} {i}:{j}')\n",
    "            \n",
    "            if count == 0:\n",
    "                count += 1\n",
    "                shared_x_range = fig.x_range\n",
    "\n",
    "            fig.line(x='LogTime', \n",
    "                     y=current_parameter, \n",
    "                     source=source, \n",
    "                     color='#47ed00',\n",
    "                     line_alpha=0.7,\n",
    "                     muted_alpha=0.2,\n",
    "                     legend_label=raw_label)\n",
    "            \n",
    "            fig.add_tools(fig_hover_tool)\n",
    "            \n",
    "            if 'RT' not in i:\n",
    "                fig.line(x='LogTime',\n",
    "                        y=sma_parameter,\n",
    "                        source=source,\n",
    "                        color='red',\n",
    "                        line_alpha=1,\n",
    "                        muted_alpha=0.1,\n",
    "                        legend_label=sma_label)\n",
    "\n",
    "                fig.line(x='LogTime',\n",
    "                        y=ewma_parameter,\n",
    "                        source=source,\n",
    "                        color='blue',\n",
    "                        line_alpha=1,\n",
    "                        muted_alpha=0.2,\n",
    "                        legend_label=ewma_label)\n",
    "\n",
    "            fig.circle(x='LogTime',\n",
    "                       y=current_parameter,\n",
    "                       source=source,\n",
    "                       color='green',\n",
    "                       radius=radius_size)\n",
    "            \n",
    "            fig.title.text_font_size = '12pt'\n",
    "\n",
    "            fig.xaxis.major_label_orientation = math.pi/4\n",
    "\n",
    "            fig.axis.axis_label_text_font_size = '10px'\n",
    "\n",
    "            fig.legend.title = 'Legend'\n",
    "\n",
    "            fig.legend.title_text_font_size = '12pt'\n",
    "\n",
    "            fig.legend.title_text_font_style = 'italic'\n",
    "\n",
    "            fig.legend.title_text_color = 'white'\n",
    "\n",
    "            fig.legend.location = 'top_left'\n",
    "\n",
    "            fig.legend.border_line_alpha = 1\n",
    "\n",
    "            fig.legend.border_line_color = 'black'\n",
    "\n",
    "            fig.legend.background_fill_alpha = 0.7\n",
    "\n",
    "            fig.legend.background_fill_color = 'grey'\n",
    "\n",
    "            fig.legend.click_policy = 'hide'\n",
    "\n",
    "            fig.legend.label_text_font_size = '12pt'\n",
    "\n",
    "            fig.legend.label_text_font_style = 'italic'\n",
    "\n",
    "            fig.legend.label_text_color = 'white'\n",
    "            \n",
    "            # fig.add_layout(fig.legend[0], 'right')\n",
    "\n",
    "            parts_plots[i].append(fig)\n",
    "    \n",
    "    \n",
    "    plot_title = Div(text=f\"{system_name}\",\n",
    "                     style={'font-size':'30px', 'color':'black'}) #, style={'font-size':'300%', \n",
    "                                            #       'color':'black', \n",
    "                                            #       'text-align':'center', \n",
    "                                            #       'margin':'auto'})\n",
    "    \n",
    "    plot_columns = []\n",
    "    for key in parts_plots.keys():\n",
    "        if len(parts_plots[key]) > 0:\n",
    "            part_name = Div(text=f'{key} Parameters',\n",
    "                            style={'font-size':'22px', 'color':'black'})\n",
    "            plot_columns.append(layouts.column(part_name, layouts.column(parts_plots[key])))\n",
    "\n",
    "    if save:\n",
    "        io.output_file(os.path.join(save_dest, \n",
    "                                    f\"{system_position} {system}.html\"))\n",
    "        \n",
    "        plotting.save(layouts.column(plot_title,\n",
    "                                     layouts.row(plot_columns)))\n",
    "        \n",
    "    if show_plots:\n",
    "        io.show(layouts.column(plot_title,\n",
    "                                     layouts.row(plot_columns)))\n",
    "        \n",
    "bokeh_system_data_plotters = {'mk1':interactive_plot_system_data_1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Working on the separated by swap date plot for TW01 pump_1.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:bokeh.core.validation.check:E-1001 (BAD_COLUMN_NAME): Glyph refers to nonexistent column name. This could either be due to a misspelling or typo, or due to an expected column being missing. : key \"y\" value \"ShaftSealPressureRID1862_ExpontentiallyWeightedMovingAverage\" [renderer: GlyphRenderer(id='566310', ...)]\n",
      "ERROR:bokeh.core.validation.check:E-1001 (BAD_COLUMN_NAME): Glyph refers to nonexistent column name. This could either be due to a misspelling or typo, or due to an expected column being missing. : key \"y\" value \"ShaftSealPressureRID1862_SimpleMovingAverage\" [renderer: GlyphRenderer(id='566281', ...)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDashboard for TW01 pump_1 generated and placed within 'C:\\Users\\a00555655\\OneDrive - ONEVIRTUALOFFICE\\Documents\\Dashboards\\XFAB_France\\2022-12-15\\Figures.'\u001b[0m\n",
      "\n",
      "Working on the plot for all of the data on TW01.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:bokeh.core.validation.check:E-1001 (BAD_COLUMN_NAME): Glyph refers to nonexistent column name. This could either be due to a misspelling or typo, or due to an expected column being missing. : key \"y\" value \"ShaftSealPressureRID1862_ExpontentiallyWeightedMovingAverage\" [renderer: GlyphRenderer(id='572228', ...)]\n",
      "ERROR:bokeh.core.validation.check:E-1001 (BAD_COLUMN_NAME): Glyph refers to nonexistent column name. This could either be due to a misspelling or typo, or due to an expected column being missing. : key \"y\" value \"ShaftSealPressureRID1862_SimpleMovingAverage\" [renderer: GlyphRenderer(id='572199', ...)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDashboard for all of the data on TW01 generated and placed within 'C:\\Users\\a00555655\\OneDrive - ONEVIRTUALOFFICE\\Documents\\Dashboards\\XFAB_France\\2022-12-15\\Figures.'\u001b[0m\n",
      "\n",
      "Working on the separated by swap date plot for TW02 pump_1.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:bokeh.core.validation.check:E-1001 (BAD_COLUMN_NAME): Glyph refers to nonexistent column name. This could either be due to a misspelling or typo, or due to an expected column being missing. : key \"y\" value \"ExhaustPressureRID10403_SimpleMovingAverage\" [renderer: GlyphRenderer(id='578375', ...)]\n",
      "ERROR:bokeh.core.validation.check:E-1001 (BAD_COLUMN_NAME): Glyph refers to nonexistent column name. This could either be due to a misspelling or typo, or due to an expected column being missing. : key \"y\" value \"ExhaustPressureRID10403_ExpontentiallyWeightedMovingAverage\" [renderer: GlyphRenderer(id='578404', ...)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDashboard for TW02 pump_1 generated and placed within 'C:\\Users\\a00555655\\OneDrive - ONEVIRTUALOFFICE\\Documents\\Dashboards\\XFAB_France\\2022-12-15\\Figures.'\u001b[0m\n",
      "\n",
      "Working on the separated by swap date plot for TW02 pump_2.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:bokeh.core.validation.check:E-1001 (BAD_COLUMN_NAME): Glyph refers to nonexistent column name. This could either be due to a misspelling or typo, or due to an expected column being missing. : key \"y\" value \"ExhaustPressureRID10403_ExpontentiallyWeightedMovingAverage\" [renderer: GlyphRenderer(id='584445', ...)]\n",
      "ERROR:bokeh.core.validation.check:E-1001 (BAD_COLUMN_NAME): Glyph refers to nonexistent column name. This could either be due to a misspelling or typo, or due to an expected column being missing. : key \"y\" value \"ExhaustPressureRID10403_SimpleMovingAverage\" [renderer: GlyphRenderer(id='584416', ...)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDashboard for TW02 pump_2 generated and placed within 'C:\\Users\\a00555655\\OneDrive - ONEVIRTUALOFFICE\\Documents\\Dashboards\\XFAB_France\\2022-12-15\\Figures.'\u001b[0m\n",
      "\n",
      "Working on the plot for all of the data on TW02.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:bokeh.core.validation.check:E-1001 (BAD_COLUMN_NAME): Glyph refers to nonexistent column name. This could either be due to a misspelling or typo, or due to an expected column being missing. : key \"y\" value \"ExhaustPressureRID10403_SimpleMovingAverage\" [renderer: GlyphRenderer(id='591909', ...)]\n",
      "ERROR:bokeh.core.validation.check:E-1001 (BAD_COLUMN_NAME): Glyph refers to nonexistent column name. This could either be due to a misspelling or typo, or due to an expected column being missing. : key \"y\" value \"ExhaustPressureRID10403_ExpontentiallyWeightedMovingAverage\" [renderer: GlyphRenderer(id='591938', ...)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDashboard for all of the data on TW02 generated and placed within 'C:\\Users\\a00555655\\OneDrive - ONEVIRTUALOFFICE\\Documents\\Dashboards\\XFAB_France\\2022-12-15\\Figures.'\u001b[0m\n",
      "\n",
      "Working on the separated by swap date plot for TW03 pump_1.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:bokeh.core.validation.check:E-1001 (BAD_COLUMN_NAME): Glyph refers to nonexistent column name. This could either be due to a misspelling or typo, or due to an expected column being missing. : key \"y\" value \"ExhaustPressureRID11140_SimpleMovingAverage\" [renderer: GlyphRenderer(id='598886', ...)]\n",
      "ERROR:bokeh.core.validation.check:E-1001 (BAD_COLUMN_NAME): Glyph refers to nonexistent column name. This could either be due to a misspelling or typo, or due to an expected column being missing. : key \"y\" value \"ExhaustPressureRID11140_ExpontentiallyWeightedMovingAverage\" [renderer: GlyphRenderer(id='598915', ...)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDashboard for TW03 pump_1 generated and placed within 'C:\\Users\\a00555655\\OneDrive - ONEVIRTUALOFFICE\\Documents\\Dashboards\\XFAB_France\\2022-12-15\\Figures.'\u001b[0m\n",
      "\n",
      "Working on the plot for all of the data on TW03.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:bokeh.core.validation.check:E-1001 (BAD_COLUMN_NAME): Glyph refers to nonexistent column name. This could either be due to a misspelling or typo, or due to an expected column being missing. : key \"y\" value \"ExhaustPressureRID11140_ExpontentiallyWeightedMovingAverage\" [renderer: GlyphRenderer(id='604440', ...)]\n",
      "ERROR:bokeh.core.validation.check:E-1001 (BAD_COLUMN_NAME): Glyph refers to nonexistent column name. This could either be due to a misspelling or typo, or due to an expected column being missing. : key \"y\" value \"ExhaustPressureRID11140_SimpleMovingAverage\" [renderer: GlyphRenderer(id='604411', ...)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDashboard for all of the data on TW03 generated and placed within 'C:\\Users\\a00555655\\OneDrive - ONEVIRTUALOFFICE\\Documents\\Dashboards\\XFAB_France\\2022-12-15\\Figures.'\u001b[0m\n",
      "\n",
      "Working on the separated by swap date plot for TW04 pump_1.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:bokeh.core.validation.check:E-1001 (BAD_COLUMN_NAME): Glyph refers to nonexistent column name. This could either be due to a misspelling or typo, or due to an expected column being missing. : key \"y\" value \"ExhaustPressureRID6416_ExpontentiallyWeightedMovingAverage\" [renderer: GlyphRenderer(id='610223', ...)]\n",
      "ERROR:bokeh.core.validation.check:E-1001 (BAD_COLUMN_NAME): Glyph refers to nonexistent column name. This could either be due to a misspelling or typo, or due to an expected column being missing. : key \"y\" value \"ExhaustPressureRID6416_SimpleMovingAverage\" [renderer: GlyphRenderer(id='610194', ...)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDashboard for TW04 pump_1 generated and placed within 'C:\\Users\\a00555655\\OneDrive - ONEVIRTUALOFFICE\\Documents\\Dashboards\\XFAB_France\\2022-12-15\\Figures.'\u001b[0m\n",
      "\n",
      "Working on the plot for all of the data on TW04.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:bokeh.core.validation.check:E-1001 (BAD_COLUMN_NAME): Glyph refers to nonexistent column name. This could either be due to a misspelling or typo, or due to an expected column being missing. : key \"y\" value \"ExhaustPressureRID6416_SimpleMovingAverage\" [renderer: GlyphRenderer(id='616901', ...)]\n",
      "ERROR:bokeh.core.validation.check:E-1001 (BAD_COLUMN_NAME): Glyph refers to nonexistent column name. This could either be due to a misspelling or typo, or due to an expected column being missing. : key \"y\" value \"ExhaustPressureRID6416_ExpontentiallyWeightedMovingAverage\" [renderer: GlyphRenderer(id='616930', ...)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDashboard for all of the data on TW04 generated and placed within 'C:\\Users\\a00555655\\OneDrive - ONEVIRTUALOFFICE\\Documents\\Dashboards\\XFAB_France\\2022-12-15\\Figures.'\u001b[0m\n",
      "\n",
      "Working on the separated by swap date plot for TW05 pump_1.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:bokeh.core.validation.check:E-1001 (BAD_COLUMN_NAME): Glyph refers to nonexistent column name. This could either be due to a misspelling or typo, or due to an expected column being missing. : key \"y\" value \"ShaftSealPressureRID4271_SimpleMovingAverage\" [renderer: GlyphRenderer(id='623092', ...)]\n",
      "ERROR:bokeh.core.validation.check:E-1001 (BAD_COLUMN_NAME): Glyph refers to nonexistent column name. This could either be due to a misspelling or typo, or due to an expected column being missing. : key \"y\" value \"ShaftSealPressureRID4271_ExpontentiallyWeightedMovingAverage\" [renderer: GlyphRenderer(id='623121', ...)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDashboard for TW05 pump_1 generated and placed within 'C:\\Users\\a00555655\\OneDrive - ONEVIRTUALOFFICE\\Documents\\Dashboards\\XFAB_France\\2022-12-15\\Figures.'\u001b[0m\n",
      "\n",
      "Working on the plot for all of the data on TW05.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:bokeh.core.validation.check:E-1001 (BAD_COLUMN_NAME): Glyph refers to nonexistent column name. This could either be due to a misspelling or typo, or due to an expected column being missing. : key \"y\" value \"ShaftSealPressureRID4271_ExpontentiallyWeightedMovingAverage\" [renderer: GlyphRenderer(id='627860', ...)]\n",
      "ERROR:bokeh.core.validation.check:E-1001 (BAD_COLUMN_NAME): Glyph refers to nonexistent column name. This could either be due to a misspelling or typo, or due to an expected column being missing. : key \"y\" value \"ShaftSealPressureRID4271_SimpleMovingAverage\" [renderer: GlyphRenderer(id='627831', ...)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDashboard for all of the data on TW05 generated and placed within 'C:\\Users\\a00555655\\OneDrive - ONEVIRTUALOFFICE\\Documents\\Dashboards\\XFAB_France\\2022-12-15\\Figures.'\u001b[0m\n",
      "\n",
      "Working on the separated by swap date plot for TW06 pump_1.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:bokeh.core.validation.check:E-1001 (BAD_COLUMN_NAME): Glyph refers to nonexistent column name. This could either be due to a misspelling or typo, or due to an expected column being missing. : key \"y\" value \"ExhaustPressureRID14826_SimpleMovingAverage\" [renderer: GlyphRenderer(id='632441', ...)]\n",
      "ERROR:bokeh.core.validation.check:E-1001 (BAD_COLUMN_NAME): Glyph refers to nonexistent column name. This could either be due to a misspelling or typo, or due to an expected column being missing. : key \"y\" value \"ExhaustPressureRID14826_ExpontentiallyWeightedMovingAverage\" [renderer: GlyphRenderer(id='632470', ...)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDashboard for TW06 pump_1 generated and placed within 'C:\\Users\\a00555655\\OneDrive - ONEVIRTUALOFFICE\\Documents\\Dashboards\\XFAB_France\\2022-12-15\\Figures.'\u001b[0m\n",
      "\n",
      "Working on the separated by swap date plot for TW06 pump_2.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:bokeh.core.validation.check:E-1001 (BAD_COLUMN_NAME): Glyph refers to nonexistent column name. This could either be due to a misspelling or typo, or due to an expected column being missing. : key \"y\" value \"ExhaustPressureRID14826_ExpontentiallyWeightedMovingAverage\" [renderer: GlyphRenderer(id='636816', ...)]\n",
      "ERROR:bokeh.core.validation.check:E-1001 (BAD_COLUMN_NAME): Glyph refers to nonexistent column name. This could either be due to a misspelling or typo, or due to an expected column being missing. : key \"y\" value \"ExhaustPressureRID14826_SimpleMovingAverage\" [renderer: GlyphRenderer(id='636787', ...)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDashboard for TW06 pump_2 generated and placed within 'C:\\Users\\a00555655\\OneDrive - ONEVIRTUALOFFICE\\Documents\\Dashboards\\XFAB_France\\2022-12-15\\Figures.'\u001b[0m\n",
      "\n",
      "Working on the plot for all of the data on TW06.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:bokeh.core.validation.check:E-1001 (BAD_COLUMN_NAME): Glyph refers to nonexistent column name. This could either be due to a misspelling or typo, or due to an expected column being missing. : key \"y\" value \"ExhaustPressureRID14826_SimpleMovingAverage\" [renderer: GlyphRenderer(id='641133', ...)]\n",
      "ERROR:bokeh.core.validation.check:E-1001 (BAD_COLUMN_NAME): Glyph refers to nonexistent column name. This could either be due to a misspelling or typo, or due to an expected column being missing. : key \"y\" value \"ExhaustPressureRID14826_ExpontentiallyWeightedMovingAverage\" [renderer: GlyphRenderer(id='641162', ...)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDashboard for all of the data on TW06 generated and placed within 'C:\\Users\\a00555655\\OneDrive - ONEVIRTUALOFFICE\\Documents\\Dashboards\\XFAB_France\\2022-12-15\\Figures.'\u001b[0m\n",
      "\n",
      "Working on the separated by swap date plot for TW07 pump_1.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:bokeh.core.validation.check:E-1001 (BAD_COLUMN_NAME): Glyph refers to nonexistent column name. This could either be due to a misspelling or typo, or due to an expected column being missing. : key \"y\" value \"ExhaustPressureRID11127_SimpleMovingAverage\" [renderer: GlyphRenderer(id='646382', ...)]\n",
      "ERROR:bokeh.core.validation.check:E-1001 (BAD_COLUMN_NAME): Glyph refers to nonexistent column name. This could either be due to a misspelling or typo, or due to an expected column being missing. : key \"y\" value \"ExhaustPressureRID11127_ExpontentiallyWeightedMovingAverage\" [renderer: GlyphRenderer(id='646411', ...)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDashboard for TW07 pump_1 generated and placed within 'C:\\Users\\a00555655\\OneDrive - ONEVIRTUALOFFICE\\Documents\\Dashboards\\XFAB_France\\2022-12-15\\Figures.'\u001b[0m\n",
      "\n",
      "Working on the plot for all of the data on TW07.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:bokeh.core.validation.check:E-1001 (BAD_COLUMN_NAME): Glyph refers to nonexistent column name. This could either be due to a misspelling or typo, or due to an expected column being missing. : key \"y\" value \"ExhaustPressureRID11127_SimpleMovingAverage\" [renderer: GlyphRenderer(id='653875', ...)]\n",
      "ERROR:bokeh.core.validation.check:E-1001 (BAD_COLUMN_NAME): Glyph refers to nonexistent column name. This could either be due to a misspelling or typo, or due to an expected column being missing. : key \"y\" value \"ExhaustPressureRID11127_ExpontentiallyWeightedMovingAverage\" [renderer: GlyphRenderer(id='653904', ...)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDashboard for all of the data on TW07 generated and placed within 'C:\\Users\\a00555655\\OneDrive - ONEVIRTUALOFFICE\\Documents\\Dashboards\\XFAB_France\\2022-12-15\\Figures.'\u001b[0m\n",
      "\n",
      "Working on the separated by swap date plot for TW08 pump_1.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:bokeh.core.validation.check:E-1001 (BAD_COLUMN_NAME): Glyph refers to nonexistent column name. This could either be due to a misspelling or typo, or due to an expected column being missing. : key \"y\" value \"ExhaustPressureRID530_SimpleMovingAverage\" [renderer: GlyphRenderer(id='660465', ...)]\n",
      "ERROR:bokeh.core.validation.check:E-1001 (BAD_COLUMN_NAME): Glyph refers to nonexistent column name. This could either be due to a misspelling or typo, or due to an expected column being missing. : key \"y\" value \"ExhaustPressureRID530_ExpontentiallyWeightedMovingAverage\" [renderer: GlyphRenderer(id='660494', ...)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDashboard for TW08 pump_1 generated and placed within 'C:\\Users\\a00555655\\OneDrive - ONEVIRTUALOFFICE\\Documents\\Dashboards\\XFAB_France\\2022-12-15\\Figures.'\u001b[0m\n",
      "\n",
      "Working on the plot for all of the data on TW08.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:bokeh.core.validation.check:E-1001 (BAD_COLUMN_NAME): Glyph refers to nonexistent column name. This could either be due to a misspelling or typo, or due to an expected column being missing. : key \"y\" value \"ExhaustPressureRID530_SimpleMovingAverage\" [renderer: GlyphRenderer(id='664811', ...)]\n",
      "ERROR:bokeh.core.validation.check:E-1001 (BAD_COLUMN_NAME): Glyph refers to nonexistent column name. This could either be due to a misspelling or typo, or due to an expected column being missing. : key \"y\" value \"ExhaustPressureRID530_ExpontentiallyWeightedMovingAverage\" [renderer: GlyphRenderer(id='664840', ...)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDashboard for all of the data on TW08 generated and placed within 'C:\\Users\\a00555655\\OneDrive - ONEVIRTUALOFFICE\\Documents\\Dashboards\\XFAB_France\\2022-12-15\\Figures.'\u001b[0m\n",
      "\n",
      "Working on the separated by swap date plot for TW09 pump_1.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:bokeh.core.validation.check:E-1001 (BAD_COLUMN_NAME): Glyph refers to nonexistent column name. This could either be due to a misspelling or typo, or due to an expected column being missing. : key \"y\" value \"ExhaustPressureRID6441_SimpleMovingAverage\" [renderer: GlyphRenderer(id='670060', ...)]\n",
      "ERROR:bokeh.core.validation.check:E-1001 (BAD_COLUMN_NAME): Glyph refers to nonexistent column name. This could either be due to a misspelling or typo, or due to an expected column being missing. : key \"y\" value \"ExhaustPressureRID6441_ExpontentiallyWeightedMovingAverage\" [renderer: GlyphRenderer(id='670089', ...)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDashboard for TW09 pump_1 generated and placed within 'C:\\Users\\a00555655\\OneDrive - ONEVIRTUALOFFICE\\Documents\\Dashboards\\XFAB_France\\2022-12-15\\Figures.'\u001b[0m\n",
      "\n",
      "Working on the plot for all of the data on TW09.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:bokeh.core.validation.check:E-1001 (BAD_COLUMN_NAME): Glyph refers to nonexistent column name. This could either be due to a misspelling or typo, or due to an expected column being missing. : key \"y\" value \"ExhaustPressureRID6441_SimpleMovingAverage\" [renderer: GlyphRenderer(id='677553', ...)]\n",
      "ERROR:bokeh.core.validation.check:E-1001 (BAD_COLUMN_NAME): Glyph refers to nonexistent column name. This could either be due to a misspelling or typo, or due to an expected column being missing. : key \"y\" value \"ExhaustPressureRID6441_ExpontentiallyWeightedMovingAverage\" [renderer: GlyphRenderer(id='677582', ...)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDashboard for all of the data on TW09 generated and placed within 'C:\\Users\\a00555655\\OneDrive - ONEVIRTUALOFFICE\\Documents\\Dashboards\\XFAB_France\\2022-12-15\\Figures.'\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def interactive_plot_all_systems_data(all_systems_data,\n",
    "                                      save_dest,\n",
    "                                      customer_name,\n",
    "                                      mark=1,\n",
    "                                      cols=None,\n",
    "                                      save=True,\n",
    "                                      show_plots=False,\n",
    "                                      separate_by_swap=True,\n",
    "                                      sep_and_whole=True,\n",
    "                                      conceal_params=False):\n",
    "    \n",
    "    system_positions = [str(dict_key) for dict_key in all_systems_data.keys()]\n",
    "    \n",
    "    \n",
    "    for position in system_positions:\n",
    "        position_systems = [dict_key for dict_key in all_systems_data[position].keys() if 'swap_date' not in str(dict_key)]\n",
    "        if separate_by_swap or sep_and_whole:\n",
    "            for system in position_systems:\n",
    "                # columns = all_systems_data[position][system].columns\n",
    "                # columns = {col:col.replace(' ', '').replace('DP', 'DryPump').replace('MB', 'Booster') for col in columns}\n",
    "                # all_systems_data[position][system].rename(columns={})\n",
    "                print(f'\\nWorking on the separated by swap date plot for {position} {system}.\\n')\n",
    "                bokeh_system_data_plotters[f\"mk{mark}\"](data=all_systems_data[position][system],\n",
    "                                                        save_dest = save_dest,\n",
    "                                                        system_position = f\"{position}\",\n",
    "                                                        system=f\"{system}\",\n",
    "                                                        show_plots=show_plots,\n",
    "                                                        save=save,\n",
    "                                                        conceal_params=conceal_params,\n",
    "                                                        customer_name=customer_name)\n",
    "\n",
    "                if save:\n",
    "                    text = '\\033[1m' + f\"Dashboard for {position} {system} generated and placed within '{save_dest}.'\" + '\\033[0m'\n",
    "                    colored_text = colored(text=text, color='blue')\n",
    "                    print(colored_text)\n",
    "    \n",
    "        if (not separate_by_swap) or sep_and_whole:\n",
    "            all_data_for_position = pd.concat([all_systems_data[position][sys] for sys in position_systems])\n",
    "            print(f'\\nWorking on the plot for all of the data on {position}.\\n')\n",
    "            bokeh_system_data_plotters[f'mk{mark}'](data=all_data_for_position,\n",
    "                                                    save_dest=save_dest,\n",
    "                                                    system_position=position,\n",
    "                                                    system='All_Systems',\n",
    "                                                    show_plots=show_plots,\n",
    "                                                    save=save,\n",
    "                                                    conceal_params=conceal_params,\n",
    "                                                    customer_name=customer_name)\n",
    "            if save:\n",
    "                text = '\\033[1m' + f\"Dashboard for all of the data on {position} generated and placed within '{save_dest}.'\" + '\\033[0m'\n",
    "                colored_text = colored(text=text, color='blue')\n",
    "                print(colored_text)\n",
    "\n",
    "\n",
    "interactive_plot_all_systems_data(all_systems_data,\n",
    "                                  save_dest=FIG_DIR,\n",
    "                                  mark=1,\n",
    "                                  show_plots=False,\n",
    "                                  save=True,\n",
    "                                  separate_by_swap=separate_by_swap,\n",
    "                                  sep_and_whole=sep_and_whole,\n",
    "                                  conceal_params=conceal_or_not,\n",
    "                                  customer_name=customer_account_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "27e55a07bc38151c1c095ec1be726f30fcff6d2fbda644176d0355fa9ce05d44"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
